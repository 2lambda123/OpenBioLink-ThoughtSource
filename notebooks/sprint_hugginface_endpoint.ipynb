{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cot import Collection\n",
    "from cot.generate import FRAGMENTS\n",
    "from rich.pretty import pprint\n",
    "import json\n",
    "from sprint_utils import get_answer_extraction, join_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"commonsense_qa\", \"validation\"\n",
    "# \"med_qa\", \"test\"\n",
    "# \"medmc_qa\", \"validation\"\n",
    "# \"open_book_qa\", \"test\"\n",
    "# \"strategy_qa\", \"train\"\n",
    "# \"worldtree\", \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None,         # no cot-trigger\n",
    "# 'kojima-01',  # Answer: Let's think step by step.\n",
    "# 'kojima-02',  # Answer: First,\n",
    "# 'kojima-03',  # Answer: Let's think about this logically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_sprint_thoughtsource(collection, dataset_name_splits, api_service_model, cot_trigger_key=None):\n",
    "    # collection = create_thoughtsource_100()\n",
    "    collection = collection\n",
    "    for dataset_name, split in dataset_name_splits:\n",
    "        print(dataset_name)\n",
    "        answer_extraction_key = get_answer_extraction(collection[dataset_name][split][0][\"type\"], collection[dataset_name][split][0][\"choices\"])\n",
    "        for api_service, model, api_time_interval in api_service_model:\n",
    "\n",
    "            config={\n",
    "                \"instruction_keys\": None,\n",
    "                \"cot_trigger_keys\": cot_trigger_key,\n",
    "                \"answer_extraction_keys\": [answer_extraction_key], # Therefore, among A through C/D/E/F, the answer is'\n",
    "                \"author\" : \"thoughtsource\",\n",
    "                \"api_service\": api_service,\n",
    "                \"engine\": model,\n",
    "                \"temperature\": 0,\n",
    "                \"max_tokens\": 512,\n",
    "                \"api_time_interval\": api_time_interval,\n",
    "                \"verbose\": False,\n",
    "                \"warn\": False,\n",
    "            }\n",
    "        \n",
    "            collection.generate(name=dataset_name, split=split,config=config)\n",
    "            collection.dump(\"extra_save_thoughtsource_100_\" + dataset_name + \"_huggingface_endpoint.json\")\n",
    "    collection.evaluate()\n",
    "    # write model name manually in here, or it gives an error because of the \"/\" in the model name = endpoint url in this case\n",
    "    collection.dump(\"thoughtsource_100\" + \"_\" + api_service + \"_\" + \"google_flan-t5-xxl\" + join_strings(config[\"cot_trigger_keys\"]) + \".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENDPOINT TEST\n",
    "endpoint_url = (\n",
    "    \"https://vg66yz1taapw6ef6.us-east-1.aws.endpoints.huggingface.cloud\"\n",
    ")\n",
    "number_examples = 1\n",
    "dataset_name_splits = [(\"commonsense_qa\", \"validation\")] \n",
    "\n",
    "# api_service_model = [(\"huggingface_hub\", \"google/flan-t5-small\", 1)]\n",
    "cot_trigger_keys = [\"kojima-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name_splits = [(\"commonsense_qa\", \"validation\"),\n",
    "                        # (\"med_qa\", \"test\"),\n",
    "                        # (\"medmc_qa\", \"validation\"),\n",
    "                        # (\"open_book_qa\", \"test\"),\n",
    "                        # (\"strategy_qa\", \"train\"),\n",
    "                        # (\"worldtree\", \"test\"),\n",
    "                        ]\n",
    "\n",
    "# api_service_model = [(\"huggingface_hub\", \"google/flan-t5-xl\", 1)]\n",
    "api_service_model = [(\"huggingface_endpoint\", endpoint_url, 0)]\n",
    "# api_service_model = [(\"mock_api\", \"mock_model\", 0)]\n",
    "cot_trigger_key = [None, \"kojima-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "collection = Collection.from_json(\"sprint_data/thoughtsource_1_empty.json\")\n",
    "# collection = Collection.from_json(\"sprint_data/thoughtsource_100_empty.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sprint_thoughtsource(collection, dataset_name_splits, api_service_model, cot_trigger_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = collection.evaluate()\n",
    "pprint(eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccbfa654f25866afe66a1c016d0b518a994fbe20a93c2d8b432dbe114020e2d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
