{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b410b12-370e-48f5-9a93-9f7821ed847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kon/CoT/ThoughtSource/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from cot import Collection\n",
    "from cot.generate import TEMPLATES\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ec6ef-31a1-41f6-98df-ca1df05a5a25",
   "metadata": {},
   "source": [
    "## Generate random sample of worldtree dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3bc2e7-f4f6-434b-8722-609b55fe0c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading worldtree...\n",
      "| Name      |   Train |   Valid |   Test |\n",
      "|-----------|---------|---------|--------|\n",
      "| worldtree |    2207 |     496 |   1664 |\n",
      "\n",
      "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'open_book_qa', 'qed', 'strategy_qa', 'svamp']\n"
     ]
    }
   ],
   "source": [
    "# load datasets to sample from\n",
    "collection = Collection([\"worldtree\"], verbose=False)\n",
    "print(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea911fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also open an existing json\n",
    "# collection = Collection.from_json(\"generation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "379dde04-6d68-4ca0-a7b2-0a2eb552686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of random samples per dataset\n",
    "number_of_samples = 100\n",
    "\n",
    "# define subset to sample from (train/validation/test)\n",
    "subset_name = 'train'\n",
    "\n",
    "# set seed for reproducibility\n",
    "seed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5cd82e-7072-4e3c-90a3-6f1136383741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "random_sampled_collection = copy.deepcopy(collection)\n",
    "\n",
    "for dataset in random_sampled_collection:\n",
    "    _ , dataset_dict = dataset\n",
    "    subset = copy.deepcopy(dataset_dict[subset_name])\n",
    "    #get number of samples in subset\n",
    "    samples_count = subset.num_rows\n",
    "    # set seed for reproducibility\n",
    "    if seed:\n",
    "        random.seed(0)\n",
    "    random_ids = random.sample(range(samples_count), number_of_samples)\n",
    "    # sample from subset\n",
    "    random_subset = subset.select(random_ids)\n",
    "    # clear original dictionary\n",
    "    dataset_dict.clear()\n",
    "    # reinsert selected samples\n",
    "    dataset_dict[subset_name] = random_subset\n",
    "random_sampled_collection.dump(\"random_sample.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3295f79-9422-4060-b0bc-79b511523e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name      |   Train | Valid   | Test   |\n",
       "|-----------|---------|---------|--------|\n",
       "| worldtree |     100 | -       | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'open_book_qa', 'qed', 'strategy_qa', 'svamp']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sampled_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f57e102",
   "metadata": {},
   "source": [
    "# CoT Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f043028",
   "metadata": {},
   "source": [
    "Print available templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63ddbbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer-extractions': {'kojima-01': 'Therefore, the answer is',\n",
      "                        'kojima-02': 'Therefore,',\n",
      "                        'kojima-03': 'The answer is',\n",
      "                        'kojima-A-C': 'Therefore, among A through C, the '\n",
      "                                      'answer is',\n",
      "                        'kojima-A-D': 'Therefore, among A through D, the '\n",
      "                                      'answer is',\n",
      "                        'kojima-A-E': 'Therefore, among A through E, the '\n",
      "                                      'answer is',\n",
      "                        'kojima-A-F': 'Therefore, among A through F, the '\n",
      "                                      'answer is',\n",
      "                        'kojima-numerals': 'Therefore, the answer (arabic '\n",
      "                                           'numerals) is',\n",
      "                        'kojima-yes-no': 'Therefore, the answer (Yes or No) '\n",
      "                                         'is'},\n",
      " 'cot-triggers': {'kojima-01': \"Answer: Let's think step by step.\",\n",
      "                  'kojima-02': 'Answer: We should think about this step by '\n",
      "                               'step.',\n",
      "                  'kojima-03': 'Answer: First,',\n",
      "                  'kojima-04': 'Answer: Before we dive into the answer,',\n",
      "                  'kojima-05': 'Answer: Proof followed by the answer.',\n",
      "                  'kojima-06': \"Answer: Let's think step by step in a \"\n",
      "                               'realistic way.',\n",
      "                  'kojima-07': \"Answer: Let's think step by step using common \"\n",
      "                               'sense and knowledge.',\n",
      "                  'kojima-08': \"Answer: Let's think like a detective step by \"\n",
      "                               'step.',\n",
      "                  'kojima-09': \"Answer: Let's think about this logically.\",\n",
      "                  'kojima-10': \"Answer: Let's think step by step. First,\",\n",
      "                  'kojima-11': \"Answer: Let's think\",\n",
      "                  'kojima-12': \"Answer: Let's solve this problem by splitting \"\n",
      "                               'it into steps.',\n",
      "                  'kojima-13': 'Answer: The answer is after the proof.',\n",
      "                  'kojima-14': \"Answer: Let's be realistic and think step by \"\n",
      "                               'step.',\n",
      "                  'lievin-01': 'Answer: Let’s derive the differential '\n",
      "                               'diagnosis step by step.',\n",
      "                  'lievin-02': 'Answer: Let’s use step by step inductive '\n",
      "                               'reasoning, given the medical nature of the '\n",
      "                               'question.',\n",
      "                  'lievin-03': 'Answer: Let’s differentiate using step by step '\n",
      "                               'reasoning like a medical expert.',\n",
      "                  'lievin-04': 'Answer: Let’s think step by step using '\n",
      "                               'deductive reasoning.',\n",
      "                  'lievin-05': 'Answer: Let’s differentiate using step by step '\n",
      "                               'reasoning .',\n",
      "                  'lievin-06': 'Answer: Let’s think step by step to arrive at '\n",
      "                               'one of the options.',\n",
      "                  'lievin-07': 'Answer: Let’s break the problem into multiple '\n",
      "                               'steps.',\n",
      "                  'lievin-08': 'Answer: Let’s use step by step deductive '\n",
      "                               'reasoning, given the medical nature of the '\n",
      "                               'question.',\n",
      "                  'lievin-09': 'Answer: Let’s think step by step like a '\n",
      "                               'doctor.',\n",
      "                  'lievin-10': 'Answer: Let’s think step by step like a '\n",
      "                               'medical expert.',\n",
      "                  'lievin-11': 'Answer: Let’s summarize the facts step by '\n",
      "                               'step.',\n",
      "                  'lievin-12': 'Answer: Let’s think step by step using '\n",
      "                               'inductive reasoning.',\n",
      "                  'lievin-13': 'Answer: Let’s think step by step using '\n",
      "                               'deductive reasoning like a medical expert.',\n",
      "                  'lievin-14': 'Answer: Let’s be concise and think step by '\n",
      "                               'step.',\n",
      "                  'lievin-15': 'Answer: Let’s differentiate using step by step '\n",
      "                               'deductive reasoning like a medical expert.',\n",
      "                  'lievin-16': 'Answer: Let’s argue step by step.',\n",
      "                  'lievin-17': 'Answer: Let’s think step by step like a '\n",
      "                               'clinician.',\n",
      "                  'lievin-18': 'Answer: Let’s reflect on each answer option '\n",
      "                               'step by step.',\n",
      "                  'lievin-19': 'Answer: Let’s reason and differentiate options '\n",
      "                               'step by step like a medical expert.',\n",
      "                  'lievin-20': 'Answer: Let’s differentiate using step by step '\n",
      "                               'inductive reasoning like a medical expert.',\n",
      "                  'lievin-21': 'Answer: Let’s think step by step given every '\n",
      "                               'option equal consideration.',\n",
      "                  'lievin-22': 'Answer: Let’s think step by step like a '\n",
      "                               'scientist.',\n",
      "                  'lievin-23': 'Answer: Let’s use step by step inductive '\n",
      "                               'reasoning.',\n",
      "                  'lievin-24': 'Answer: Let’s work by elimination step by '\n",
      "                               'step.',\n",
      "                  'lievin-25': 'Answer: Let’s use step by step deductive '\n",
      "                               'reasoning.',\n",
      "                  'lievin-26': 'Answer: Let’s follow a Bayesian step by step '\n",
      "                               'approach.',\n",
      "                  'lievin-27': 'Answer: Let’s reflect on each option from the '\n",
      "                               'least likely to the most likely.',\n",
      "                  'lievin-28': 'Answer: Let’s use step by step Bayesian '\n",
      "                               'reasoning, given the medical nature of the '\n",
      "                               'question.'},\n",
      " 'instructions': {'qa-01': 'Answer the following question through step-by-step '\n",
      "                           'reasoning.',\n",
      "                  'qa-02': 'Answer the following question through careful, '\n",
      "                           'concise step-by-step reasoning.',\n",
      "                  'qa-03': 'Answer the following question through careful, '\n",
      "                           'concise step-by-step reasoning. Avoid making up '\n",
      "                           'wrong statements. If the question does not make '\n",
      "                           'sense or cannot be answered, write \"I cannot '\n",
      "                           'answer the question\". If you do not have a good '\n",
      "                           'answer, write \"I do not have a good answer\". If '\n",
      "                           'you are uncertain, write \"I am uncertain about '\n",
      "                           'this\".',\n",
      "                  'qa-04': 'Answer the following question through careful, '\n",
      "                           'concise step-by-step reasoning. Avoid making up '\n",
      "                           'wrong statements. Generate sub-questions that are '\n",
      "                           'required to answer the original question, answer '\n",
      "                           'them until you can answer the original question. '\n",
      "                           'If the question does not make sense or cannot be '\n",
      "                           'answered, write \"I cannot answer the question\". If '\n",
      "                           'you do not have a good answer, write \"I do not '\n",
      "                           'have a good answer\". If you are uncertain, write '\n",
      "                           '\"I am uncertain about this\".'},\n",
      " 'version': '0.01'}\n"
     ]
    }
   ],
   "source": [
    "pprint(TEMPLATES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0444b5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 100, n_instruction_keys: 1, n_cot_trigger_keys: 1, n_answer_extraction_keys: 1\n",
      "You are about to call the openai API which produces costs.\n",
      "Due to your settings you are about to call the openai API in total 200 times.\n",
      "Number API calls for CoT generation: n_samples * n_instruction_keys * n_cot_trigger_keys\n",
      "Number API calls for answer extraction: n_samples * n_instruction_keys * n_cot_trigger_keys * n_answer_extraction_keys\n",
      "Do you want to continue? y/n\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "config={\n",
    "    \"idx_range\":(0,3), # Determines which indices the generate_and_extract routine is applied to, Default: None (All items are used)\n",
    "    \"debug\": True, # Determines whether an api is called or a mock is returned, used for debugging, Default: True (api is not used)\n",
    "    \"instruction_keys\": [\"qa-01\"], # Determines which instructions are used from templates.json, Default: None (All used)\n",
    "    \"cot_trigger_keys\": [\"kojima-01\"], # Determines which cot triggers are used from templates.json, Default: None (All are used)\n",
    "    \"answer_extraction_keys\": [\"kojima-01\"], # Determines which answer extraction prompts are used from templates.json, Default: None (All are used)\n",
    "    \"author\" : \"Konstantin\", # Name of the person responsible for generation, Default: \"\"\n",
    "    \"api_service\": \"openai\", # Name of the API called (\"openai\", \"huggingface_hub\"), Default: \"openai\"\n",
    "    \"engine\": \"text-davinci-002\", # Name of the engine used (for \"huggingface_hub\" use for example \"google/flan-t5-xl\"), Default: \"text-davinci-002\"\n",
    "    \"temperature\": 0, # Name of the person responsible for generation, Default: 0\n",
    "    \"max_tokens\": 512, # Maximum lenght of output generated by the model, Default: 128\n",
    "    \"api_time_interval\": 1.0, # Pause between two api calls in seconds, Default: 1.0\n",
    "    \"warn\": False,\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "config={\n",
    "    \"debug\": True,\n",
    "    \"instruction_keys\": [None],\n",
    "    \"cot_trigger_keys\": [\n",
    "        'kojima-01'\n",
    "    ],\n",
    "    \"answer_extraction_keys\": [\n",
    "        'kojima-01'\n",
    "    ],\n",
    "    \"author\" : \"konstantin\",\n",
    "    \"api_service\": \"openai\",\n",
    "    \"engine\": \"text-davinci-002\",\n",
    "    \"temperature\": 0,\n",
    "    \"max_tokens\": 512,\n",
    "    \"api_time_interval\": 1.0,\n",
    "    \"verbose\": False\n",
    "}\n",
    "random_sampled_collection.generate(name=\"worldtree\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508ffb0",
   "metadata": {},
   "source": [
    "### Save generated cots and extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sampled_collection.dump(\"generation.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a19cb823e24c98ee05a9cfa4a3a579b5d56d4c1a735f2a12456750b95a1e155e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
