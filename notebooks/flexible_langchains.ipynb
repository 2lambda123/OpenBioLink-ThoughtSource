{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Example dataset with one sample for two datasets\"\"\"\n",
    "\n",
    "from cot import Collection\n",
    "coll = Collection.load_thoughtsource_100(names=['worldtree'],load_pregenerated_cots=True) #random_sample=False?\n",
    "coll = coll.select(split=\"all\", number_samples=1)\n",
    "coll.select_generated_cots(cot_trigger = \"kojima-01\", api_service='cohere') #have one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading worldtree...\n",
      "Downloading and preparing dataset worldtree_dataset/thoughtsource to /Users/robertpraas/.cache/huggingface/datasets/worldtree_dataset/thoughtsource/1.0.0/4ec0cd827b41f05891af9a27bf461fecd407e2fe7c1beebfed1eb00193c2cd52...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aed59b8ad2b40b7afc6396822c78b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4aa67823ab1404f95e42070853b1d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a65226b4be456a96d43047495215a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset worldtree_dataset downloaded and prepared to /Users/robertpraas/.cache/huggingface/datasets/worldtree_dataset/thoughtsource/1.0.0/4ec0cd827b41f05891af9a27bf461fecd407e2fe7c1beebfed1eb00193c2cd52. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce402c9b02743ab81c86f742dcd5015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cot import Collection\n",
    "\n",
    "coll = Collection(\"worldtree\", load_pregenerated_cots=True,generate_mode='recache')\n",
    "coll = coll.select(split=\"test\", number_samples=1)\n",
    "coll.select_generated_cots(cot_trigger = \"kojima-01\", api_service='cohere') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'worldtree_test_788',\n",
       " 'ref_id': '',\n",
       " 'question': 'When light hits a mirror, most of the light is',\n",
       " 'type': 'multiplechoice',\n",
       " 'choices': ['refracted.', 'reflected.', 'absorbed.', 'transmitted.'],\n",
       " 'context': '',\n",
       " 'cot': ['A mirror reflects light.',\n",
       "  'Reflection is when a wave bounces off a surface and travels in the opposite direction relative to the angle of incidence.',\n",
       "  'Light is a kind of wave.',\n",
       "  'When light hits a reflective object , that light bounces off that object.',\n",
       "  'A mirror is a kind of reflective object.'],\n",
       " 'answer': ['reflected.'],\n",
       " 'generated_cot': [],\n",
       " 'feedback': []}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll['worldtree']['test'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI \n",
    "from langchain.prompts import PromptTemplate \n",
    "from langchain.chains.llm import LLMChain\n",
    "import json\n",
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CoT Chain\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=.0,model_name=\"gpt-3.5-turbo\") #ADA #for chat: gpt-3.5-turbo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "template = \"\"\"{instruction}\n",
    "\n",
    "Question: {question}\n",
    "Answer_choices: {answer_choices}\n",
    "\n",
    "{cot_trigger}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\"], template=template)\n",
    "cot_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"cot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"answer extraction chain\"\"\"\n",
    "\n",
    "extraction_template = \"\"\"{instruction}\n",
    "\n",
    "Question: {question}\n",
    "Answer_choices: {answer_choices}\n",
    "\n",
    "Cot: {cot_trigger}{cot}\n",
    "{answer_extraction}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\"], template=extraction_template)\n",
    "answer_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"predicted_answer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CoT-Ans_extraction chain\"\"\"\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "overall_chain = SequentialChain(chains=[cot_chain, answer_chain],\n",
    "                                input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"answer_extraction\"],\n",
    "                                output_variables=[\"cot\", \"predicted_answer\"],\n",
    "                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name      | Train   | Valid   |   Test |\n",
       "|-----------|---------|---------|--------|\n",
       "| worldtree | -       | -       |      1 |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'med_qa_open', 'medmc_qa', '_init_', 'mmlu_clinical_knowledge', 'mmlu_college_biology', 'mmlu_college_medicine', 'mmlu_medical_genetics', 'mmlu_professional_medicine', '_init_', 'mmlu_anatomy', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating worldtree...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'id': 'worldtree_test_788', 'ref_id': '', 'question': 'When light hits a mirror, most of the light is', 'type': 'multiplechoice', 'choices': ['refracted.', 'reflected.', 'absorbed.', 'transmitted.'], 'context': '', 'cot': ['A mirror reflects light.', 'Reflection is when a wave bounces off a surface and travels in the opposite direction relative to the angle of incidence.', 'Light is a kind of wave.', 'When light hits a reflective object , that light bounces off that object.', 'A mirror is a kind of reflective object.'], 'answer': ['reflected.'], 'generated_cot': [{'id': '5c3620a5-058a-42db-9f3d-ebee29d1d3ae', 'fragments_version': None, 'instruction': 'Be faithful and a little hopeful', 'cot_trigger': \"Answer: Let's think step by step.\", 'cot_trigger_template': '', 'prompt_text': '', 'cot': 'When light hits a mirror, it bounces back off the surface of the mirror. This process is called reflection. Therefore, the correct answer is B) reflected.', 'answers': [{'id': '67a45297-a294-487e-bbfe-a29e69331b76', 'answer_extraction': 'Therefore, among A through D, the answer is', 'answer_extraction_template': '', 'answer_extraction_text': '', 'answer': 'B) reflected.', 'answer_from_choices': '', 'correct_answer': None}], 'author': '', 'date': '2023/05/12 10:06:11', 'api_service': '', 'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 800}\", 'comment': 'generated and extracted', 'annotations': []}], 'feedback': []}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Generate CoT with use of TS-schema\"\"\"\n",
    "#compare with config used before; what about max tokens?\n",
    "#config contains what the chain needs\n",
    "input_dict = {'input_dict':\n",
    "              {\n",
    "                  'chain': overall_chain,\n",
    "                  \"instruction\": \"Be faithful and a little hopeful\",\n",
    "                  \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "                  \"answer_extraction\": \"Therefore, among A through D, the answer is\",\n",
    "                  'model': \"gpt-3.5-turbo\",\n",
    "                  'temperature': 0,\n",
    "                  'max_tokens': 800\n",
    "              }\n",
    "              }\n",
    "    \n",
    "coll.generate_extract_flexible(input_dict=input_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_coll = Collection.to_Collection(coll,\"worldtree\",'test','file_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldtree_2 = {'worldtree':{'test':coll}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'id': '470bcc15-51e6-40da-a19d-d575123a07a1',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': 'Be faithful and a little hopeful',\n",
       "   'cot_trigger': \"Answer: Let's think step by step.\",\n",
       "   'cot_trigger_template': '',\n",
       "   'prompt_text': '',\n",
       "   'cot': 'When light hits a mirror, it bounces back off the surface of the mirror. This process is called reflection. Therefore, the correct answer is B) reflected.',\n",
       "   'answers': [{'id': 'c755d584-135b-4610-b6b5-680b834142f5',\n",
       "     'answer_extraction': 'Therefore, among A through D, the answer is',\n",
       "     'answer_extraction_template': '',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'B) reflected.',\n",
       "     'correct_answer': None}],\n",
       "   'author': '',\n",
       "   'date': '2023/05/07 13:11:15',\n",
       "   'api_service': '',\n",
       "   'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 800}\",\n",
       "   'comment': 'generated and extracted',\n",
       "   'annotations': []}]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and collect a json to make collection\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    json.dump(worldtree_2, outfile)\n",
    "collect = Collection.from_json('sample.json')\n",
    "\n",
    "collect['worldtree']['test']['generated_cot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['id', 'ref_id', 'question', 'type', 'choices', 'context', 'cot', 'answer', 'generated_cot', 'feedback'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect['worldtree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset worldtree_dataset (/Users/robertpraas/.cache/huggingface/datasets/worldtree_dataset/thoughtsource/1.0.0/4ec0cd827b41f05891af9a27bf461fecd407e2fe7c1beebfed1eb00193c2cd52)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading worldtree...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bf990b8cf146a9822b6043ce4ccb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "third_coll = Collection(\"worldtree\", load_pregenerated_cots=True)\n",
    "third_coll = third_coll.select(split=\"test\", number_samples=1)\n",
    "third_coll.select_generated_cots(cot_trigger = \"kojima-01\", api_service='cohere') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate or extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset worldtree_dataset (/Users/robertpraas/.cache/huggingface/datasets/worldtree_dataset/thoughtsource/1.0.0/4ec0cd827b41f05891af9a27bf461fecd407e2fe7c1beebfed1eb00193c2cd52)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading worldtree...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e0deed80a947bca817dfb6045a4bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cot import Collection\n",
    "new_coll = Collection(\"worldtree\", load_pregenerated_cots=True)\n",
    "new_coll = new_coll.select(split=\"test\", number_samples=1)\n",
    "\n",
    "new_coll.select_generated_cots(cot_trigger = \"kojima-01\", api_service='cohere') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name      | Train   | Valid   |   Test |\n",
       "|-----------|---------|---------|--------|\n",
       "| worldtree | -       | -       |      1 |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'med_qa_open', 'medmc_qa', '_init_', 'mmlu_clinical_knowledge', 'mmlu_college_biology', 'mmlu_college_medicine', 'mmlu_medical_genetics', 'mmlu_professional_medicine', '_init_', 'mmlu_anatomy', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating worldtree...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "| Name      | Train   | Valid   |   Test |\n",
       "|-----------|---------|---------|--------|\n",
       "| worldtree | -       | -       |      1 |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'med_qa_open', 'medmc_qa', '_init_', 'mmlu_clinical_knowledge', 'mmlu_college_biology', 'mmlu_college_medicine', 'mmlu_medical_genetics', 'mmlu_professional_medicine', '_init_', 'mmlu_anatomy', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Here use the single langchain\"\"\"\n",
    "input_dict = {\n",
    "    'input_dict': {\n",
    "        'chain': cot_chain,\n",
    "        \"instruction\": \"Be faithful and a little hopeful\",\n",
    "        \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "        \"answer_extraction\": \"Therefore, among A through D, the answer is\",\n",
    "        'model': \"gpt-3.5-turbo\",\n",
    "        'api_service': 'OpenAI',\n",
    "        'temperature': 0,\n",
    "        'max_tokens': 800\n",
    "    }\n",
    "} \n",
    "\n",
    "new_coll.generate_flexible(input_dict=input_dict,name='worldtree',split='test')\n",
    "new_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating worldtree...\n",
      "[{'id': '2e815d15-e354-4956-8df6-68b38ffdbe38', 'answer_extraction': 'Be faithful and a little hopeful', 'answer_extraction_template': '', 'answer_extraction_text': '', 'answer': 'As an AI language model, I do not have beliefs or emotions, but I will always provide accurate and helpful responses to your questions.', 'answer_from_choices': '', 'correct_answer': None}]\n",
      "################\n",
      "[{'id': '2e815d15-e354-4956-8df6-68b38ffdbe38', 'answer_extraction': 'Be faithful and a little hopeful', 'answer_extraction_template': '', 'answer_extraction_text': '', 'answer': 'As an AI language model, I do not have beliefs or emotions, but I will always provide accurate and helpful responses to your questions.', 'answer_from_choices': '', 'correct_answer': None}, {'id': 'c4b30671-576e-4654-9bd5-931e28f3c024', 'answer_extraction': 'Be faithful and a little hopeful', 'answer_extraction_template': '', 'answer_extraction_text': '', 'answer': 'As an AI language model, I do not have beliefs or emotions, but I will always provide accurate and helpful responses to your questions.', 'answer_from_choices': '', 'correct_answer': None}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Extract script: Assumes there are CoTs in the dataset already\"\"\"\n",
    "\n",
    "input_dict = {\n",
    "    'input_dict':{\n",
    "    'chain': answer_chain,\n",
    "    'instruction': None,\n",
    "    \"answer_extraction\": \"Be faithful and a little hopeful\",\n",
    "    \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "    'api_service': \"chat_openai\",\n",
    "    'model':\"gpt-3.5-turbo\",\n",
    "    'temperature': 0,\n",
    "    'max_tokens': 800 \n",
    "}}\n",
    "new_coll.extract_flexible(input_dict=input_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=.0,model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "reflect_template = \"\"\"\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    Cot: {cot_trigger}{cot}\n",
    "    {answer_extraction}\n",
    "    Answer: {answer}\n",
    "    \n",
    "    {reflection_prompt}\n",
    "    \"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\",'answer','reflection_prompt'], template=reflect_template)\n",
    "reflect_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"reflection\")\n",
    "\n",
    "extraction_template = \"\"\"{instruction}\n",
    "\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    Cot: {cot_trigger}{cot}\n",
    "    {answer_extraction}{answer}\n",
    "    {reflection_prompt}{reflection}\n",
    "\n",
    "    {reflect_answer_extraction}\n",
    "    \"\"\"\n",
    "    #Get reflection\n",
    "prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\",'answer','reflection_prompt','reflection','reflect_answer_extraction'], template=extraction_template)\n",
    "reflect_answer_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"reflection_answer\")\n",
    "\n",
    "    # This is the overall chain where we run these two chains in sequence.\n",
    "from langchain.chains import SequentialChain\n",
    "reflect_overall_chain = SequentialChain(chains=[reflect_chain, reflect_answer_chain],input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"answer_extraction\",'cot','answer','reflection_prompt','reflect_answer_extraction'],\n",
    "        output_variables=[\"reflection\", \"reflection_answer\"],\n",
    "        verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating worldtree...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#check for what is already in item\n",
    "input_dict = {'input_dict':{\n",
    "    'chain':reflect_overall_chain,\n",
    "    'cot_trigger':\"\", \n",
    "    'answer':\"\", \n",
    "    'answer_extraction': \"\", \n",
    "    'cot': \"\", \n",
    "    'instruction': \"\",\n",
    "    'api_service': \"chat_openai\", \n",
    "    'model': \"gpt-3.5-turbo\",\n",
    "    'reflection_prompt':\"Double check this\",\n",
    "    'reflect_answer_extraction':'Based on the reflection, what is the definite answer?',\n",
    "    'temperature': 0,\n",
    "    'max_tokens': 800 \n",
    "}\n",
    "}\n",
    "coll.metareason_flexible(input_dict=input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '6d6af7a2-9246-4569-bf59-82f87217c732',\n",
       " 'fragments_version': '',\n",
       " 'instruction': '',\n",
       " 'cot_trigger': 'Double check this',\n",
       " 'cot_trigger_template': '',\n",
       " 'prompt_text': '',\n",
       " 'cot': 'As an AI language model, I can confirm that the answer is correct. When light hits a mirror, it is reflected back off the surface of the mirror. This is due to the smooth surface of the mirror, which allows the light to bounce back in a predictable way. Therefore, the correct answer is B) reflected.',\n",
       " 'answers': [{'id': '85ab99c5-5651-45b2-b9bb-f934aab50e37',\n",
       "   'answer_extraction': 'Based on the reflection, what is the definite answer?',\n",
       "   'answer_extraction_template': '',\n",
       "   'answer_extraction_text': 'self_reflection',\n",
       "   'answer': 'The definite answer is B) reflected.',\n",
       "   'answer_from_choices': '',\n",
       "   'correct_answer': None}],\n",
       " 'author': '',\n",
       " 'date': '2023/05/12 10:42:30',\n",
       " 'api_service': 'chat_openai',\n",
       " 'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 800}\",\n",
       " 'comment': 'self_reflection cot',\n",
       " 'annotations': []}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll['worldtree']['test'][0]['generated_cot'][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
