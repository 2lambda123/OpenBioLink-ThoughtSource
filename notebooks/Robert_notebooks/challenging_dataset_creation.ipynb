{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commonsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/robertpraas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from cot import Collection\n",
    "coll = Collection.load_thoughtsource_100(load_pregenerated_cots=True)\n",
    "coll.select_generated_cots(cot_trigger = \"kojima-01\", api_service='openai',model = 'text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1b29d402c3e17cb3b435',\n",
       " 'ref_id': '',\n",
       " 'question': 'Is a pound sterling valuable?',\n",
       " 'type': 'bool',\n",
       " 'choices': ['True', 'False'],\n",
       " 'context': '',\n",
       " 'cot': ['A pound sterling is fiat money.',\n",
       "  'Fiat money is backed by government decree and has no intrinsic value.',\n",
       "  'One pound sterling is worth about 1.24 US dollars by May of 2020.'],\n",
       " 'answer': ['False'],\n",
       " 'generated_cot': [],\n",
       " 'feedback': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll['strategy_qa']['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name           | Train   |   Valid | Test   |\n",
       "|----------------|---------|---------|--------|\n",
       "| commonsense_qa | -       |     100 | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp', 'worldtree']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cot import Collection\n",
    "coll = Collection.load_thoughtsource_100(load_pregenerated_cots=True)\n",
    "coll.select_generated_cots(cot_trigger = \"kojima-01\", api_service='openai',model = 'text-davinci-003')\n",
    "coll.select_generated_cots(answers=\"False\")\n",
    "coll.unload_datasets([\"med_qa\",\"medmc_qa\",\"strategy_qa\",'open_book_qa','worldtree'])\n",
    "coll\n",
    "#coll.dump(\"cs_davinci.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Went through Annotator\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name           | Train   |   Valid | Test   |\n",
       "|----------------|---------|---------|--------|\n",
       "| commonsense_qa | -       |     100 | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp', 'worldtree']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated = Collection.from_json(\"cs_davinci_annotated.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Moved to annotated files folder\"\"\"\n",
    "\n",
    "ann_1 = Collection.from_json(\"annotated_ob_davinci.json\") #open book\n",
    "ann_2 = Collection.from_json(\"annotated_st_davinci.json\") #strategu\n",
    "ann_3 = Collection.from_json(\"annotated_wt_davinci.json\")\n",
    "ann_4 = Collection.from_json(\"cs_davinci_annotated.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_annotated(dataset,split,selection):\n",
    "    i= 0\n",
    "    lst = []\n",
    "    for element in selection[dataset][split]:\n",
    "        if len(element['generated_cot'])>0:\n",
    "            if len(element['generated_cot'][0]['annotations'])>0 :\n",
    "                lst.append(i)\n",
    "        i+=1\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_1 = Collection.from_json(\"annotated_ob_davinci.json\") #open book\n",
    "ann_2 = Collection.from_json(\"annotated_st_davinci.json\") #strategu\n",
    "ann_3 = Collection.from_json(\"annotated_wt_davinci.json\")\n",
    "ann_4 = Collection.from_json(\"cs_davinci_annotated.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_1['open_book_qa']['test'] = ann_1['open_book_qa']['test'].select(select_annotated('open_book_qa','test',ann_1))\n",
    "ann_2['strategy_qa']['train'] = ann_2['strategy_qa']['train'].select(select_annotated('strategy_qa','train',ann_2))\n",
    "ann_3['worldtree']['test'] = ann_3['worldtree']['test'].select(select_annotated('worldtree','test',ann_3))\n",
    "ann_4['commonsense_qa']['validation'] = ann_4['commonsense_qa']['validation'].select(select_annotated('commonsense_qa','validation',ann_4))\n",
    " annotated_set = ann_4.merge(ann_3).merge(ann_2).merge(ann_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_set.dump('annotated_set.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Medical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cot import Collection\n",
    "coll = Collection.load_thoughtsource_100(load_pregenerated_cots=True)\n",
    "coll.select_generated_cots(cot_trigger = \"kojima-01\", api_service='openai',model = 'text-davinci-003')\n",
    "coll.select_generated_cots(answers=\"False\")\n",
    "coll.unload_datasets([\"commonsense_qa\",\"strategy_qa\",'open_book_qa','worldtree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name     | Train   | Valid   | Test   |\n",
       "|----------|---------|---------|--------|\n",
       "| med_qa   | -       | -       | 100    |\n",
       "| medmc_qa | -       | 100     | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp', 'worldtree']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for item in coll['med_qa']['test']:\n",
    "    if len(item['generated_cot'])>0:\n",
    "        i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for item in coll['medmc_qa']['validation']:\n",
    "    if len(item['generated_cot'])>0:\n",
    "        i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll.dump('medical_incorrect.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get gpt-4 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cot import Collection\n",
    "col = Collection.from_json(\"../notebooks/thoughtsource_100_openai_chat_gpt-4_None_zhou-01.json\")\n",
    "col.select_generated_cots(api_service='openai_chat',model = 'gpt-4')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at annotated set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name           | Train   | Valid   | Test   |\n",
       "|----------------|---------|---------|--------|\n",
       "| commonsense_qa | -       | 12      | -      |\n",
       "| worldtree      | -       | -       | 7      |\n",
       "| strategy_qa    | 11      | -       | -      |\n",
       "| open_book_qa   | -       | -       | 21     |\n",
       "| med_qa         | -       | -       | 20     |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'entailment_bank', 'gsm8k', 'mawps', 'medmc_qa', 'pubmed_qa', 'qed', 'svamp']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cot import Collection\n",
    "ann_col = Collection.from_json(\"../notebooks/ts_hard_v1.json\")\n",
    "ann_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = ann_col['commonsense_qa']['validation']['id']\n",
    "id_list_2 = ann_col['worldtree']['test']['id']\n",
    "id_list_3 = ann_col['strategy_qa']['train']['id']\n",
    "id_list_4 = ann_col['open_book_qa']['test']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(collection,id_list,dataset,split):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for item in collection[dataset][split]:\n",
    "        if item['id'] in id_list:\n",
    "            j +=1\n",
    "            if item['generated_cot'][0]['answers'][0]['correct_answer'] == True:\n",
    "                i +=1\n",
    "    return (f\"{i}/{j}={i/j}\")\n",
    "\n",
    "# GPT-4 7/11 correct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8/12=0.6666666666666666'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(col, id_list,'commonsense_qa','validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7/7=1.0'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(col, id_list_2,'worldtree','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8/11=0.7272727272727273'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(col, id_list_3,'strategy_qa','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19/21=0.9047619047619048'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(col, id_list_4,'open_book_qa','test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotated creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_1 = Collection.from_json(\"../notebooks/internal_documentation/newly_annotated/annotated_ob_davinci.json\") #open book\n",
    "ann_2 = Collection.from_json(\"../notebooks/internal_documentation/newly_annotated/annotated_st_davinci.json\") #strategu\n",
    "ann_3 = Collection.from_json(\"../notebooks/internal_documentation/newly_annotated/annotated_wt_davinci.json\")\n",
    "ann_4 = Collection.from_json(\"../notebooks/internal_documentation/newly_annotated/cs_davinci_annotated.json\")\n",
    "ann_5 = Collection.from_json(\"../notebooks/internal_documentation/newly_annotated/medical_incorrect_1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_5 = Collection.from_json(\"chat_hard.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_5['open_book_qa']['test'] = ann_5['open_book_qa']['test'].select(select_annotated('open_book_qa','test',ann_5))\n",
    "ann_5['strategy_qa']['train'] = ann_5['strategy_qa']['train'].select(select_annotated('strategy_qa','train',ann_5))\n",
    "ann_5['worldtree']['test'] = ann_5['worldtree']['test'].select(select_annotated('worldtree','test',ann_5))\n",
    "ann_5['commonsense_qa']['validation'] = ann_5['commonsense_qa']['validation'].select(select_annotated('commonsense_qa','validation',ann_5))\n",
    "ann_5['medmc_qa']['validation'] = ann_5['medmc_qa']['validation'].select(select_annotated('medmc_qa','validation',ann_5))\n",
    "ann_5['med_qa']['test'] = ann_5['med_qa']['test'].select(select_annotated('med_qa','test',ann_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name           | Train   | Valid   | Test   |\n",
       "|----------------|---------|---------|--------|\n",
       "| commonsense_qa | -       | 4       | -      |\n",
       "| med_qa         | -       | -       | 1      |\n",
       "| medmc_qa       | -       | 0       | -      |\n",
       "| open_book_qa   | -       | -       | 12     |\n",
       "| strategy_qa    | 3       | -       | -      |\n",
       "| worldtree      | -       | -       | 1      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'entailment_bank', 'gsm8k', 'mawps', 'pubmed_qa', 'qed', 'svamp']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_5.unload_datasets([\"medmc_qa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name           | Train   | Valid   | Test   |\n",
       "|----------------|---------|---------|--------|\n",
       "| commonsense_qa | -       | 4       | -      |\n",
       "| med_qa         | -       | -       | 1      |\n",
       "| open_book_qa   | -       | -       | 12     |\n",
       "| strategy_qa    | 3       | -       | -      |\n",
       "| worldtree      | -       | -       | 1      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'entailment_bank', 'gsm8k', 'mawps', 'medmc_qa', 'pubmed_qa', 'qed', 'svamp']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d05ec826c94a80a31afb1c0e31d365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f170d98ec9704b8dbde89f48325b1bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbab20b2ea1f4d56a3a03b05f46f8e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30522940f54b41169f8045dc4f92d8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f9ebe22baf4ba2935988af05f32da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann_5.dump('chatgpt_hard_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_1['open_book_qa']['test'] = ann_1['open_book_qa']['test'].select(select_annotated('open_book_qa','test',ann_1))\n",
    "ann_2['strategy_qa']['train'] = ann_2['strategy_qa']['train'].select(select_annotated('strategy_qa','train',ann_2))\n",
    "ann_3['worldtree']['test'] = ann_3['worldtree']['test'].select(select_annotated('worldtree','test',ann_3))\n",
    "ann_4['commonsense_qa']['validation'] = ann_4['commonsense_qa']['validation'].select(select_annotated('commonsense_qa','validation',ann_4))\n",
    "ann_5['med_qa']['test'] = ann_5['med_qa']['test'].select(select_annotated('med_qa','test',ann_5))\n",
    "annotated_set = ann_4.merge(ann_3).merge(ann_2).merge(ann_1).merge(ann_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name           | Train   | Valid   | Test   |\n",
       "|----------------|---------|---------|--------|\n",
       "| commonsense_qa | -       | 12      | -      |\n",
       "| worldtree      | -       | -       | 7      |\n",
       "| strategy_qa    | 11      | -       | -      |\n",
       "| open_book_qa   | -       | -       | 21     |\n",
       "| med_qa         | -       | -       | 20     |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'entailment_bank', 'gsm8k', 'mawps', 'medmc_qa', 'pubmed_qa', 'qed', 'svamp']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/robertpraas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from cot import Collection\n",
    "chat_col = Collection.load_thoughtsource_100(load_pregenerated_cots=True)\n",
    "chat_col.select_generated_cots(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9/12=0.75'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(chat_col, id_list,'commonsense_qa','validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6/7=0.8571428571428571'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(chat_col, id_list_2,'worldtree','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6/11=0.5454545454545454'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(chat_col, id_list_3,'strategy_qa','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cases(collection,id_list,dataset,split):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for item in collection[dataset][split]:\n",
    "        if item['id'] in id_list:\n",
    "            j +=1\n",
    "            if item['generated_cot'][0]['answers'][0]['correct_answer'] == True:\n",
    "                i +=1\n",
    "                print(item['generated_cot'][0])\n",
    "    return (f\"{i}/{j}={i/j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_wrong_cases(collection,id_list,dataset,split):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for item in collection[dataset][split]:\n",
    "        if item['id'] in id_list:\n",
    "            j +=1\n",
    "            if item['generated_cot'][0]['answers'][0]['correct_answer'] == True:\n",
    "                i +=1\n",
    "            else:\n",
    "                print(item['generated_cot'][0])\n",
    "    return (f\"{i}/{j}={i/j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '8f7f7891-6883-4f3c-ba65-9815b1dc1336', 'fragments_version': '0.01', 'instruction': None, 'cot_trigger': None, 'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}', 'prompt_text': '', 'cot': 'B) False', 'answers': [{'id': 'd4cb0b15-d436-4109-9e97-877948d892ba', 'answer_extraction': 'kojima-yes-no', 'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}', 'answer_extraction_text': '', 'answer': 'No.', 'correct_answer': True}], 'author': 'thoughtsource', 'date': '2023/03/11 02:09:38', 'api_service': 'openai_chat', 'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\", 'comment': '', 'annotations': []}\n",
      "{'id': '36c657f8-c64c-46dd-83ea-3ad934e51f45', 'fragments_version': '0.01', 'instruction': None, 'cot_trigger': None, 'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}', 'prompt_text': '', 'cot': 'A) True', 'answers': [{'id': 'eebdc618-a20e-4ccc-8cf8-ac62c1b210bb', 'answer_extraction': 'kojima-yes-no', 'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}', 'answer_extraction_text': '', 'answer': 'Yes.', 'correct_answer': True}], 'author': 'thoughtsource', 'date': '2023/03/11 02:10:32', 'api_service': 'openai_chat', 'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\", 'comment': '', 'annotations': []}\n",
      "{'id': 'd7d8c828-a1ce-46f0-9de1-d9a7a324ff81', 'fragments_version': '0.01', 'instruction': None, 'cot_trigger': None, 'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}', 'prompt_text': '', 'cot': 'A) True', 'answers': [{'id': '393ca48f-0dc2-43f1-a2d1-dd2f42caf17c', 'answer_extraction': 'kojima-yes-no', 'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}', 'answer_extraction_text': '', 'answer': 'Yes.', 'correct_answer': True}], 'author': 'thoughtsource', 'date': '2023/03/11 02:13:17', 'api_service': 'openai_chat', 'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\", 'comment': '', 'annotations': []}\n",
      "{'id': 'b4e34b58-5756-4420-a3b1-f756d66a7dbf', 'fragments_version': '0.01', 'instruction': None, 'cot_trigger': None, 'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}', 'prompt_text': '', 'cot': 'A) True', 'answers': [{'id': 'd73e7512-15cb-461e-994c-487bdf6381b9', 'answer_extraction': 'kojima-yes-no', 'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}', 'answer_extraction_text': '', 'answer': 'Yes.', 'correct_answer': True}], 'author': 'thoughtsource', 'date': '2023/03/11 02:15:22', 'api_service': 'openai_chat', 'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\", 'comment': '', 'annotations': []}\n",
      "{'id': '14a1b71d-52b3-4965-89a4-d139e086786c', 'fragments_version': '0.01', 'instruction': None, 'cot_trigger': None, 'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}', 'prompt_text': '', 'cot': 'B) False', 'answers': [{'id': '2a312091-e5ef-4c1f-9d58-7ef038907bf7', 'answer_extraction': 'kojima-yes-no', 'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}', 'answer_extraction_text': '', 'answer': 'No.', 'correct_answer': True}], 'author': 'thoughtsource', 'date': '2023/03/11 02:25:05', 'api_service': 'openai_chat', 'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\", 'comment': '', 'annotations': []}\n",
      "{'id': 'df0513d7-c33f-4dc9-bb16-5fa840c26a58', 'fragments_version': '0.01', 'instruction': None, 'cot_trigger': None, 'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}', 'prompt_text': '', 'cot': 'B) False. Kindergarten teachers typically do not teach religious lessons, especially those focused on specific religious texts.', 'answers': [{'id': '28be354c-af56-4a4f-9d4c-5f6d2dcff7ca', 'answer_extraction': 'kojima-yes-no', 'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}', 'answer_extraction_text': '', 'answer': 'No.', 'correct_answer': True}], 'author': 'thoughtsource', 'date': '2023/03/11 02:25:21', 'api_service': 'openai_chat', 'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\", 'comment': '', 'annotations': []}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'6/11=0.5454545454545454'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_cases(chat_col, id_list_3,'strategy_qa','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'a6fb7b88-1514-47ef-b6af-cde000092a5c', 'fragments_version': '0.01', 'instruction': None, 'cot_trigger': None, 'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}', 'prompt_text': '', 'cot': 'A) True', 'answers': [{'id': '1e2d4c0d-f825-430c-a1b1-7aa70dbe79b2', 'answer_extraction': 'kojima-yes-no', 'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}', 'answer_extraction_text': '', 'answer': 'Yes.', 'correct_answer': False}], 'author': 'thoughtsource', 'date': '2023/03/11 02:07:14', 'api_service': 'openai_chat', 'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\", 'comment': '', 'annotations': []}\n",
      "{'id': '048ecdb5-3d1a-4fa7-b46e-fa1aacb34141', 'fragments_version': '0.01', 'instruction': None, 'cot_trigger': None, 'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}', 'prompt_text': '', 'cot': 'False. Woodrow Wilson was a supporter of segregation and racism, but he did not publicly express his opinion on the Plessy v. Ferguson decision. However, he did support the idea of \"separate but equal\" facilities for African Americans, which was the basis of the Plessy v. Ferguson decision.', 'answers': [{'id': '290258cc-f1d1-4352-b8ad-af011e978ba2', 'answer_extraction': 'kojima-yes-no', 'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}', 'answer_extraction_text': '', 'answer': 'not applicable as it is a multiple choice question and the correct answer is False with an explanation.', 'correct_answer': False}], 'author': 'thoughtsource', 'date': '2023/03/11 02:10:44', 'api_service': 'openai_chat', 'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\", 'comment': '', 'annotations': []}\n",
      "{'id': '3d5f2c13-bc5e-47ef-a3c1-3f6618e0b732', 'fragments_version': '0.01', 'instruction': None, 'cot_trigger': None, 'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}', 'prompt_text': '', 'cot': 'B) False', 'answers': [{'id': '8fef491a-25c8-4c7c-9f06-0795a0ae7835', 'answer_extraction': 'kojima-yes-no', 'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}', 'answer_extraction_text': '', 'answer': 'No.', 'correct_answer': False}], 'author': 'thoughtsource', 'date': '2023/03/11 02:11:29', 'api_service': 'openai_chat', 'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\", 'comment': '', 'annotations': []}\n",
      "{'id': '33229f4f-9c73-4832-bac9-7425a7c070e3', 'fragments_version': '0.01', 'instruction': None, 'cot_trigger': None, 'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}', 'prompt_text': '', 'cot': \"I'm sorry, I cannot answer this question as it does not provide enough context or information to understand what is being compared.\", 'answers': [{'id': 'a0c5514f-0e58-4640-ac6e-7a1718d29021', 'answer_extraction': 'kojima-yes-no', 'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}', 'answer_extraction_text': '', 'answer': 'not applicable.', 'correct_answer': False}], 'author': 'thoughtsource', 'date': '2023/03/11 02:22:33', 'api_service': 'openai_chat', 'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\", 'comment': '', 'annotations': []}\n",
      "{'id': 'e875568f-b565-4677-947a-b6cf1cf8f988', 'fragments_version': '0.01', 'instruction': None, 'cot_trigger': None, 'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}', 'prompt_text': '', 'cot': 'B) False. Sound cannot travel through the vacuum of space, so the concert would not be audible outside of the space station.', 'answers': [{'id': '59439895-838f-4cfa-b535-8fa6bca03a54', 'answer_extraction': 'kojima-yes-no', 'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}', 'answer_extraction_text': '', 'answer': 'No.', 'correct_answer': False}], 'author': 'thoughtsource', 'date': '2023/03/11 02:23:15', 'api_service': 'openai_chat', 'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\", 'comment': '', 'annotations': []}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'6/11=0.5454545454545454'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_wrong_cases(chat_col, id_list_3,'strategy_qa','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13/21=0.6190476190476191'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(chat_col, id_list_4,'open_book_qa','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'b8c0a4703079cf661d7261a60a1bcbff',\n",
       " 'ref_id': '',\n",
       " 'question': 'Where would you find magazines along side many other printed works?',\n",
       " 'type': 'multiplechoice',\n",
       " 'choices': ['doctor', 'bookstore', 'market', 'train station', 'mortuary'],\n",
       " 'context': '',\n",
       " 'cot': ['If one wants various printed reading material, they can go to a bookstore.',\n",
       "  'All other options are invalid as they do not have wide range of printed reading material.'],\n",
       " 'answer': ['bookstore'],\n",
       " 'generated_cot': [{'id': '1f6f9395-4241-42b0-9156-13a3c9d5d0f0',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': None,\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': 'B) bookstore',\n",
       "   'answers': [{'id': 'bf2f1626-aba6-4a9e-845c-2169d75a5109',\n",
       "     'answer_extraction': 'kojima-A-E',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'B) bookstore.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'thoughtsource',\n",
       "   'date': '2023/03/11 00:06:02',\n",
       "   'api_service': 'openai_chat',\n",
       "   'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': 'ad874d34-a246-4538-81e4-d2e2bf2425b0',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'kojima-01',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': \"\\n\\nMagazines are typically sold in places where people have time to read and relax, such as waiting rooms or leisure areas. \\n\\nA) Doctor's offices often have magazines in their waiting rooms, but they typically don't have a wide variety of printed works. \\n\\nB) Bookstores are a good option, as they have a wide selection of books, magazines, and other printed works. \\n\\nC) Markets may have some magazines, but they are not typically known for selling printed works. \\n\\nD) Train stations often have newsstands or convenience stores that sell magazines, newspapers, and other printed works. \\n\\nE) Mortuaries are unlikely to have magazines or other printed works available for purchase. \\n\\nTherefore, the best answer is B) bookstore.\",\n",
       "   'answers': [{'id': '757b98f4-387c-40a4-97fb-ebb4608a7125',\n",
       "     'answer_extraction': 'kojima-A-E',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'B) bookstore.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'thoughtsource',\n",
       "   'date': '2023/03/11 00:06:12',\n",
       "   'api_service': 'openai_chat',\n",
       "   'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': 'ceb945c7-d661-4392-924d-9aa568500159',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'zhou-01',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': '\\n\\nStep 1: Identify the keyword in the question. The keyword is \"magazines.\"\\n\\nStep 2: Look at the options provided and eliminate any that are clearly not relevant. Options A, C, and E are unlikely to have magazines alongside other printed works.\\n\\nStep 3: Consider option D, a train station. While train stations may have some printed materials available, they are unlikely to have a wide variety of magazines.\\n\\nStep 4: This leaves us with option B, a bookstore. Bookstores typically have a wide variety of printed materials, including magazines, newspapers, books, and other publications.\\n\\nTherefore, the correct answer is B) bookstore.',\n",
       "   'answers': [{'id': 'ab62357a-9fa6-4bc1-9159-402bf29b835d',\n",
       "     'answer_extraction': 'kojima-A-E',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'B) bookstore.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'thoughtsource',\n",
       "   'date': '2023/03/13 17:10:29',\n",
       "   'api_service': 'openai_chat',\n",
       "   'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': '7ee2aaca-645c-4674-82ff-134fa40f3560',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': 'qa-01',\n",
       "   'cot_trigger': None,\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': \"\\n\\nThe most likely answer to this question is B) bookstore. Here's why:\\n\\n- A) Doctor: While some doctors' offices may have magazines available for patients to read, they typically don't have a wide variety of printed works beyond medical pamphlets and brochures.\\n- B) Bookstore: Bookstores are known for carrying a wide variety of printed works, including books, magazines, newspapers, and more. It's common to find magazines displayed alongside other printed works in a bookstore.\\n- C) Market: Depending on the type of market, there may be some printed works available for sale or distribution, but it's less likely to find a wide variety of magazines alongside other printed works.\\n- D) Train station: Train stations may have newsstands or convenience stores that sell magazines, but they may not have a large selection of other printed works beyond newspapers and travel guides.\\n- E) Mortuary: It's unlikely that a mortuary would have magazines or other printed works available for visitors, as it's not a typical setting for reading materials.\\n\\nTherefore, the most likely place to find magazines alongside many other printed works is a bookstore.\",\n",
       "   'answers': [{'id': '1b433093-11cd-4fdd-a026-24dd7b24b1b8',\n",
       "     'answer_extraction': 'kojima-A-E',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'B) bookstore.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'thoughtsource',\n",
       "   'date': '2023/03/14 14:31:09',\n",
       "   'api_service': 'openai_chat',\n",
       "   'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': '77f21626-6f9c-433e-b2b1-e0716f791791',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'kojima-03',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': 'the most likely answer is B) bookstore, as bookstores typically carry a variety of printed materials including magazines. The other options are less likely to have a selection of magazines available for purchase or reading.',\n",
       "   'answers': [{'id': '413dde6a-324a-45a6-af97-da98a359a60c',\n",
       "     'answer_extraction': 'kojima-A-E',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'B) bookstore.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'thoughtsource',\n",
       "   'date': '2023/03/16 17:26:36',\n",
       "   'api_service': 'openai_chat',\n",
       "   'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': '3d88f9f4-4925-4c57-8c82-60306f9b4a54',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'kojima-09',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': \"\\n\\nThe most likely answer is B) bookstore, as bookstores typically carry a wide variety of printed works, including magazines. Doctors' offices may have magazines in their waiting rooms, but they would not typically have a large selection of other printed works. Markets and train stations may have newsstands that sell magazines, but they would not typically have a wide variety of other printed works. A mortuary would not typically have magazines or other printed works available for customers.\",\n",
       "   'answers': [{'id': 'd410c33b-b6ac-4b5e-95df-fcb8dd8c777a',\n",
       "     'answer_extraction': 'kojima-A-E',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'B) bookstore.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'thoughtsource',\n",
       "   'date': '2023/03/16 18:50:13',\n",
       "   'api_service': 'openai_chat',\n",
       "   'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []}],\n",
       " 'feedback': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll['commonsense_qa']['validation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f27524fac54696a16cf7e3b1cf4775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c5ebf3921941e382c439898c3703db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6827e68593c4801bb8b8f98d0f1b1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a1fecdf5d246da90b7b3e419e6b979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e307761b7ec34837bc9958a0d7799bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotated_set.dump(\"ts_hard_v1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TS_hard v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cot import Collection\n",
    "ts_hard = Collection.from_json('ts_hard_v2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_hard.select_generated_cots(api_service='openai',model='text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '7fd0766c-8322-4b4e-9161-8bd7a27be7ca',\n",
       "  'fragments_version': '0.01',\n",
       "  'instruction': None,\n",
       "  'cot_trigger': None,\n",
       "  'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "  'prompt_text': '',\n",
       "  'cot': '\\nC) Transplacental passage of TSH receptor antibodies',\n",
       "  'answers': [{'id': '3468445f-d4a3-4747-85f6-d4847cfbd5ef',\n",
       "    'answer_extraction': 'kojima-A-E',\n",
       "    'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "    'answer_extraction_text': '',\n",
       "    'answer': \" C. Transplacental passage of TSH receptor antibodies is the most likely cause of the newborn's poor weight gain. This is due to the mother's history of Graves' disease and her near-total thyroidectomy in the second trimester of her pregnancy.\",\n",
       "    'correct_answer': True}],\n",
       "  'author': 'thoughtsource',\n",
       "  'date': '2023/02/15 14:38:43',\n",
       "  'api_service': 'openai',\n",
       "  'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "  'comment': '',\n",
       "  'annotations': []},\n",
       " {'id': '7546dbc4-7e5f-46fd-8ffe-377d080a5b72',\n",
       "  'fragments_version': '0.01',\n",
       "  'instruction': None,\n",
       "  'cot_trigger': 'kojima-01',\n",
       "  'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "  'prompt_text': '',\n",
       "  'cot': \" The patient has poor weight gain since birth, a history of Graves' disease in the mother, and swelling of the neck at the midline. This suggests that the most likely cause is transplacental passage of thyroid peroxidase antibodies (Option B). This is because Graves' disease is an autoimmune disorder caused by the production of antibodies against the thyroid gland, which can be passed from the mother to the baby in utero.\",\n",
       "  'answers': [{'id': '582f6726-e87a-476e-89f9-174d035a6253',\n",
       "    'answer_extraction': 'kojima-A-E',\n",
       "    'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "    'answer_extraction_text': '',\n",
       "    'answer': ' B.',\n",
       "    'correct_answer': False}],\n",
       "  'author': 'thoughtsource',\n",
       "  'date': '2023/02/15 15:49:53',\n",
       "  'api_service': 'openai',\n",
       "  'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "  'comment': '',\n",
       "  'annotations': [{'author': 'Matthias',\n",
       "    'date': '2023-03-20',\n",
       "    'key': 'preferred',\n",
       "    'value': 'True'}]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_hard['med_qa']['test'][0]['generated_cot']\n",
    "#trigger: kojima-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'open_book_qa': {'test': {'accuracy': {'gpt-4': {'None_None_kojima-A-D': 0.809524,\n",
       "     'None_zhou-01_kojima-A-D': 0.904762}}}},\n",
       " 'strategy_qa': {'train': {'accuracy': {'gpt-4': {'None_None_kojima-yes-no': 0.545455,\n",
       "     'None_zhou-01_kojima-yes-no': 0.727273}}}},\n",
       " 'worldtree': {'test': {'accuracy': {'gpt-4': {'None_None_kojima-A-D': 1.0,\n",
       "     'None_zhou-01_kojima-A-D': 1.0}}}},\n",
       " 'commonsense_qa': {'validation': {'accuracy': {'gpt-4': {'None_None_kojima-A-E': 0.666667,\n",
       "     'None_zhou-01_kojima-A-E': 0.666667}}}},\n",
       " 'med_qa': {'test': {'accuracy': {'gpt-4': {'None_None_kojima-A-E': 0.6,\n",
       "     'None_zhou-01_kojima-A-E': 0.5}}}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_hard.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'open_book_qa': {'test': {'accuracy': {'gpt-3.5-turbo': {'None_kojima-01_kojima-A-D': 0.714286}}}},\n",
       " 'strategy_qa': {'train': {'accuracy': {'gpt-3.5-turbo': {'None_kojima-01_kojima-yes-no': 0.545455}}}},\n",
       " 'worldtree': {'test': {'accuracy': {'gpt-3.5-turbo': {'None_kojima-01_kojima-A-D': 0.857143}}}},\n",
       " 'commonsense_qa': {'validation': {'accuracy': {'gpt-3.5-turbo': {'None_kojima-01_kojima-A-E': 0.416667}}}},\n",
       " 'med_qa': {'test': {'accuracy': {'gpt-3.5-turbo': {'None_kojima-01_kojima-A-E': 0.4}}}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cot import Collection\n",
    "ts_hard = Collection.from_json('ts_hard_v2.json')\n",
    "ts_hard.select_generated_cots(api_service='openai_chat',model = 'gpt-3.5-turbo',cot_trigger='kojima-01')\n",
    "ts_hard.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TS_Hard_chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/robertpraas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from cot import Collection\n",
    "coll = Collection.load_thoughtsource_100(load_pregenerated_cots=True)\n",
    "coll.select_generated_cots(cot_trigger = 'kojima-01',api_service='openai_chat',model = 'gpt-3.5-turbo')\n",
    "coll.select_generated_cots(answer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll.dump('chat_hard_clean.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll = Collection.load_thoughtsource_100(load_pregenerated_cots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not convert 'false' with type str: tried to convert to boolean",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/datasets/arrow_writer.py:187\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    186\u001b[0m     trying_cast_to_python_objects \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m     out \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49marray(cast_to_python_objects(data, only_1d_for_numpy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m    188\u001b[0m \u001b[39m# use smaller integer precisions if possible\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyarrow/array.pxi:316\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyarrow/array.pxi:39\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Could not convert 'false' with type str: tried to convert to boolean",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/robertpraas/Desktop/ThoughtSource/notebooks/challenging_dataset_creation.ipynb Cell 58\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robertpraas/Desktop/ThoughtSource/notebooks/challenging_dataset_creation.ipynb#Y112sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#retrieve annotated:\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/robertpraas/Desktop/ThoughtSource/notebooks/challenging_dataset_creation.ipynb#Y112sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m coll \u001b[39m=\u001b[39m Collection\u001b[39m.\u001b[39;49mfrom_json(\u001b[39m\"\u001b[39;49m\u001b[39mchat_hard.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/ThoughtSource/libs/cot/cot/dataloader.py:290\u001b[0m, in \u001b[0;36mCollection.from_json\u001b[0;34m(path_or_json, download_mode, source)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m dic:\n\u001b[1;32m    288\u001b[0m                 \u001b[39mdel\u001b[39;00m dic[key]\n\u001b[0;32m--> 290\u001b[0m         dataset_dict[split_name] \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mfrom_dict(dic, info\u001b[39m.\u001b[39;49mfeatures, info, split)\n\u001b[1;32m    291\u001b[0m     collection[dataset_name] \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mDatasetDict(dataset_dict)\n\u001b[1;32m    292\u001b[0m \u001b[39mreturn\u001b[39;00m collection\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py:822\u001b[0m, in \u001b[0;36mDataset.from_dict\u001b[0;34m(cls, mapping, features, info, split)\u001b[0m\n\u001b[1;32m    817\u001b[0m     mapping \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mencode_batch(mapping)\n\u001b[1;32m    818\u001b[0m mapping \u001b[39m=\u001b[39m {\n\u001b[1;32m    819\u001b[0m     col: OptimizedTypedSequence(data, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mfeatures[col] \u001b[39mif\u001b[39;00m features \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, col\u001b[39m=\u001b[39mcol)\n\u001b[1;32m    820\u001b[0m     \u001b[39mfor\u001b[39;00m col, data \u001b[39min\u001b[39;00m mapping\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    821\u001b[0m }\n\u001b[0;32m--> 822\u001b[0m pa_table \u001b[39m=\u001b[39m InMemoryTable\u001b[39m.\u001b[39;49mfrom_pydict(mapping\u001b[39m=\u001b[39;49mmapping)\n\u001b[1;32m    823\u001b[0m \u001b[39mif\u001b[39;00m info\u001b[39m.\u001b[39mfeatures \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    824\u001b[0m     info\u001b[39m.\u001b[39mfeatures \u001b[39m=\u001b[39m Features({col: ts\u001b[39m.\u001b[39mget_inferred_type() \u001b[39mfor\u001b[39;00m col, ts \u001b[39min\u001b[39;00m mapping\u001b[39m.\u001b[39mitems()})\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/datasets/table.py:749\u001b[0m, in \u001b[0;36mInMemoryTable.from_pydict\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    734\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pydict\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    735\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \u001b[39m    Construct a Table from Arrow arrays or columns\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39m        :class:`datasets.table.Table`:\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 749\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(pa\u001b[39m.\u001b[39;49mTable\u001b[39m.\u001b[39;49mfrom_pydict(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyarrow/table.pxi:3625\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pydict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyarrow/table.pxi:5150\u001b[0m, in \u001b[0;36mpyarrow.lib._from_pydict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyarrow/array.pxi:342\u001b[0m, in \u001b[0;36mpyarrow.lib.asarray\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyarrow/array.pxi:230\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyarrow/array.pxi:110\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/datasets/arrow_writer.py:243\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m    242\u001b[0m \u001b[39melif\u001b[39;00m trying_cast_to_python_objects \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mCould not convert\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n\u001b[0;32m--> 243\u001b[0m     out \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49marray(cast_to_python_objects(data, only_1d_for_numpy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, optimize_list_casting\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m))\n\u001b[1;32m    244\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m         out \u001b[39m=\u001b[39m cast_array_to_feature(out, \u001b[39mtype\u001b[39m, allow_number_to_str\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyarrow/array.pxi:316\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyarrow/array.pxi:39\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Could not convert 'false' with type str: tried to convert to boolean"
     ]
    }
   ],
   "source": [
    "#retrieve annotated:\n",
    "\n",
    "coll = Collection.from_json(\"chat_hard.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in coll['med_qa']['test']:\n",
    "    if len(element['generated_cot'])>0:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/robertpraas/Desktop/ThoughtSource/notebooks/challenging_dataset_creation.ipynb Cell 59\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/robertpraas/Desktop/ThoughtSource/notebooks/challenging_dataset_creation.ipynb#Y110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m coll[\u001b[39m'\u001b[39;49m\u001b[39mcommonsense_qa\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mvalidation\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m20\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mgenerated_cot\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcorrect_answer\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "coll['commonsense_qa']['validation'][20]['generated_cot'][0][\"answers\"][0][\"correct_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT multiple ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name           | Train   | Valid   | Test   |\n",
       "|----------------|---------|---------|--------|\n",
       "| commonsense_qa | -       | 7       | -      |\n",
       "| med_qa         | -       | -       | 3      |\n",
       "| medmc_qa       | -       | 100     | -      |\n",
       "| open_book_qa   | -       | -       | 4      |\n",
       "| strategy_qa    | 0       | -       | -      |\n",
       "| worldtree      | -       | -       | 0      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'entailment_bank', 'gsm8k', 'mawps', 'pubmed_qa', 'qed', 'svamp']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cot import Collection\n",
    "ann_5 = Collection.from_json(\"chat_hard_multiple_ans.json\")\n",
    "ann_5['open_book_qa']['test'] = ann_5['open_book_qa']['test'].select(select_annotated('open_book_qa','test',ann_5))\n",
    "ann_5['strategy_qa']['train'] = ann_5['strategy_qa']['train'].select(select_annotated('strategy_qa','train',ann_5))\n",
    "ann_5['worldtree']['test'] = ann_5['worldtree']['test'].select(select_annotated('worldtree','test',ann_5))\n",
    "ann_5['commonsense_qa']['validation'] = ann_5['commonsense_qa']['validation'].select(select_annotated('commonsense_qa','validation',ann_5))\n",
    "ann_5['med_qa']['test'] = ann_5['med_qa']['test'].select(select_annotated('med_qa','test',ann_5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name           | Train   | Valid   | Test   |\n",
       "|----------------|---------|---------|--------|\n",
       "| commonsense_qa | -       | 7       | -      |\n",
       "| med_qa         | -       | -       | 3      |\n",
       "| open_book_qa   | -       | -       | 4      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'entailment_bank', 'gsm8k', 'mawps', 'medmc_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp', 'worldtree']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_5.unload_datasets(['medmc_qa','strategy_qa','worldtree'])\n",
    "ann_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a673d99ca143ae8cd154aeecde29a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2155a9bb879643449326642e8f574a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b00e14aba774f0f8877da3f17da34bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann_5.dump(\"clean_chat_hard_multiple_ans.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
