{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate \n",
    "from langchain.chains.llm import LLMChain\n",
    "from cot import Collection\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CoT Chain\"\"\"\n",
    "\n",
    "llm = OpenAI(temperature=.0,model_name=\"ada\") #for chat: gpt-3.5-turbo\n",
    "\n",
    "\n",
    "template = \"\"\"{instruction}\n",
    "\n",
    "Question: {question}\n",
    "Answer_choices: {answer_choices}\n",
    "\n",
    "{cot_trigger}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\"], template=template)\n",
    "cot_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"cot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"answer extraction chain\"\"\"\n",
    "\n",
    "extraction_template = \"\"\"{instruction}\n",
    "\n",
    "Question: {question}\n",
    "Answer_choices: {answer_choices}\n",
    "\n",
    "Cot: {cot_trigger}{cot}\n",
    "{answer_extraction}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\"], template=extraction_template)\n",
    "answer_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"predicted_answer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CoT-Ans_extraction chain\"\"\"\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "overall_chain = SequentialChain(chains=[cot_chain, answer_chain],\n",
    "                                input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"answer_extraction\"],\n",
    "                                output_variables=[\"cot\", \"predicted_answer\"],\n",
    "                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading worldtree...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Generate CoT with use of TS-schema\"\"\"\n",
    "#compare with config used before; what about max tokens?\n",
    "#config contains what the chain needs\n",
    "input_dict = {\n",
    "    \"instruction\": \"Be faithful and a little hopeful\",\n",
    "    \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "    \"answer_extraction\": \"Therefore, among A through D, the answer is\" \n",
    "}\n",
    "\n",
    "worldtree = Collection([\"worldtree\"], verbose=False)\n",
    "worldtree_1 = worldtree.select(split=\"train\", number_samples=1, random_samples=True, seed=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating worldtree...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "processed_example:\n",
      "{'id': '1577', 'ref_id': '', 'question': 'A parent and a child share several characteristics. Both individuals are tall, have curly hair, are good cooks, and have freckles. Which of these characteristics is a learned behavior?', 'type': 'multiplechoice', 'choices': ['being tall', 'having curly hair', 'being a good cook', 'having freckles'], 'context': '', 'cot': ['Skills are learned characteristics.', 'A behavior is a kind of characteristic.', 'Cooking is a kind of skill for preparing food.'], 'answer': ['being a good cook'], 'generated_cot': [{'id': '0f5c6874-5187-4e5d-b645-16a941f2e40f', 'fragments_version': '0.01', 'instruction': 'Be faithful and a little hopeful', 'cot_trigger': \"Answer: Let's think step by step.\", 'cot_trigger_template': '', 'prompt_text': '', 'cot': '\\n1. A) is a learned behavior.\\n\\n2. B) is a learned behavior.\\n\\n3. C) is a learned behavior.\\n\\n4. D) is a learned behavior.\\n\\n5. E) is a learned behavior.\\n\\n6. F) is a learned behavior.\\n\\n7. G) is a learned behavior.\\n\\n8. H) is a learned behavior.\\n\\n9. I) is a learned behavior.\\n\\n10. J) is a learned behavior.\\n\\n11. K) is a learned behavior.\\n\\n12. L) is a learned behavior.\\n\\n13. M) is a learned behavior.\\n\\n14. N) is a learned behavior.\\n\\n15. O) is a learned behavior.\\n\\n16. P) is a learned behavior.\\n\\n17. Q) is a learned behavior.\\n\\n18. R) is a learned behavior.\\n\\n19. S) is a learned behavior.\\n\\n20. T) is a learned behavior.\\n\\n21. U) is a learned behavior.\\n\\n22. V) is a learned behavior.\\n\\n23. W) is a learned behavior.\\n\\n24.', 'answers': [{'id': 'c5710cb5-a07e-4b73-a412-33fdec4d6926', 'answer_extraction': 'Therefore, among A through D, the answer is', 'answer_extraction_template': '', 'answer_extraction_text': '', 'answer': '\\nA) is a learned behavior.\\n\\nB) is a learned behavior.\\n\\nC) is a learned behavior.\\n\\nD) is a learned behavior.\\n\\nE) is a learned behavior.\\n\\nF) is a learned behavior.\\n\\nG) is a learned behavior.\\n\\nH) is a learned behavior.\\n\\nI) is a learned behavior.\\n\\nJ) is a learned behavior.\\n\\nK) is a learned behavior.\\n\\nL) is a learned behavior.\\n\\nM) is a learned behavior.\\n\\nN) is a learned behavior.\\n\\nO) is a learned behavior.\\n\\nP) is a learned behavior.\\n\\nQ) is a learned behavior.\\n\\nR) is a learned behavior.\\n\\nS) is a learned behavior.\\n\\nT) is a learned behavior.\\n\\nU) is a learned behavior.\\n\\nV) is a learned behavior.\\n\\nW) is a learned behavior.\\n\\nTherefore, among A through F, the answer is\\n\\nA) is a learned behavior.\\n\\nB) is a learned behavior.\\n\\nC) is a learned behavior.\\n\\nD) is a learned behavior.\\n\\n', 'correct_answer': None}], 'author': '', 'date': '2023/03/10 13:30:23', 'api_service': '', 'model': \"{'name': '', 'temperature': 0, 'max_tokens': 800}\", 'comment': '', 'annotations': []}], 'feedback': []}\n"
     ]
    }
   ],
   "source": [
    "test = worldtree_1.generate_extract_flexibly(chain=overall_chain,input_dict=input_dict)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#worldtree_1['worldtree']['train'][0]\n",
    "worldtree_new = {'worldtree':{'train':test}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and collect a json to make collection\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    json.dump(worldtree_new, outfile)\n",
    "collect = Collection.from_json('sample.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name      |   Train | Valid   | Test   |\n",
       "|-----------|---------|---------|--------|\n",
       "| worldtree |       1 | -       | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate or extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate CoT with use of TS-schema\"\"\"\n",
    "#compare with config used before; what about max tokens?\n",
    "#config contains what the chain needs\n",
    "input_dict = {\n",
    "    \"instruction\": \"Be faithful and a little hopeful\",\n",
    "    \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "    \"answer_extraction\": \"Therefore, among A through D, the answer is\" \n",
    "}\n",
    "cot_dataset = Collection.from_json(\"worldtree_10.json\") #input dataset\n",
    "cot_dataset = cot_dataset.select(split=\"train\", number_samples=1, random_samples=True, seed=0)\n",
    "\n",
    "\n",
    "extract = cot_dataset.extract_flexible(chain=answer_chain,input_dict=input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading worldtree...\n",
      "Generating worldtree...\n",
      "processed_example:\n",
      "{'id': '1577', 'ref_id': '', 'question': 'A parent and a child share several characteristics. Both individuals are tall, have curly hair, are good cooks, and have freckles. Which of these characteristics is a learned behavior?', 'type': 'multiplechoice', 'choices': ['being tall', 'having curly hair', 'being a good cook', 'having freckles'], 'context': '', 'cot': ['Skills are learned characteristics.', 'A behavior is a kind of characteristic.', 'Cooking is a kind of skill for preparing food.'], 'answer': ['being a good cook'], 'generated_cot': [{'id': '7622c1a5-c03b-444f-9847-ef1a6fe3a7d1', 'fragments_version': '0.01', 'instruction': 'Be faithful and a little hopeful', 'cot_trigger': \"Answer: Let's think step by step.\", 'cot_trigger_template': '', 'prompt_text': '', 'cot': '\\n1. A) is a learned behavior.\\n\\n2. B) is a learned behavior.\\n\\n3. C) is a learned behavior.\\n\\n4. D) is a learned behavior.\\n\\n5. E) is a learned behavior.\\n\\n6. F) is a learned behavior.\\n\\n7. G) is a learned behavior.\\n\\n8. H) is a learned behavior.\\n\\n9. I) is a learned behavior.\\n\\n10. J) is a learned behavior.\\n\\n11. K) is a learned behavior.\\n\\n12. L) is a learned behavior.\\n\\n13. M) is a learned behavior.\\n\\n14. N) is a learned behavior.\\n\\n15. O) is a learned behavior.\\n\\n16. P) is a learned behavior.\\n\\n17. Q) is a learned behavior.\\n\\n18. R) is a learned behavior.\\n\\n19. S) is a learned behavior.\\n\\n20. T) is a learned behavior.\\n\\n21. U) is a learned behavior.\\n\\n22. V) is a learned behavior.\\n\\n23. W) is a learned behavior.\\n\\n24.', 'answers': [], 'author': '', 'date': '2023/03/10 16:56:50', 'api_service': '', 'model': \"{'name': '', 'temperature': 0, 'max_tokens': 800}\", 'comment': '', 'annotations': []}], 'feedback': []}\n"
     ]
    }
   ],
   "source": [
    "input_dict = {\n",
    "    \"instruction\": \"Be faithful and a little hopeful\",\n",
    "    \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "    \"answer_extraction\": \"Therefore, among A through D, the answer is\" \n",
    "}\n",
    "worldtree = Collection([\"worldtree\"], verbose=False)\n",
    "worldtree_1 = worldtree.select(split=\"train\", number_samples=1, random_samples=True, seed=0)\n",
    "\n",
    "generate_only = extract = worldtree_1.generate_flexible(chain=cot_chain,input_dict=input_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflect_template = \"\"\"\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    Cot: {cot_trigger}{cot}\n",
    "    {answer_extraction}\n",
    "    Answer: {answer}\n",
    "    \n",
    "    {reflection_prompt}\n",
    "    \"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\",'answer','reflection_prompt'], template=reflect_template)\n",
    "cot_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"reflection\")\n",
    "\n",
    "extraction_template = \"\"\"{instruction}\n",
    "\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    Cot: {cot_trigger}{cot}\n",
    "    {answer_extraction}{answer}\n",
    "    {reflection_prompt}\n",
    "    \n",
    "    {reflect_answer_extraction}\n",
    "    \"\"\"\n",
    "    #Get reflection\n",
    "prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\",'answer','reflection_prompt','reflect_answer_extraction'], template=extraction_template)\n",
    "answer_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"reflection_answer\")\n",
    "\n",
    "    # This is the overall chain where we run these two chains in sequence.\n",
    "from langchain.chains import SequentialChain\n",
    "reflect_overall_chain = SequentialChain(chains=[cot_chain, answer_chain],input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"answer_extraction\",'cot','answer','reflection_prompt','reflect_answer_extraction'],\n",
    "        output_variables=[\"reflection\", \"reflection_answer\"],\n",
    "        verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating worldtree...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/wq/slcg80w1143270jpznm3k9hm0000gn/T/ipykernel_2435/4289028613.py\", line 11, in <cell line: 11>\n",
      "    metareason= worldtree_1.metareason_flexible(chain=reflect_overall_chain,input_dict=input_dict)\n",
      "  File \"/Users/robertpraas/Desktop/ThoughtSource/libs/cot/cot/dataloader.py\", line 370, in metareason_flexible\n",
      "    return self_reason(self[name], chain, input_dict)\n",
      "  File \"/Users/robertpraas/Desktop/ThoughtSource/libs/cot/cot/new_generate.py\", line 212, in self_reason\n",
      "    processed_example = _self_reason(example,input_dict,chain)\n",
      "  File \"/Users/robertpraas/Desktop/ThoughtSource/libs/cot/cot/new_generate.py\", line 236, in _self_reason\n",
      "    answer[\"answer\"] = lang_chain['predicted_answer']\n",
      "KeyError: 'predicted_answer'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 1982, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "#check for what is already in item\n",
    "input_dict = {\n",
    "    'cot_trigger':\"\", \n",
    "    'answer':\"\", \n",
    "    'answer_extraction': \"\", \n",
    "    'cot': \"\", \n",
    "    'instruction': \"\",\n",
    "    'reflection_prompt':\"Double check this\",\n",
    "    'reflect_answer_extraction':'Based on the reflection, what is the definite answer?'\n",
    "}\n",
    "metareason= worldtree_1.metareason_flexible(chain=reflect_overall_chain,input_dict=input_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervision = \"Double check this idea, are the reasoning and answer sound yes/no?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data:\n",
    "instruction = \"Answer the following question through step-by-step reasoning.\"\n",
    "question = \"Animals may fight, make threatening sounds, and act aggressively toward members of the same species. These behaviors usually occur as the result of\",\n",
    "answer_choices = [\n",
    "                    \"competition\",\n",
    "                    \"conservation\",\n",
    "                    \"decomposition\",\n",
    "                    \"pollution\"\n",
    "                ]\n",
    "cot_trigger = \"Answer: Let's think step by step.\"\n",
    "answer_extraction = \"Therefore, the answer is\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate \n",
    "from langchain.chains.llm import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cot import Collection\n",
    "from cot.generate import FRAGMENTS\n",
    "from rich.pretty import pprint\n",
    "import json\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate \n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "\"\"\"From collection to changed collection\"\"\"\n",
    "def cot_to_context(example):\n",
    "    example['context'] = example['generated_cot'][0]['cot']\n",
    "    example ['generated_cot'] = list()\n",
    "    return example\n",
    "\n",
    "def main(data_dict,instruction,answer_extraction,cot_trigger):\n",
    "    var_dataset = {\"instruction\":instruction,\"answer_extraction\":answer_extraction,\"cot_trigger\":cot_trigger} # \"cot_trigger\":cot_trigger,\n",
    "    cot_in_context = data_dict.map(cot_to_context)\n",
    "    final = cot_in_context.map(generate_cot,fn_kwargs = var_dataset) #\n",
    "    return final\n",
    "\n",
    "def generate_cot(item,instruction,answer_extraction,cot_trigger):\n",
    "\n",
    "    llm = OpenAI(temperature=.0)\n",
    "    template = \"\"\"{instruction}\n",
    "\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    {cot_trigger}\n",
    "    \"\"\"\n",
    "    prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\"], template=template)\n",
    "    cot_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"cot\")\n",
    "\n",
    "    \"\"\"This chain tries answer extraction and supervision at once\"\"\"\n",
    "    extraction_template = \"\"\"{instruction}\n",
    "\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    Cot: {cot_trigger}{cot}\n",
    "    {answer_extraction}\n",
    "    \"\"\"\n",
    "    prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\"], template=extraction_template)\n",
    "    answer_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"answer\")\n",
    "\n",
    "    # This is the overall chain where we run these two chains in sequence.\n",
    "    from langchain.chains import SequentialChain\n",
    "    overall_chain = SequentialChain(chains=[cot_chain, answer_chain],input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"answer_extraction\"],\n",
    "    # overall_chain = SequentialChain(chains=[cot_chain, supervision_chain],input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",'cot',\"answer_extraction\",\"supervision\"],\n",
    "        # Here we return multiple variables\n",
    "        output_variables=[\"cot\", \"answer\"],\n",
    "        verbose=True)\n",
    "    answer_cot = overall_chain({\"instruction\":instruction,\"question\":item['question'],\"answer_choices\":item['choices'],\"cot_trigger\":cot_trigger,\"answer_extraction\":answer_extraction})\n",
    "    # item['generated_cot']['cot'] = answer_cot['cot']\n",
    "    # item['generated_cot']['answers']['answer'] = answer_cot['answer']\n",
    "    # generated_cot[\"cot\"] = cot\n",
    "    # generated_cot[\"date\"] = print_now(1)\n",
    "    # answer[\"answer\"] = predicted_answer\n",
    "    # generated_cot[\"answers\"].append(answer)\n",
    "    # item[\"generated_cot\"].append(generated_cot)\n",
    "\n",
    "    return answer_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reflection template has new instruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reflection(item, cot_chain, reflection_prompt,reflect_answer_extraction):\n",
    "    llm = OpenAI(temperature=.0)\n",
    "    reflect_template = \"\"\"\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    Cot: {cot_trigger}{cot}\n",
    "    {answer_extraction}\n",
    "    Answer: {answer}\n",
    "    \n",
    "    {reflection_prompt}\n",
    "    \"\"\"\n",
    "    prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\",'answer','reflection_prompt'], template=reflect_template)\n",
    "    cot_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"reflection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cot_dataset = Collection.from_json(\"worldtree_10.json\") #input dataset\n",
    "cot_dataset = cot_dataset.select(split=\"train\", number_samples=1, random_samples=True, seed=0) #input # samples,seed\n",
    "cot_dataset = cot_dataset['worldtree']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1722',\n",
       " 'ref_id': '',\n",
       " 'question': 'Sharpening a pencil and tearing paper are examples of physical changes. Which statement describes why these are physical changes?',\n",
       " 'type': 'multiplechoice',\n",
       " 'choices': ['There is a change in how the objects are used.',\n",
       "  'There is a change in the appearance of the objects.',\n",
       "  'There is a change in the materials from which the objects are made.',\n",
       "  'There is a change in both the appearance of the objects and the materials from which they are made.'],\n",
       " 'context': '',\n",
       " 'cot': ['Shape is a property of the appearance of an object.',\n",
       "  'If something undergoes physical change then the chemical properties of that something will remain unchanged.',\n",
       "  'Material composition is a kind of chemical property.',\n",
       "  'Changed is the opposite of unchanged.',\n",
       "  'Composed of means made of.',\n",
       "  'If something undergoes a physical change then the physical properties of that something will change.',\n",
       "  'Appearance is a kind of physical property.',\n",
       "  'Sharpening an object causes that object to change shape.',\n",
       "  'A pencil is a kind of object.',\n",
       "  \"Tearing an object changes that object 's shape.\",\n",
       "  'A paper is a kind of object.'],\n",
       " 'answer': ['There is a change in the appearance of the objects.'],\n",
       " 'generated_cot': [{'id': '8a1b6bdc-4c0a-4a93-be8e-46ff33b8aa31',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'kojima-01',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': ' When you sharpen a pencil, the appearance of the pencil changes, but the materials from which it is made remain the same. When you tear paper, the appearance of the paper changes, but the materials from which it is made remain the same. Therefore, the correct answer is B) There is a change in the appearance of the objects.',\n",
       "   'answers': [{'id': '1a4ad0a8-54f8-4632-8bea-55946b4f33dd',\n",
       "     'answer_extraction': 'kojima-A-D',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': ' B.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'your_name',\n",
       "   'date': '2023/01/27 18:22:27',\n",
       "   'api_service': 'openai',\n",
       "   'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': '5be675fe-e1cc-4902-8887-3fcb6b9c1351',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'kojima-02',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': ' Sharpening a pencil and tearing paper are physical changes because they involve a change in the appearance of the objects. Therefore, the correct answer is B) There is a change in the appearance of the objects.',\n",
       "   'answers': [{'id': 'e9380525-1b69-4b67-9890-62d14126b23f',\n",
       "     'answer_extraction': 'kojima-A-D',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': ' B.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'your_name',\n",
       "   'date': '2023/01/27 18:22:33',\n",
       "   'api_service': 'openai',\n",
       "   'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': 'a8d3e8ff-4b3f-442a-8e97-b34848274649',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'kojima-03',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': ' B) There is a change in the appearance of the objects.',\n",
       "   'answers': [{'id': '3e854465-4073-4eb7-ad15-d8568c6cdc62',\n",
       "     'answer_extraction': 'kojima-A-D',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': ' B.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'your_name',\n",
       "   'date': '2023/01/27 18:22:36',\n",
       "   'api_service': 'openai',\n",
       "   'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []}],\n",
       " 'feedback': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = OpenAI(temperature=.0,model_name=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instruction = \"Answer the following question through step-by-step reasoning.\"\n",
    "#test = generate_cot(cot_dataset['train'],instruction,answer_extraction,cot_trigger)\n",
    "llm = OpenAI(temperature=.0)\n",
    "reflect_template = \"\"\"\n",
    "Question: {question}\n",
    "Answer_choices: {answer_choices}\n",
    "\n",
    "Cot: {cot_trigger}{cot}\n",
    "{answer_extraction}\n",
    "Answer: {answer}\n",
    "\n",
    "{reflection_prompt}\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\",'answer','reflection_prompt'], template=reflect_template)\n",
    "cot_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"reflection\")\n",
    "cot_chain.run()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cot_trigger = \"Answer: Let's think step by step.\"\n",
    "answer_extraction = \"Therefore, the answer is\"\n",
    "reflection_prompt = 'Do you think the Answer is really the correct answer?' #try with {answer}\n",
    "\n",
    "\n",
    "\n",
    "gen_test = generate_reflection(cot_dataset['train'],cot_chain,reflection_prompt, reflect_answer_extraction)\n",
    "\n",
    "item, cot_chain, reflection_prompt,reflect_answer_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \"\"\"This chain tries answer extraction and supervision at once\"\"\"\n",
    "    extraction_template = \"\"\"{instruction}\n",
    "\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    Cot: {cot_trigger}{cot}\n",
    "    {answer_extraction}{answer}\n",
    "    {reflection_prompt}\n",
    "    \n",
    "    {reflect_answer_extraction}\n",
    "    \"\"\"\n",
    "    #Get reflection\n",
    "    prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\",'answer','reflection_prompt','reflect_answer_extraction'], template=extraction_template)\n",
    "    answer_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"reflection_answer\")\n",
    "\n",
    "    # This is the overall chain where we run these two chains in sequence.\n",
    "    from langchain.chains import SequentialChain\n",
    "    overall_chain = SequentialChain(chains=[cot_chain, answer_chain],input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"answer_extraction\",'cot','answer'],\n",
    "\n",
    "        output_variables=[\"reflection\", \"reflection_answer\"],\n",
    "        verbose=True)\n",
    "    answer_cot = overall_chain({\"instruction\":instruction,\"question\":item['question'],\"answer_choices\":item['choices'],\"cot_trigger\":cot_trigger,\"answer_extraction\":answer_extraction})\n",
    "\n",
    "\n",
    "    return answer_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cot_dataset = Collection.from_json(\"worldtree_10.json\") #input dataset\n",
    "cot_dataset = cot_dataset.select(split=\"train\", number_samples=1, random_samples=True, seed=0) #input # samples,seed\n",
    "cot_dataset = cot_dataset['worldtree']\n",
    "\n",
    "instruction = \"Answer the following question through step-by-step reasoning.\"\n",
    "cot_trigger = \"Answer: Let's think step by step.\"\n",
    "answer_extraction = \"Therefore, the answer is\"\n",
    "\n",
    "test = generate_cot(cot_dataset['train'],instruction,answer_extraction,cot_trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Answer the following question through step-by-step reasoning.',\n",
       " 'question': ['Sharpening a pencil and tearing paper are examples of physical changes. Which statement describes why these are physical changes?'],\n",
       " 'answer_choices': [['There is a change in how the objects are used.',\n",
       "   'There is a change in the appearance of the objects.',\n",
       "   'There is a change in the materials from which the objects are made.',\n",
       "   'There is a change in both the appearance of the objects and the materials from which they are made.']],\n",
       " 'cot_trigger': \"Answer: Let's think step by step.\",\n",
       " 'answer_extraction': 'Therefore, the answer is',\n",
       " 'cot': '\\n    Step 1: Physical changes involve a change in the physical properties of an object.\\n    \\n    Step 2: Sharpening a pencil involves a change in the shape of the pencil, while tearing paper involves a change in the shape of the paper.\\n    \\n    Step 3: Therefore, these are physical changes because there is a change in the appearance of the objects.',\n",
       " 'answer': \"\\n    'There is a change in the appearance of the objects.'\"}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test\n",
    "test['cot']\n",
    "test['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '8a1b6bdc-4c0a-4a93-be8e-46ff33b8aa31',\n",
       "  'fragments_version': '0.01',\n",
       "  'instruction': None,\n",
       "  'cot_trigger': 'kojima-01',\n",
       "  'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "  'prompt_text': '',\n",
       "  'cot': ' When you sharpen a pencil, the appearance of the pencil changes, but the materials from which it is made remain the same. When you tear paper, the appearance of the paper changes, but the materials from which it is made remain the same. Therefore, the correct answer is B) There is a change in the appearance of the objects.',\n",
       "  'answers': [{'id': '1a4ad0a8-54f8-4632-8bea-55946b4f33dd',\n",
       "    'answer_extraction': 'kojima-A-D',\n",
       "    'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "    'answer_extraction_text': '',\n",
       "    'answer': ' B.',\n",
       "    'correct_answer': True}],\n",
       "  'author': 'your_name',\n",
       "  'date': '2023/01/27 18:22:27',\n",
       "  'api_service': 'openai',\n",
       "  'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "  'comment': '',\n",
       "  'annotations': []},\n",
       " {'id': '5be675fe-e1cc-4902-8887-3fcb6b9c1351',\n",
       "  'fragments_version': '0.01',\n",
       "  'instruction': None,\n",
       "  'cot_trigger': 'kojima-02',\n",
       "  'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "  'prompt_text': '',\n",
       "  'cot': ' Sharpening a pencil and tearing paper are physical changes because they involve a change in the appearance of the objects. Therefore, the correct answer is B) There is a change in the appearance of the objects.',\n",
       "  'answers': [{'id': 'e9380525-1b69-4b67-9890-62d14126b23f',\n",
       "    'answer_extraction': 'kojima-A-D',\n",
       "    'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "    'answer_extraction_text': '',\n",
       "    'answer': ' B.',\n",
       "    'correct_answer': True}],\n",
       "  'author': 'your_name',\n",
       "  'date': '2023/01/27 18:22:33',\n",
       "  'api_service': 'openai',\n",
       "  'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "  'comment': '',\n",
       "  'annotations': []},\n",
       " {'id': 'a8d3e8ff-4b3f-442a-8e97-b34848274649',\n",
       "  'fragments_version': '0.01',\n",
       "  'instruction': None,\n",
       "  'cot_trigger': 'kojima-03',\n",
       "  'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "  'prompt_text': '',\n",
       "  'cot': ' B) There is a change in the appearance of the objects.',\n",
       "  'answers': [{'id': '3e854465-4073-4eb7-ad15-d8568c6cdc62',\n",
       "    'answer_extraction': 'kojima-A-D',\n",
       "    'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "    'answer_extraction_text': '',\n",
       "    'answer': ' B.',\n",
       "    'correct_answer': True}],\n",
       "  'author': 'your_name',\n",
       "  'date': '2023/01/27 18:22:36',\n",
       "  'api_service': 'openai',\n",
       "  'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "  'comment': '',\n",
       "  'annotations': []}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_dataset['train'][0]['generated_cot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to thoughtsource"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Upgrades\"\"\"\n",
    "#langchain.__version__ #old 0.0.14\n",
    "#!pip install --upgrade langchain #langchain-0.0.92\n",
    "#!pip install -U openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset manipulation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cot import Collection\n",
    "from cot.generate import FRAGMENTS\n",
    "from rich.pretty import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcab79a997e049038ffc7bfc348c4829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"From collection to changed collection\"\"\"\n",
    "def cot_to_context(example):\n",
    "    example['context'] = example['generated_cot'][0]['cot']\n",
    "    example ['generated_cot'] = list()\n",
    "    return example\n",
    "\n",
    "cot_dataset = Collection.from_json(\"worldtree_10.json\") #input dataset\n",
    "cot_dataset = cot_dataset.select(split=\"train\", number_samples=1, random_samples=True, seed=0)\n",
    "updated_dataset = cot_dataset['worldtree'].map(cot_to_context) #input dataset name\n",
    "\n",
    "#force dataset into the right format\n",
    "dataset = {\"train\":[updated_dataset['train'][0]]}\n",
    "dict_dataset = {\"worldtree\":dataset} \n",
    "\n",
    "#create and collect a json to make collection\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    json.dump(dict_dataset, outfile)\n",
    "collect = Collection.from_json('sample.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name      |   Train | Valid   | Test   |\n",
       "|-----------|---------|---------|--------|\n",
       "| worldtree |       1 | -       | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1722',\n",
       " 'ref_id': '',\n",
       " 'question': 'Sharpening a pencil and tearing paper are examples of physical changes. Which statement describes why these are physical changes?',\n",
       " 'type': 'multiplechoice',\n",
       " 'choices': ['There is a change in how the objects are used.',\n",
       "  'There is a change in the appearance of the objects.',\n",
       "  'There is a change in the materials from which the objects are made.',\n",
       "  'There is a change in both the appearance of the objects and the materials from which they are made.'],\n",
       " 'context': ' When you sharpen a pencil, the appearance of the pencil changes, but the materials from which it is made remain the same. When you tear paper, the appearance of the paper changes, but the materials from which it is made remain the same. Therefore, the correct answer is B) There is a change in the appearance of the objects.',\n",
       " 'cot': ['Shape is a property of the appearance of an object.',\n",
       "  'If something undergoes physical change then the chemical properties of that something will remain unchanged.',\n",
       "  'Material composition is a kind of chemical property.',\n",
       "  'Changed is the opposite of unchanged.',\n",
       "  'Composed of means made of.',\n",
       "  'If something undergoes a physical change then the physical properties of that something will change.',\n",
       "  'Appearance is a kind of physical property.',\n",
       "  'Sharpening an object causes that object to change shape.',\n",
       "  'A pencil is a kind of object.',\n",
       "  \"Tearing an object changes that object 's shape.\",\n",
       "  'A paper is a kind of object.'],\n",
       " 'answer': ['There is a change in the appearance of the objects.'],\n",
       " 'generated_cot': [],\n",
       " 'feedback': []}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect['worldtree']['train'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
