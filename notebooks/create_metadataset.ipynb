{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Upgrades\"\"\"\n",
    "#langchain.__version__ #old 0.0.14\n",
    "#!pip install --upgrade langchain #langchain-0.0.92\n",
    "#!pip install -U openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data:\n",
    "instruction = \"Answer the following question through step-by-step reasoning.\"\n",
    "question = \"Animals may fight, make threatening sounds, and act aggressively toward members of the same species. These behaviors usually occur as the result of\",\n",
    "answer_choices = [\n",
    "                    \"competition\",\n",
    "                    \"conservation\",\n",
    "                    \"decomposition\",\n",
    "                    \"pollution\"\n",
    "                ]\n",
    "cot_trigger = \"Answer: Let's think step by step.\"\n",
    "answer_extraction = \"Therefore, the answer is\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate \n",
    "from langchain.chains.llm import LLMChain\n",
    "from cot import Collection\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Chain to retrieve a chain-of-thought\"\"\"\n",
    "llm = OpenAI(temperature=.0)\n",
    "template = \"\"\"{instruction}\n",
    "\n",
    "Question: {question}\n",
    "Answer_choices: {answer_choices}\n",
    "\n",
    "{cot_trigger}\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\"], template=template)\n",
    "cot_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"cot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This chain retrieves answer extraction\"\"\"\n",
    "extraction_template = \"\"\"{instruction}\n",
    "\n",
    "Question: {question}\n",
    "Answer_choices: {answer_choices}\n",
    "\n",
    "Cot: {cot_trigger}{cot}\n",
    "{answer_extraction}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\"], template=extraction_template)\n",
    "answer_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"answer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Combine chains\"\"\"\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "overall_chain = SequentialChain(chains=[cot_chain, answer_chain],\n",
    "                                input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"answer_extraction\"],\n",
    "                                output_variables=[\"cot\", \"answer\"],\n",
    "                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading worldtree...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Generate CoT with use of TS-schema\"\"\"\n",
    "#compare with config used before; what about max tokens?\n",
    "#config contains what the chain needs\n",
    "input_dict = {\n",
    "    \"instruction\": \"Be faithful and a little hopeful\",\n",
    "    \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "    \"answer_extraction\": ['kojima-A-D'], \n",
    "}\n",
    "\n",
    "\n",
    "worldtree = Collection([\"worldtree\"], verbose=False)\n",
    "worldtree_1 = worldtree.select(split=\"train\", number_samples=1, random_samples=True, seed=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating worldtree...\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'ref_id', 'question', 'type', 'choices', 'context', 'cot', 'answer', 'generated_cot', 'feedback'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "test = worldtree_2.generate_flexible(chain=overall_chain,input_dict=input_dict)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#worldtree_1['worldtree']['train'][0]\n",
    "worldtree_new = {'worldtree':{'train':test}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and collect a json to make collection\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    json.dump(worldtree_new, outfile)\n",
    "collect = Collection.from_json('sample.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name      |   Train | Valid   | Test   |\n",
       "|-----------|---------|---------|--------|\n",
       "| worldtree |       2 | -       | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldtree_1 = worldtree.select(split=\"train\", number_samples=1, random_samples=True, seed=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate CoT with use of TS-schema\"\"\"\n",
    "#compare with config used before; what about max tokens?\n",
    "#config contains what the chain needs\n",
    "input_dict = {\n",
    "    \"instruction\": \"Be faithful and a little hopeful\",\n",
    "    \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "    \"answer_extraction\": ['kojima-A-D'], \n",
    "}\n",
    "\n",
    "\n",
    "worldtree = Collection([\"worldtree\"], verbose=False)\n",
    "worldtree_1 = worldtree.select(split=\"train\", number_samples=1, random_samples=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervision = \"Double check this idea, are the reasoning and answer sound yes/no?\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate \n",
    "from langchain.chains.llm import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cot import Collection\n",
    "from cot.generate import FRAGMENTS\n",
    "from rich.pretty import pprint\n",
    "import json\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate \n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "\"\"\"From collection to changed collection\"\"\"\n",
    "def cot_to_context(example):\n",
    "    example['context'] = example['generated_cot'][0]['cot']\n",
    "    example ['generated_cot'] = list()\n",
    "    return example\n",
    "\n",
    "def main(data_dict,instruction,answer_extraction,cot_trigger):\n",
    "    var_dataset = {\"instruction\":instruction,\"answer_extraction\":answer_extraction,\"cot_trigger\":cot_trigger} # \"cot_trigger\":cot_trigger,\n",
    "    cot_in_context = data_dict.map(cot_to_context)\n",
    "    final = cot_in_context.map(generate_cot,fn_kwargs = var_dataset) #\n",
    "    return final\n",
    "\n",
    "def generate_cot(item,instruction,answer_extraction,cot_trigger):\n",
    "\n",
    "    llm = OpenAI(temperature=.0)\n",
    "    template = \"\"\"{instruction}\n",
    "\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    {cot_trigger}\n",
    "    \"\"\"\n",
    "    prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\"], template=template)\n",
    "    cot_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"cot\")\n",
    "\n",
    "    \"\"\"This chain tries answer extraction and supervision at once\"\"\"\n",
    "    extraction_template = \"\"\"{instruction}\n",
    "\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    Cot: {cot_trigger}{cot}\n",
    "    {answer_extraction}\n",
    "    \"\"\"\n",
    "    prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\"], template=extraction_template)\n",
    "    answer_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"answer\")\n",
    "\n",
    "    # This is the overall chain where we run these two chains in sequence.\n",
    "    from langchain.chains import SequentialChain\n",
    "    overall_chain = SequentialChain(chains=[cot_chain, answer_chain],input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"answer_extraction\"],\n",
    "    # overall_chain = SequentialChain(chains=[cot_chain, supervision_chain],input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",'cot',\"answer_extraction\",\"supervision\"],\n",
    "        # Here we return multiple variables\n",
    "        output_variables=[\"cot\", \"answer\"],\n",
    "        verbose=True)\n",
    "    answer_cot = overall_chain({\"instruction\":instruction,\"question\":item['question'],\"answer_choices\":item['choices'],\"cot_trigger\":cot_trigger,\"answer_extraction\":answer_extraction})\n",
    "    # item['generated_cot']['cot'] = answer_cot['cot']\n",
    "    # item['generated_cot']['answers']['answer'] = answer_cot['answer']\n",
    "    # generated_cot[\"cot\"] = cot\n",
    "    # generated_cot[\"date\"] = print_now(1)\n",
    "    # answer[\"answer\"] = predicted_answer\n",
    "    # generated_cot[\"answers\"].append(answer)\n",
    "    # item[\"generated_cot\"].append(generated_cot)\n",
    "\n",
    "    return answer_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reflection template has new instruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reflection(item, cot_chain, reflection_prompt,reflect_answer_extraction):\n",
    "    llm = OpenAI(temperature=.0)\n",
    "    reflect_template = \"\"\"\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    Cot: {cot_trigger}{cot}\n",
    "    {answer_extraction}\n",
    "    Answer: {answer}\n",
    "    \n",
    "    {reflection_prompt}\n",
    "    \"\"\"\n",
    "    prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\",'answer','reflection_prompt'], template=reflect_template)\n",
    "    cot_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"reflection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cot_dataset = Collection.from_json(\"worldtree_10.json\") #input dataset\n",
    "cot_dataset = cot_dataset.select(split=\"train\", number_samples=1, random_samples=True, seed=0) #input # samples,seed\n",
    "cot_dataset = cot_dataset['worldtree']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1722',\n",
       " 'ref_id': '',\n",
       " 'question': 'Sharpening a pencil and tearing paper are examples of physical changes. Which statement describes why these are physical changes?',\n",
       " 'type': 'multiplechoice',\n",
       " 'choices': ['There is a change in how the objects are used.',\n",
       "  'There is a change in the appearance of the objects.',\n",
       "  'There is a change in the materials from which the objects are made.',\n",
       "  'There is a change in both the appearance of the objects and the materials from which they are made.'],\n",
       " 'context': '',\n",
       " 'cot': ['Shape is a property of the appearance of an object.',\n",
       "  'If something undergoes physical change then the chemical properties of that something will remain unchanged.',\n",
       "  'Material composition is a kind of chemical property.',\n",
       "  'Changed is the opposite of unchanged.',\n",
       "  'Composed of means made of.',\n",
       "  'If something undergoes a physical change then the physical properties of that something will change.',\n",
       "  'Appearance is a kind of physical property.',\n",
       "  'Sharpening an object causes that object to change shape.',\n",
       "  'A pencil is a kind of object.',\n",
       "  \"Tearing an object changes that object 's shape.\",\n",
       "  'A paper is a kind of object.'],\n",
       " 'answer': ['There is a change in the appearance of the objects.'],\n",
       " 'generated_cot': [{'id': '8a1b6bdc-4c0a-4a93-be8e-46ff33b8aa31',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'kojima-01',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': ' When you sharpen a pencil, the appearance of the pencil changes, but the materials from which it is made remain the same. When you tear paper, the appearance of the paper changes, but the materials from which it is made remain the same. Therefore, the correct answer is B) There is a change in the appearance of the objects.',\n",
       "   'answers': [{'id': '1a4ad0a8-54f8-4632-8bea-55946b4f33dd',\n",
       "     'answer_extraction': 'kojima-A-D',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': ' B.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'your_name',\n",
       "   'date': '2023/01/27 18:22:27',\n",
       "   'api_service': 'openai',\n",
       "   'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': '5be675fe-e1cc-4902-8887-3fcb6b9c1351',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'kojima-02',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': ' Sharpening a pencil and tearing paper are physical changes because they involve a change in the appearance of the objects. Therefore, the correct answer is B) There is a change in the appearance of the objects.',\n",
       "   'answers': [{'id': 'e9380525-1b69-4b67-9890-62d14126b23f',\n",
       "     'answer_extraction': 'kojima-A-D',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': ' B.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'your_name',\n",
       "   'date': '2023/01/27 18:22:33',\n",
       "   'api_service': 'openai',\n",
       "   'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': 'a8d3e8ff-4b3f-442a-8e97-b34848274649',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'kojima-03',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': ' B) There is a change in the appearance of the objects.',\n",
       "   'answers': [{'id': '3e854465-4073-4eb7-ad15-d8568c6cdc62',\n",
       "     'answer_extraction': 'kojima-A-D',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': ' B.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'your_name',\n",
       "   'date': '2023/01/27 18:22:36',\n",
       "   'api_service': 'openai',\n",
       "   'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []}],\n",
       " 'feedback': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = OpenAI(temperature=.0,model_name=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instruction = \"Answer the following question through step-by-step reasoning.\"\n",
    "#test = generate_cot(cot_dataset['train'],instruction,answer_extraction,cot_trigger)\n",
    "llm = OpenAI(temperature=.0)\n",
    "reflect_template = \"\"\"\n",
    "Question: {question}\n",
    "Answer_choices: {answer_choices}\n",
    "\n",
    "Cot: {cot_trigger}{cot}\n",
    "{answer_extraction}\n",
    "Answer: {answer}\n",
    "\n",
    "{reflection_prompt}\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\",'answer','reflection_prompt'], template=reflect_template)\n",
    "cot_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"reflection\")\n",
    "cot_chain.run()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cot_trigger = \"Answer: Let's think step by step.\"\n",
    "answer_extraction = \"Therefore, the answer is\"\n",
    "reflection_prompt = 'Do you think the Answer is really the correct answer?' #try with {answer}\n",
    "\n",
    "\n",
    "\n",
    "gen_test = generate_reflection(cot_dataset['train'],cot_chain,reflection_prompt, reflect_answer_extraction)\n",
    "\n",
    "item, cot_chain, reflection_prompt,reflect_answer_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \"\"\"This chain tries answer extraction and supervision at once\"\"\"\n",
    "    extraction_template = \"\"\"{instruction}\n",
    "\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    Cot: {cot_trigger}{cot}\n",
    "    {answer_extraction}{answer}\n",
    "    {reflection_prompt}\n",
    "    \n",
    "    {reflect_answer_extraction}\n",
    "    \"\"\"\n",
    "    #Get reflection\n",
    "    prompt_template = PromptTemplate(input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\",'answer','reflection_prompt','reflect_answer_extraction'], template=extraction_template)\n",
    "    answer_chain = LLMChain(llm=llm, prompt=prompt_template,output_key=\"reflection_answer\")\n",
    "\n",
    "    # This is the overall chain where we run these two chains in sequence.\n",
    "    from langchain.chains import SequentialChain\n",
    "    overall_chain = SequentialChain(chains=[cot_chain, answer_chain],input_variables=[\"instruction\",\"question\",\"answer_choices\",\"cot_trigger\",\"answer_extraction\",'cot','answer'],\n",
    "\n",
    "        output_variables=[\"reflection\", \"reflection_answer\"],\n",
    "        verbose=True)\n",
    "    answer_cot = overall_chain({\"instruction\":instruction,\"question\":item['question'],\"answer_choices\":item['choices'],\"cot_trigger\":cot_trigger,\"answer_extraction\":answer_extraction})\n",
    "\n",
    "\n",
    "    return answer_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cot_dataset = Collection.from_json(\"worldtree_10.json\") #input dataset\n",
    "cot_dataset = cot_dataset.select(split=\"train\", number_samples=1, random_samples=True, seed=0) #input # samples,seed\n",
    "cot_dataset = cot_dataset['worldtree']\n",
    "\n",
    "instruction = \"Answer the following question through step-by-step reasoning.\"\n",
    "cot_trigger = \"Answer: Let's think step by step.\"\n",
    "answer_extraction = \"Therefore, the answer is\"\n",
    "\n",
    "test = generate_cot(cot_dataset['train'],instruction,answer_extraction,cot_trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Answer the following question through step-by-step reasoning.',\n",
       " 'question': ['Sharpening a pencil and tearing paper are examples of physical changes. Which statement describes why these are physical changes?'],\n",
       " 'answer_choices': [['There is a change in how the objects are used.',\n",
       "   'There is a change in the appearance of the objects.',\n",
       "   'There is a change in the materials from which the objects are made.',\n",
       "   'There is a change in both the appearance of the objects and the materials from which they are made.']],\n",
       " 'cot_trigger': \"Answer: Let's think step by step.\",\n",
       " 'answer_extraction': 'Therefore, the answer is',\n",
       " 'cot': '\\n    Step 1: Physical changes involve a change in the physical properties of an object.\\n    \\n    Step 2: Sharpening a pencil involves a change in the shape of the pencil, while tearing paper involves a change in the shape of the paper.\\n    \\n    Step 3: Therefore, these are physical changes because there is a change in the appearance of the objects.',\n",
       " 'answer': \"\\n    'There is a change in the appearance of the objects.'\"}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test\n",
    "test['cot']\n",
    "test['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '8a1b6bdc-4c0a-4a93-be8e-46ff33b8aa31',\n",
       "  'fragments_version': '0.01',\n",
       "  'instruction': None,\n",
       "  'cot_trigger': 'kojima-01',\n",
       "  'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "  'prompt_text': '',\n",
       "  'cot': ' When you sharpen a pencil, the appearance of the pencil changes, but the materials from which it is made remain the same. When you tear paper, the appearance of the paper changes, but the materials from which it is made remain the same. Therefore, the correct answer is B) There is a change in the appearance of the objects.',\n",
       "  'answers': [{'id': '1a4ad0a8-54f8-4632-8bea-55946b4f33dd',\n",
       "    'answer_extraction': 'kojima-A-D',\n",
       "    'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "    'answer_extraction_text': '',\n",
       "    'answer': ' B.',\n",
       "    'correct_answer': True}],\n",
       "  'author': 'your_name',\n",
       "  'date': '2023/01/27 18:22:27',\n",
       "  'api_service': 'openai',\n",
       "  'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "  'comment': '',\n",
       "  'annotations': []},\n",
       " {'id': '5be675fe-e1cc-4902-8887-3fcb6b9c1351',\n",
       "  'fragments_version': '0.01',\n",
       "  'instruction': None,\n",
       "  'cot_trigger': 'kojima-02',\n",
       "  'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "  'prompt_text': '',\n",
       "  'cot': ' Sharpening a pencil and tearing paper are physical changes because they involve a change in the appearance of the objects. Therefore, the correct answer is B) There is a change in the appearance of the objects.',\n",
       "  'answers': [{'id': 'e9380525-1b69-4b67-9890-62d14126b23f',\n",
       "    'answer_extraction': 'kojima-A-D',\n",
       "    'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "    'answer_extraction_text': '',\n",
       "    'answer': ' B.',\n",
       "    'correct_answer': True}],\n",
       "  'author': 'your_name',\n",
       "  'date': '2023/01/27 18:22:33',\n",
       "  'api_service': 'openai',\n",
       "  'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "  'comment': '',\n",
       "  'annotations': []},\n",
       " {'id': 'a8d3e8ff-4b3f-442a-8e97-b34848274649',\n",
       "  'fragments_version': '0.01',\n",
       "  'instruction': None,\n",
       "  'cot_trigger': 'kojima-03',\n",
       "  'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "  'prompt_text': '',\n",
       "  'cot': ' B) There is a change in the appearance of the objects.',\n",
       "  'answers': [{'id': '3e854465-4073-4eb7-ad15-d8568c6cdc62',\n",
       "    'answer_extraction': 'kojima-A-D',\n",
       "    'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "    'answer_extraction_text': '',\n",
       "    'answer': ' B.',\n",
       "    'correct_answer': True}],\n",
       "  'author': 'your_name',\n",
       "  'date': '2023/01/27 18:22:36',\n",
       "  'api_service': 'openai',\n",
       "  'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "  'comment': '',\n",
       "  'annotations': []}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_dataset['train'][0]['generated_cot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to thoughtsource"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset manipulation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cot import Collection\n",
    "from cot.generate import FRAGMENTS\n",
    "from rich.pretty import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcab79a997e049038ffc7bfc348c4829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"From collection to changed collection\"\"\"\n",
    "def cot_to_context(example):\n",
    "    example['context'] = example['generated_cot'][0]['cot']\n",
    "    example ['generated_cot'] = list()\n",
    "    return example\n",
    "\n",
    "cot_dataset = Collection.from_json(\"worldtree_10.json\") #input dataset\n",
    "cot_dataset = cot_dataset.select(split=\"train\", number_samples=1, random_samples=True, seed=0) #input # samples,seed\n",
    "updated_dataset = cot_dataset['worldtree'].map(cot_to_context) #input dataset name\n",
    "\n",
    "#force dataset into the right format\n",
    "dataset = {\"train\":[updated_dataset['train'][0]]}\n",
    "dict_dataset = {\"worldtree\":dataset} \n",
    "\n",
    "#create and collect a json to make collection\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    json.dump(dict_dataset, outfile)\n",
    "collect = Collection.from_json('sample.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name      |   Train | Valid   | Test   |\n",
       "|-----------|---------|---------|--------|\n",
       "| worldtree |       1 | -       | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1722',\n",
       " 'ref_id': '',\n",
       " 'question': 'Sharpening a pencil and tearing paper are examples of physical changes. Which statement describes why these are physical changes?',\n",
       " 'type': 'multiplechoice',\n",
       " 'choices': ['There is a change in how the objects are used.',\n",
       "  'There is a change in the appearance of the objects.',\n",
       "  'There is a change in the materials from which the objects are made.',\n",
       "  'There is a change in both the appearance of the objects and the materials from which they are made.'],\n",
       " 'context': ' When you sharpen a pencil, the appearance of the pencil changes, but the materials from which it is made remain the same. When you tear paper, the appearance of the paper changes, but the materials from which it is made remain the same. Therefore, the correct answer is B) There is a change in the appearance of the objects.',\n",
       " 'cot': ['Shape is a property of the appearance of an object.',\n",
       "  'If something undergoes physical change then the chemical properties of that something will remain unchanged.',\n",
       "  'Material composition is a kind of chemical property.',\n",
       "  'Changed is the opposite of unchanged.',\n",
       "  'Composed of means made of.',\n",
       "  'If something undergoes a physical change then the physical properties of that something will change.',\n",
       "  'Appearance is a kind of physical property.',\n",
       "  'Sharpening an object causes that object to change shape.',\n",
       "  'A pencil is a kind of object.',\n",
       "  \"Tearing an object changes that object 's shape.\",\n",
       "  'A paper is a kind of object.'],\n",
       " 'answer': ['There is a change in the appearance of the objects.'],\n",
       " 'generated_cot': [],\n",
       " 'feedback': []}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect['worldtree']['train'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
