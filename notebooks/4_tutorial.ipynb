{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after cloning the repo, install linking to your local location of the cot library\n",
    "!pip install -e ./ThoughtSource-main/libs/cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "from cot import Collection\n",
    "from cot.generate import FRAGMENTS\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can find your API_TOKEN under Settings from your Hugging Face account\n",
    "\n",
    "#os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"<token>\" \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data: Loading dataset and generate random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading worldtree...\n",
      "| Name      |   Train |   Valid |   Test |\n",
      "|-----------|---------|---------|--------|\n",
      "| worldtree |    2207 |     496 |   1664 |\n",
      "\n",
      "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp']\n"
     ]
    }
   ],
   "source": [
    "# load a dataset to sample from \n",
    "collection_worldtree = Collection([\"worldtree\"], verbose=False)\n",
    "print(collection_worldtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name      |   Train | Valid   | Test   |\n",
       "|-----------|---------|---------|--------|\n",
       "| worldtree |     100 | -       | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting random 100 rows of train split\n",
    "collection_worldtree_100 = collection_worldtree.select(split=\"train\", number_samples=100, random_samples=True, seed=0)\n",
    "collection_worldtree_100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create json, it will appear in the same folder as this notebook\n",
    "collection_worldtree_100.dump(\"worldtree_100_dataset.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f57e102",
   "metadata": {},
   "source": [
    "## 2. Generate: Model Chain of Thought (CoT) Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f043028",
   "metadata": {},
   "source": [
    "## Examples of available fragments\n",
    "Three groups of templates for CoT generation:\n",
    "1) Instructions\n",
    "2) CoT-Triggers\n",
    "3) Answer-Extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63ddbbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'qa-01': 'Answer the following question through step-by-step reasoning.',\n",
      " 'qa-02': 'Answer the following question through careful, concise step-by-step '\n",
      "          'reasoning.',\n",
      " 'qa-03': 'Answer the following question through careful, concise step-by-step '\n",
      "          'reasoning. Avoid making up wrong statements. If the question does '\n",
      "          'not make sense or cannot be answered, write \"I cannot answer the '\n",
      "          'question\". If you do not have a good answer, write \"I do not have a '\n",
      "          'good answer\". If you are uncertain, write \"I am uncertain about '\n",
      "          'this\".',\n",
      " 'qa-04': 'Answer the following question through careful, concise step-by-step '\n",
      "          'reasoning. Avoid making up wrong statements. Generate sub-questions '\n",
      "          'that are required to answer the original question, answer them '\n",
      "          'until you can answer the original question. If the question does '\n",
      "          'not make sense or cannot be answered, write \"I cannot answer the '\n",
      "          'question\". If you do not have a good answer, write \"I do not have a '\n",
      "          'good answer\". If you are uncertain, write \"I am uncertain about '\n",
      "          'this\".'}\n"
     ]
    }
   ],
   "source": [
    "# Choose between instructions\n",
    "pprint(FRAGMENTS[\"instructions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63ddbbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"kojima-01\": \"Answer: Let's think step by step.\",\n",
      "  \"kojima-02\": \"Answer: We should think about this step by step.\",\n",
      "  \"kojima-03\": \"Answer: First,\",\n",
      "  \"kojima-04\": \"Answer: Before we dive into the answer,\",\n",
      "  \"kojima-05\": \"Answer: Proof followed by the answer.\",\n",
      "  \"kojima-06\": \"Answer: Let's think step by step in a realistic way.\",\n",
      "  \"kojima-07\": \"Answer: Let's think step by step using common sense and knowledge.\",\n",
      "  \"kojima-08\": \"Answer: Let's think like a detective step by step.\",\n",
      "  \"kojima-09\": \"Answer: Let's think about this logically.\",\n",
      "  \"kojima-10\": \"Answer: Let's think step by step. First,\",\n",
      "  \"kojima-11\": \"Answer: Let's think\",\n",
      "  \"kojima-12\": \"Answer: Let's solve this problem by splitting it into steps.\",\n",
      "  \"kojima-13\": \"Answer: The answer is after the proof.\",\n",
      "  \"kojima-14\": \"Answer: Let's be realistic and think step by step.\",\n",
      "  \"lievin-01\": \"Answer: Let's derive the differential diagnosis step by step.\",\n",
      "  \"lievin-02\": \"Answer: Let's use step by step inductive reasoning, given the medical nature of the question.\",\n",
      "  \"lievin-03\": \"Answer: Let's differentiate using step by step reasoning like a medical expert.\",\n",
      "  \"lievin-04\": \"Answer: Let's think step by step using deductive reasoning.\",\n",
      "  \"lievin-05\": \"Answer: Let's differentiate using step by step reasoning .\",\n",
      "  \"lievin-06\": \"Answer: Let's think step by step to arrive at one of the options.\",\n",
      "  \"lievin-07\": \"Answer: Let's break the problem into multiple steps.\",\n",
      "  \"lievin-08\": \"Answer: Let's use step by step deductive reasoning, given the medical nature of the question.\",\n",
      "  \"lievin-09\": \"Answer: Let's think step by step like a doctor.\",\n",
      "  \"lievin-10\": \"Answer: Let's think step by step like a medical expert.\",\n",
      "  \"lievin-11\": \"Answer: Let's summarize the facts step by step.\",\n",
      "  \"lievin-12\": \"Answer: Let's think step by step using inductive reasoning.\",\n",
      "  \"lievin-13\": \"Answer: Let's think step by step using deductive reasoning like a medical expert.\",\n",
      "  \"lievin-14\": \"Answer: Let's be concise and think step by step.\",\n",
      "  \"lievin-15\": \"Answer: Let's differentiate using step by step deductive reasoning like a medical expert.\",\n",
      "  \"lievin-16\": \"Answer: Let's argue step by step.\",\n",
      "  \"lievin-17\": \"Answer: Let's think step by step like a clinician.\",\n",
      "  \"lievin-18\": \"Answer: Let's reflect on each answer option step by step.\",\n",
      "  \"lievin-19\": \"Answer: Let's reason and differentiate options step by step like a medical expert.\",\n",
      "  \"lievin-20\": \"Answer: Let's differentiate using step by step inductive reasoning like a medical expert.\",\n",
      "  \"lievin-21\": \"Answer: Let's think step by step given every option equal consideration.\",\n",
      "  \"lievin-22\": \"Answer: Let's think step by step like a scientist.\",\n",
      "  \"lievin-23\": \"Answer: Let's use step by step inductive reasoning.\",\n",
      "  \"lievin-24\": \"Answer: Let's work by elimination step by step.\",\n",
      "  \"lievin-25\": \"Answer: Let's use step by step deductive reasoning.\",\n",
      "  \"lievin-26\": \"Answer: Let's follow a Bayesian step by step approach.\",\n",
      "  \"lievin-27\": \"Answer: Let's reflect on each option from the least likely to the most likely.\",\n",
      "  \"lievin-28\": \"Answer: Let's use step by step Bayesian reasoning, given the medical nature of the question.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Choose a trigger to induce chain-of-thought reasoning\n",
    "print(json.dumps(FRAGMENTS[\"cot_triggers\"], sort_keys=True, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ddbbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kojima-01': 'Therefore, the answer is',\n",
      " 'kojima-02': 'Therefore,',\n",
      " 'kojima-03': 'The answer is',\n",
      " 'kojima-A-C': 'Therefore, among A through C, the answer is',\n",
      " 'kojima-A-D': 'Therefore, among A through D, the answer is',\n",
      " 'kojima-A-E': 'Therefore, among A through E, the answer is',\n",
      " 'kojima-A-F': 'Therefore, among A through F, the answer is',\n",
      " 'kojima-numerals': 'Therefore, the answer (arabic numerals) is',\n",
      " 'kojima-yes-no': 'Therefore, the answer (Yes or No) is'}\n"
     ]
    }
   ],
   "source": [
    "# After obtaining a chain-of-thought (cot), the model receives the question with cot and an answer_extraction instruction\n",
    "pprint(FRAGMENTS[\"answer_extractions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Chain of Thought examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading worldtree...\n"
     ]
    }
   ],
   "source": [
    "# load dataset (detailed explanation in generate_samples notebook) and config file\n",
    "collection = Collection([\"worldtree\"], verbose=False)\n",
    "worldtree_100_random = collection.select(split=\"train\", number_samples=100, random_samples=True, seed=0)\n",
    "config={\n",
    "    \"idx_range\": \"all\", # Determines which indices the generate_and_extract routine is applied to, Default: \"all\" (All items are used)\n",
    "    \"instruction_keys\": [\"qa-01\"], # Determines which instructions are used from fragments.json, Default: None (no instructions are used)\n",
    "    \"cot_trigger_keys\": [\"kojima-01\"], # Determines which cot triggers are used from fragments.json, Default: [\"kojima-01\"] (only the first trigger is used)\n",
    "    \"answer_extraction_keys\": [\"kojima-A-D\"], # Determines which answer extraction prompts are used from fragments.json, Default: [\"kojima-01\"] (only the first prompt is used)\n",
    "    \"author\" : \"konstantin\", # Name of the person responsible for generation, Default: \"\"\n",
    "    \"api_service\": \"mock_api\", # Name of the API called (\"openai\", \"huggingface_hub\", or a mock for testing: \"mock_api\"), Default: \"huggingface_hub\"\n",
    "    \"engine\": \"\", # Name of the engine used (for \"huggingface_hub\" use for example \"google/flan-t5-xl\"), Default: \"google/flan-t5-xl\"\n",
    "    \"temperature\": 0, # Name of the person responsible for generation, Default: 0\n",
    "    \"max_tokens\": 512, # Maximum length of output generated by the model, Default: 128\n",
    "    \"api_time_interval\": 1.0, # Pause between two api calls in seconds, Default: 1.0\n",
    "    \"verbose\": False, # Determines whether the progress of the generation is printed, Default: True\n",
    "    \"warn\": True, # Determines whether a warnings that external APIs will be called are printed, Default: True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        You are about to \u001b[1m call an external API \u001b[0m in total 200 times, which \u001b[1m may produce costs \u001b[0m.\n",
      "        Number API calls for CoT generation: n_samples 100 * n_instruction_keys 1 * n_cot_trigger_keys 1\n",
      "        Number API calls for answer extraction: n_samples 100 * n_instruction_keys 1 * n_cot_trigger_keys 1 * n_answer_extraction_keys 1\n",
      "        Do you want to continue? y/n\n",
      "        \u001b[1m Note: You are using a mock api. When entering 'y', a test run without API calls is made. \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ebc7183ca34038b0775beceb5c0f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generating chains of thought and answer extractions (This is in Mock-API mode, not calling model over API)\n",
    "worldtree_100_random.generate(name=\"worldtree\", config=config) #if you cannot press y, set \"warn\" to false in config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above was a fake call in debug mode. Now loading a prepared dataset with real model answers.\n",
    "worldtree_100_random = Collection.from_json(\"worldtree_100_generate.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508ffb0",
   "metadata": {},
   "source": [
    "#### Question, choices and right answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Question: The length of a year is equivalent to the time it takes for one'\n",
      "'MC:'\n",
      "['rotation of Earth',\n",
      " 'rotation of the Sun',\n",
      " 'revolution of Earth around the Sun',\n",
      " 'revolution of the Sun around Earth']\n",
      "'Answer: revolution of Earth around the Sun'\n"
     ]
    }
   ],
   "source": [
    "# Extract from prepared dataset\n",
    "pprint(\"Question: \"+ worldtree_100_random[\"worldtree\"][\"train\"][1][\"question\"])\n",
    "pprint(\"Answer Options:\")\n",
    "pprint(worldtree_100_random[\"worldtree\"][\"train\"][1][\"choices\"])\n",
    "pprint(\"Answer: \"+ \"\".join(worldtree_100_random[\"worldtree\"][\"train\"][1][\"answer\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508ffb0",
   "metadata": {},
   "source": [
    "#### Model generated chain of thought and extracted answer (correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A year is equal to one revolution of Earth around the Sun. One revolution of '\n",
      " 'Earth around the Sun is equal to one year. So, the final answer is C.')\n",
      "'C.'\n"
     ]
    }
   ],
   "source": [
    "pprint(worldtree_100_random[\"worldtree\"][\"train\"][1][\"generated_cot\"][0][\"cot\"])\n",
    "pprint(worldtree_100_random[\"worldtree\"][\"train\"][1][\"generated_cot\"][0]['answers'][0]['answer'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f57e102",
   "metadata": {},
   "source": [
    "## 3. Evaluate: Performance Evaluation of model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading collection with model answers\n",
    "collection = Collection.from_json(\"worldtree_100_generate.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before the evaluation step the collection does not include if the answer is correct.\n",
    "collection[\"worldtree\"][\"train\"][0]['generated_cot'][0][\"answers\"][0]['correct_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2649c06408da495b9cc55d52c8a0ad66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': {'qa-01_kojima-01_kojima-A-D': 0.86}}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of the model predictions\n",
    "collection.evaluate(\"worldtree\",\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the collection includes if the answer is correct\n",
    "collection[\"worldtree\"][\"train\"][0]['generated_cot'][0][\"answers\"][0]['correct_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d034dfdc8a4c7da96d88993c2d88ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "collection.dump(\"worldtree_100_evaluate.json\") #save evaluation to current folder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading worldtree...\n",
      "{'accuracy': {'qa-01_kojima-01_kojima-A-D': 0.6}}\n"
     ]
    }
   ],
   "source": [
    "#Combination of the methods in one cell\n",
    "\n",
    "# 1) Dataset loading and selecting a random sample\n",
    "collection = Collection([\"worldtree\"], verbose=False)\n",
    "collection = collection.select(split=\"train\", number_samples=10)\n",
    "\n",
    "\n",
    "# 2) Language Model generates chains of thought and then extracts answers\n",
    "config={\n",
    "    \"instruction_keys\": ['qa-01'], # \"Answer the following question through step-by-step reasoning.\"\n",
    "    \"cot_trigger_keys\": ['kojima-01'], # \"Answer: Let's think step by step.\"\n",
    "    \"answer_extraction_keys\": ['kojima-A-D'], # \"Therefore, among A through D, the answer is\"\n",
    "    \"api_service\": \"huggingface_hub\",\n",
    "    \"engine\": \"google/flan-t5-xl\",\n",
    "    \"warn\": False,\n",
    "    \"verbose\": False,\n",
    "}\n",
    "pprint(collection.generate(config=config))\n",
    "\n",
    "# 3) Performance evaluation\n",
    "pprint(collection.evaluate())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
