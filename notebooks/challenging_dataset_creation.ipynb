{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commonsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/robertpraas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from cot import Collection\n",
    "coll = Collection.load_thoughtsource_100(load_pregenerated_cots=True)\n",
    "coll.select_generated_cots(cot_trigger = \"kojima-01\", api_service='openai',model = 'text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1b29d402c3e17cb3b435',\n",
       " 'ref_id': '',\n",
       " 'question': 'Is a pound sterling valuable?',\n",
       " 'type': 'bool',\n",
       " 'choices': ['True', 'False'],\n",
       " 'context': '',\n",
       " 'cot': ['A pound sterling is fiat money.',\n",
       "  'Fiat money is backed by government decree and has no intrinsic value.',\n",
       "  'One pound sterling is worth about 1.24 US dollars by May of 2020.'],\n",
       " 'answer': ['False'],\n",
       " 'generated_cot': [],\n",
       " 'feedback': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll['strategy_qa']['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name           | Train   |   Valid | Test   |\n",
       "|----------------|---------|---------|--------|\n",
       "| commonsense_qa | -       |     100 | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp', 'worldtree']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cot import Collection\n",
    "coll = Collection.load_thoughtsource_100(load_pregenerated_cots=True)\n",
    "coll.select_generated_cots(cot_trigger = \"kojima-01\", api_service='openai',model = 'text-davinci-003')\n",
    "coll.select_generated_cots(answers=\"False\")\n",
    "coll.unload_datasets([\"med_qa\",\"medmc_qa\",\"strategy_qa\",'open_book_qa','worldtree'])\n",
    "coll\n",
    "#coll.dump(\"cs_davinci.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Went through Annotator\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name           | Train   |   Valid | Test   |\n",
       "|----------------|---------|---------|--------|\n",
       "| commonsense_qa | -       |     100 | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp', 'worldtree']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated = Collection.from_json(\"cs_davinci_annotated.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Moved to annotated files folder\"\"\"\n",
    "\n",
    "ann_1 = Collection.from_json(\"annotated_ob_davinci.json\") #open book\n",
    "ann_2 = Collection.from_json(\"annotated_st_davinci.json\") #strategu\n",
    "ann_3 = Collection.from_json(\"annotated_wt_davinci.json\")\n",
    "ann_4 = Collection.from_json(\"cs_davinci_annotated.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_annotated(dataset,split,selection):\n",
    "    i= 0\n",
    "    lst = []\n",
    "    for element in selection[dataset][split]:\n",
    "        if len(element['generated_cot'])>0:\n",
    "            if len(element['generated_cot'][0]['annotations'])>0 :\n",
    "                lst.append(i)\n",
    "        i+=1\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_1 = Collection.from_json(\"annotated_ob_davinci.json\") #open book\n",
    "ann_2 = Collection.from_json(\"annotated_st_davinci.json\") #strategu\n",
    "ann_3 = Collection.from_json(\"annotated_wt_davinci.json\")\n",
    "ann_4 = Collection.from_json(\"cs_davinci_annotated.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_1['open_book_qa']['test'] = ann_1['open_book_qa']['test'].select(select_annotated('open_book_qa','test',ann_1))\n",
    "ann_2['strategy_qa']['train'] = ann_2['strategy_qa']['train'].select(select_annotated('strategy_qa','train',ann_2))\n",
    "ann_3['worldtree']['test'] = ann_3['worldtree']['test'].select(select_annotated('worldtree','test',ann_3))\n",
    "ann_4['commonsense_qa']['validation'] = ann_4['commonsense_qa']['validation'].select(select_annotated('commonsense_qa','validation',ann_4))\n",
    " annotated_set = ann_4.merge(ann_3).merge(ann_2).merge(ann_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_set.dump('annotated_set.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Medical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cot import Collection\n",
    "coll = Collection.load_thoughtsource_100(load_pregenerated_cots=True)\n",
    "coll.select_generated_cots(cot_trigger = \"kojima-01\", api_service='openai',model = 'text-davinci-003')\n",
    "coll.select_generated_cots(answers=\"False\")\n",
    "coll.unload_datasets([\"commonsense_qa\",\"strategy_qa\",'open_book_qa','worldtree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name     | Train   | Valid   | Test   |\n",
       "|----------|---------|---------|--------|\n",
       "| med_qa   | -       | -       | 100    |\n",
       "| medmc_qa | -       | 100     | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp', 'worldtree']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for item in coll['med_qa']['test']:\n",
    "    if len(item['generated_cot'])>0:\n",
    "        i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for item in coll['medmc_qa']['validation']:\n",
    "    if len(item['generated_cot'])>0:\n",
    "        i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll.dump('medical_incorrect.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra annotation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get gpt-4 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cot import Collection\n",
    "col = Collection.from_json(\"../notebooks/thoughtsource_100_openai_chat_gpt-4_None_zhou-01.json\")\n",
    "col.select_generated_cots(api_service='openai_chat',model = 'gpt-4')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at annotated set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name           | Train   | Valid   | Test   |\n",
       "|----------------|---------|---------|--------|\n",
       "| commonsense_qa | -       | 12      | -      |\n",
       "| worldtree      | -       | -       | 7      |\n",
       "| strategy_qa    | 11      | -       | -      |\n",
       "| open_book_qa   | -       | -       | 21     |\n",
       "| med_qa         | -       | -       | 20     |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'entailment_bank', 'gsm8k', 'mawps', 'medmc_qa', 'pubmed_qa', 'qed', 'svamp']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cot import Collection\n",
    "ann_col = Collection.from_json(\"../notebooks/ts_hard_v1.json\")\n",
    "ann_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = ann_col['commonsense_qa']['validation']['id']\n",
    "id_list_2 = ann_col['worldtree']['test']['id']\n",
    "id_list_3 = ann_col['strategy_qa']['train']['id']\n",
    "id_list_4 = ann_col['open_book_qa']['test']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(collection,id_list,dataset,split):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for item in collection[dataset][split]:\n",
    "        if item['id'] in id_list:\n",
    "            j +=1\n",
    "            if item['generated_cot'][0]['answers'][0]['correct_answer'] == True:\n",
    "                i +=1\n",
    "    return (f\"{i}/{j}={i/j}\")\n",
    "\n",
    "# GPT-4 7/11 correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8/12=0.6666666666666666'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(col, id_list,'commonsense_qa','validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7/7=1.0'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(col, id_list_2,'worldtree','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8/11=0.7272727272727273'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(col, id_list_3,'strategy_qa','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19/21=0.9047619047619048'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(col, id_list_4,'open_book_qa','test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotated creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/robertpraas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "ann_1 = Collection.from_json(\"../notebooks/internal_documentation/newly_annotated/annotated_ob_davinci.json\") #open book\n",
    "ann_2 = Collection.from_json(\"../notebooks/internal_documentation/newly_annotated/annotated_st_davinci.json\") #strategu\n",
    "ann_3 = Collection.from_json(\"../notebooks/internal_documentation/newly_annotated/annotated_wt_davinci.json\")\n",
    "ann_4 = Collection.from_json(\"../notebooks/internal_documentation/newly_annotated/cs_davinci_annotated.json\")\n",
    "ann_5 = Collection.from_json(\"../notebooks/internal_documentation/newly_annotated/medical_incorrect_1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name   | Train   | Valid   |   Test |\n",
       "|--------|---------|---------|--------|\n",
       "| med_qa | -       | -       |    100 |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp', 'worldtree']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_1['open_book_qa']['test'] = ann_1['open_book_qa']['test'].select(select_annotated('open_book_qa','test',ann_1))\n",
    "ann_2['strategy_qa']['train'] = ann_2['strategy_qa']['train'].select(select_annotated('strategy_qa','train',ann_2))\n",
    "ann_3['worldtree']['test'] = ann_3['worldtree']['test'].select(select_annotated('worldtree','test',ann_3))\n",
    "ann_4['commonsense_qa']['validation'] = ann_4['commonsense_qa']['validation'].select(select_annotated('commonsense_qa','validation',ann_4))\n",
    "ann_5['med_qa']['test'] = ann_5['med_qa']['test'].select(select_annotated('med_qa','test',ann_5))\n",
    "annotated_set = ann_4.merge(ann_3).merge(ann_2).merge(ann_1).merge(ann_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name           | Train   | Valid   | Test   |\n",
       "|----------------|---------|---------|--------|\n",
       "| commonsense_qa | -       | 12      | -      |\n",
       "| worldtree      | -       | -       | 7      |\n",
       "| strategy_qa    | 11      | -       | -      |\n",
       "| open_book_qa   | -       | -       | 21     |\n",
       "| med_qa         | -       | -       | 20     |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'entailment_bank', 'gsm8k', 'mawps', 'medmc_qa', 'pubmed_qa', 'qed', 'svamp']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cot import Collection\n",
    "chat_col = Collection.load_thoughtsource_100(load_pregenerated_cots=True)\n",
    "chat_col.select_generated_cots(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9/12=0.75'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(chat_col, id_list,'commonsense_qa','validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6/7=0.8571428571428571'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(chat_col, id_list_2,'worldtree','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6/11=0.5454545454545454'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(chat_col, id_list_3,'strategy_qa','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13/21=0.6190476190476191'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(chat_col, id_list_4,'open_book_qa','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'b8c0a4703079cf661d7261a60a1bcbff',\n",
       " 'ref_id': '',\n",
       " 'question': 'Where would you find magazines along side many other printed works?',\n",
       " 'type': 'multiplechoice',\n",
       " 'choices': ['doctor', 'bookstore', 'market', 'train station', 'mortuary'],\n",
       " 'context': '',\n",
       " 'cot': ['If one wants various printed reading material, they can go to a bookstore.',\n",
       "  'All other options are invalid as they do not have wide range of printed reading material.'],\n",
       " 'answer': ['bookstore'],\n",
       " 'generated_cot': [{'id': '1f6f9395-4241-42b0-9156-13a3c9d5d0f0',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': None,\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': 'B) bookstore',\n",
       "   'answers': [{'id': 'bf2f1626-aba6-4a9e-845c-2169d75a5109',\n",
       "     'answer_extraction': 'kojima-A-E',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'B) bookstore.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'thoughtsource',\n",
       "   'date': '2023/03/11 00:06:02',\n",
       "   'api_service': 'openai_chat',\n",
       "   'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': 'ad874d34-a246-4538-81e4-d2e2bf2425b0',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'kojima-01',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': \"\\n\\nMagazines are typically sold in places where people have time to read and relax, such as waiting rooms or leisure areas. \\n\\nA) Doctor's offices often have magazines in their waiting rooms, but they typically don't have a wide variety of printed works. \\n\\nB) Bookstores are a good option, as they have a wide selection of books, magazines, and other printed works. \\n\\nC) Markets may have some magazines, but they are not typically known for selling printed works. \\n\\nD) Train stations often have newsstands or convenience stores that sell magazines, newspapers, and other printed works. \\n\\nE) Mortuaries are unlikely to have magazines or other printed works available for purchase. \\n\\nTherefore, the best answer is B) bookstore.\",\n",
       "   'answers': [{'id': '757b98f4-387c-40a4-97fb-ebb4608a7125',\n",
       "     'answer_extraction': 'kojima-A-E',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'B) bookstore.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'thoughtsource',\n",
       "   'date': '2023/03/11 00:06:12',\n",
       "   'api_service': 'openai_chat',\n",
       "   'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': 'ceb945c7-d661-4392-924d-9aa568500159',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'zhou-01',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': '\\n\\nStep 1: Identify the keyword in the question. The keyword is \"magazines.\"\\n\\nStep 2: Look at the options provided and eliminate any that are clearly not relevant. Options A, C, and E are unlikely to have magazines alongside other printed works.\\n\\nStep 3: Consider option D, a train station. While train stations may have some printed materials available, they are unlikely to have a wide variety of magazines.\\n\\nStep 4: This leaves us with option B, a bookstore. Bookstores typically have a wide variety of printed materials, including magazines, newspapers, books, and other publications.\\n\\nTherefore, the correct answer is B) bookstore.',\n",
       "   'answers': [{'id': 'ab62357a-9fa6-4bc1-9159-402bf29b835d',\n",
       "     'answer_extraction': 'kojima-A-E',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'B) bookstore.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'thoughtsource',\n",
       "   'date': '2023/03/13 17:10:29',\n",
       "   'api_service': 'openai_chat',\n",
       "   'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': '7ee2aaca-645c-4674-82ff-134fa40f3560',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': 'qa-01',\n",
       "   'cot_trigger': None,\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': \"\\n\\nThe most likely answer to this question is B) bookstore. Here's why:\\n\\n- A) Doctor: While some doctors' offices may have magazines available for patients to read, they typically don't have a wide variety of printed works beyond medical pamphlets and brochures.\\n- B) Bookstore: Bookstores are known for carrying a wide variety of printed works, including books, magazines, newspapers, and more. It's common to find magazines displayed alongside other printed works in a bookstore.\\n- C) Market: Depending on the type of market, there may be some printed works available for sale or distribution, but it's less likely to find a wide variety of magazines alongside other printed works.\\n- D) Train station: Train stations may have newsstands or convenience stores that sell magazines, but they may not have a large selection of other printed works beyond newspapers and travel guides.\\n- E) Mortuary: It's unlikely that a mortuary would have magazines or other printed works available for visitors, as it's not a typical setting for reading materials.\\n\\nTherefore, the most likely place to find magazines alongside many other printed works is a bookstore.\",\n",
       "   'answers': [{'id': '1b433093-11cd-4fdd-a026-24dd7b24b1b8',\n",
       "     'answer_extraction': 'kojima-A-E',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'B) bookstore.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'thoughtsource',\n",
       "   'date': '2023/03/14 14:31:09',\n",
       "   'api_service': 'openai_chat',\n",
       "   'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': '77f21626-6f9c-433e-b2b1-e0716f791791',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'kojima-03',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': 'the most likely answer is B) bookstore, as bookstores typically carry a variety of printed materials including magazines. The other options are less likely to have a selection of magazines available for purchase or reading.',\n",
       "   'answers': [{'id': '413dde6a-324a-45a6-af97-da98a359a60c',\n",
       "     'answer_extraction': 'kojima-A-E',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'B) bookstore.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'thoughtsource',\n",
       "   'date': '2023/03/16 17:26:36',\n",
       "   'api_service': 'openai_chat',\n",
       "   'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []},\n",
       "  {'id': '3d88f9f4-4925-4c57-8c82-60306f9b4a54',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'kojima-09',\n",
       "   'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "   'prompt_text': '',\n",
       "   'cot': \"\\n\\nThe most likely answer is B) bookstore, as bookstores typically carry a wide variety of printed works, including magazines. Doctors' offices may have magazines in their waiting rooms, but they would not typically have a large selection of other printed works. Markets and train stations may have newsstands that sell magazines, but they would not typically have a wide variety of other printed works. A mortuary would not typically have magazines or other printed works available for customers.\",\n",
       "   'answers': [{'id': 'd410c33b-b6ac-4b5e-95df-fcb8dd8c777a',\n",
       "     'answer_extraction': 'kojima-A-E',\n",
       "     'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'B) bookstore.',\n",
       "     'correct_answer': True}],\n",
       "   'author': 'thoughtsource',\n",
       "   'date': '2023/03/16 18:50:13',\n",
       "   'api_service': 'openai_chat',\n",
       "   'model': \"{'name': 'gpt-3.5-turbo', 'temperature': 0, 'max_tokens': 512}\",\n",
       "   'comment': '',\n",
       "   'annotations': []}],\n",
       " 'feedback': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll['commonsense_qa']['validation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f27524fac54696a16cf7e3b1cf4775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c5ebf3921941e382c439898c3703db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6827e68593c4801bb8b8f98d0f1b1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a1fecdf5d246da90b7b3e419e6b979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e307761b7ec34837bc9958a0d7799bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotated_set.dump(\"ts_hard_v1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with strategy_Qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
