{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cot import Collection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import krippendorff\n",
    "from scipy import stats\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "coll = Collection.from_json(\"/home/kon/work/ThoughtSource/libs/cot/cot/datasets/thoughtsource/thoughtsource_33_paper.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a96f6bc571440c7836144f2b990fe8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d17fb89b344e50b035296f27eb057f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45af62e7ed049d28e2972590c71d462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c929cffbee41ae8b2be8449875248b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f7a74909634e388b4a70604088d04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b88166571f428299ee107356d4a980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ev = coll.evaluate(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = coll.collection_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>number_choices</th>\n",
       "      <th>answer_label</th>\n",
       "      <th>prompt</th>\n",
       "      <th>instruction</th>\n",
       "      <th>cot_trigger</th>\n",
       "      <th>answer_from_choices</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>multiplechoice</td>\n",
       "      <td>5</td>\n",
       "      <td>E</td>\n",
       "      <td>None_None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>multiplechoice</td>\n",
       "      <td>5</td>\n",
       "      <td>E</td>\n",
       "      <td>None_None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>text-davinci-003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>multiplechoice</td>\n",
       "      <td>5</td>\n",
       "      <td>E</td>\n",
       "      <td>None_None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>flan-T5-xxl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset       split                                id  \\\n",
       "0  commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "1  commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "2  commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "\n",
       "             type  number_choices answer_label     prompt instruction  \\\n",
       "0  multiplechoice               5            E  None_None        None   \n",
       "1  multiplechoice               5            E  None_None        None   \n",
       "2  multiplechoice               5            E  None_None        None   \n",
       "\n",
       "  cot_trigger answer_from_choices  correct_answer                   model  \n",
       "0        None                   E            True  command-xlarge-nightly  \n",
       "1        None                   E            True        text-davinci-003  \n",
       "2        None                   E            True             flan-T5-xxl  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"number_choices\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prompt</th>\n",
       "      <th>None_None</th>\n",
       "      <th>None_kojima-01</th>\n",
       "      <th>None_zhou-01</th>\n",
       "      <th>qa-10_None</th>\n",
       "      <th>qa-12_None</th>\n",
       "      <th>qa-13_None</th>\n",
       "      <th>qa-16_None</th>\n",
       "      <th>qa-17_None</th>\n",
       "      <th>refl-01_None</th>\n",
       "      <th>zhou-01-ins_None</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>command-xlarge-nightly</th>\n",
       "      <td>0.449495</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.459596</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.434343</td>\n",
       "      <td>0.474747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan-T5-xxl</th>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.601010</td>\n",
       "      <td>0.631313</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.540404</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.570707</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.686869</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.656566</td>\n",
       "      <td>0.651515</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.651515</td>\n",
       "      <td>0.671717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4</th>\n",
       "      <td>0.792929</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.813131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-002</th>\n",
       "      <td>0.565657</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.580808</td>\n",
       "      <td>0.565657</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.540404</td>\n",
       "      <td>0.525253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-003</th>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.580808</td>\n",
       "      <td>0.631313</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.626263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prompt                  None_None  None_kojima-01  None_zhou-01  qa-10_None  \\\n",
       "model                                                                         \n",
       "command-xlarge-nightly   0.449495        0.424242      0.505051    0.444444   \n",
       "flan-T5-xxl              0.621212        0.621212      0.575758    0.601010   \n",
       "gpt-3.5-turbo            0.712121        0.686869      0.696970    0.666667   \n",
       "gpt-4                    0.792929        0.833333      0.863636    0.833333   \n",
       "text-davinci-002         0.565657        0.525253      0.611111    0.530303   \n",
       "text-davinci-003         0.595960        0.580808      0.631313    0.606061   \n",
       "\n",
       "prompt                  qa-12_None  qa-13_None  qa-16_None  qa-17_None  \\\n",
       "model                                                                    \n",
       "command-xlarge-nightly    0.459596    0.484848    0.515152    0.469697   \n",
       "flan-T5-xxl               0.631313    0.611111    0.540404    0.611111   \n",
       "gpt-3.5-turbo             0.666667    0.656566    0.651515    0.681818   \n",
       "gpt-4                     0.797980    0.818182    0.797980    0.777778   \n",
       "text-davinci-002          0.580808    0.565657    0.611111    0.494949   \n",
       "text-davinci-003          0.636364    0.595960    0.555556    0.585859   \n",
       "\n",
       "prompt                  refl-01_None  zhou-01-ins_None  \n",
       "model                                                   \n",
       "command-xlarge-nightly      0.434343          0.474747  \n",
       "flan-T5-xxl                 0.570707          0.590909  \n",
       "gpt-3.5-turbo               0.651515          0.671717  \n",
       "gpt-4                       0.797980          0.813131  \n",
       "text-davinci-002            0.540404          0.525253  \n",
       "text-davinci-003            0.611111          0.626263  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = df.groupby([\"model\", \"prompt\"]).mean(\"correct_answer\").pivot_table(index=\"model\", columns=\"prompt\", values=\"correct_answer\")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>commonsense_qa</th>\n",
       "      <th>med_qa</th>\n",
       "      <th>medmc_qa</th>\n",
       "      <th>open_book_qa</th>\n",
       "      <th>strategy_qa</th>\n",
       "      <th>worldtree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>command-xlarge-nightly</th>\n",
       "      <td>0.657576</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.572727</td>\n",
       "      <td>0.248485</td>\n",
       "      <td>0.745455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan-T5-xxl</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.342424</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.812121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>0.684848</td>\n",
       "      <td>0.503030</td>\n",
       "      <td>0.593939</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.596970</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4</th>\n",
       "      <td>0.748485</td>\n",
       "      <td>0.642424</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.912121</td>\n",
       "      <td>0.815152</td>\n",
       "      <td>0.975758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-002</th>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.396970</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.875758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-003</th>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.339394</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.693939</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.875758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                 commonsense_qa    med_qa  medmc_qa  open_book_qa  \\\n",
       "model                                                                      \n",
       "command-xlarge-nightly        0.657576  0.263636  0.309091      0.572727   \n",
       "flan-T5-xxl                   0.833333  0.212121  0.342424      0.766667   \n",
       "gpt-3.5-turbo                 0.684848  0.503030  0.593939      0.757576   \n",
       "gpt-4                         0.748485  0.642424  0.781818      0.912121   \n",
       "text-davinci-002              0.690909  0.272727  0.396970      0.560606   \n",
       "text-davinci-003              0.690909  0.339394  0.393939      0.693939   \n",
       "\n",
       "dataset                 strategy_qa  worldtree  \n",
       "model                                           \n",
       "command-xlarge-nightly     0.248485   0.745455  \n",
       "flan-T5-xxl                0.618182   0.812121  \n",
       "gpt-3.5-turbo              0.596970   0.909091  \n",
       "gpt-4                      0.815152   0.975758  \n",
       "text-davinci-002           0.533333   0.875758  \n",
       "text-davinci-003           0.621212   0.875758  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = df.groupby([\"model\", \"dataset\"]).mean(\"correct_answer\").pivot_table(index=\"model\", columns=\"dataset\", values=\"correct_answer\")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>commonsense_qa</th>\n",
       "      <th>med_qa</th>\n",
       "      <th>medmc_qa</th>\n",
       "      <th>open_book_qa</th>\n",
       "      <th>strategy_qa</th>\n",
       "      <th>worldtree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>None_None</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.368687</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.868687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_kojima-01</th>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.373737</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.828283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_zhou-01</th>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.868687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-10_None</th>\n",
       "      <td>0.752525</td>\n",
       "      <td>0.358586</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.853535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-12_None</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.914141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-13_None</th>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.368687</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.656566</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-16_None</th>\n",
       "      <td>0.661616</td>\n",
       "      <td>0.398990</td>\n",
       "      <td>0.510101</td>\n",
       "      <td>0.661616</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-17_None</th>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.838384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refl-01_None</th>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.419192</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.489899</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zhou-01-ins_None</th>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.358586</td>\n",
       "      <td>0.434343</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.898990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset           commonsense_qa    med_qa  medmc_qa  open_book_qa  \\\n",
       "prompt                                                               \n",
       "None_None               0.722222  0.368687  0.454545      0.727273   \n",
       "None_kojima-01          0.696970  0.373737  0.424242      0.681818   \n",
       "None_zhou-01            0.717172  0.393939  0.530303      0.777778   \n",
       "qa-10_None              0.752525  0.358586  0.474747      0.722222   \n",
       "qa-12_None              0.722222  0.383838  0.494949      0.737374   \n",
       "qa-13_None              0.742424  0.368687  0.469697      0.656566   \n",
       "qa-16_None              0.661616  0.398990  0.510101      0.661616   \n",
       "qa-17_None              0.646465  0.363636  0.484848      0.696970   \n",
       "refl-01_None            0.757576  0.353535  0.419192      0.722222   \n",
       "zhou-01-ins_None        0.757576  0.358586  0.434343      0.722222   \n",
       "\n",
       "dataset           strategy_qa  worldtree  \n",
       "prompt                                    \n",
       "None_None            0.595960   0.868687  \n",
       "None_kojima-01       0.666667   0.828283  \n",
       "None_zhou-01         0.595960   0.868687  \n",
       "qa-10_None           0.520202   0.853535  \n",
       "qa-12_None           0.520202   0.914141  \n",
       "qa-13_None           0.606061   0.888889  \n",
       "qa-16_None           0.606061   0.833333  \n",
       "qa-17_None           0.590909   0.838384  \n",
       "refl-01_None         0.489899   0.863636  \n",
       "zhou-01-ins_None     0.530303   0.898990  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = df.groupby([\"prompt\", \"dataset\"]).mean(\"correct_answer\").pivot_table(index=\"prompt\", columns=\"dataset\", values=\"correct_answer\")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bootstrapping parameters\n",
    "n_bootstraps = 1000\n",
    "confidence_level = 0.95\n",
    "np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# Perform bootstrapping and calculate means and confidence intervals\n",
    "results = []\n",
    "\n",
    "for (model, prompt), group in df.groupby(['model', 'prompt']):\n",
    "    bootstrapped_means = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        resampled = group['correct_answer'].sample(n=len(group), replace=True)\n",
    "        bootstrapped_means.append(resampled.mean())\n",
    "    \n",
    "    mean = np.mean(bootstrapped_means)\n",
    "    lower = np.percentile(bootstrapped_means, (1 - confidence_level) / 2 * 100)\n",
    "    upper = np.percentile(bootstrapped_means, (1 + confidence_level) / 2 * 100)\n",
    "    \n",
    "    results.append({\n",
    "        'model': model,\n",
    "        'prompt': prompt,\n",
    "        'mean': mean,\n",
    "        'ci_lower': lower,\n",
    "        'ci_upper': upper\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame and pivot\n",
    "results_df = pd.DataFrame(results)\n",
    "mean_pivot = results_df.pivot_table(values='mean', index='model', columns='prompt')\n",
    "ci_pivot_lower = results_df.pivot_table(values='ci_lower', index='model', columns='prompt')\n",
    "ci_pivot_upper = results_df.pivot_table(values='ci_upper', index='model', columns='prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# every dataset seperately\n",
    "# Define bootstrapping parameters\n",
    "n_bootstraps = 1000\n",
    "confidence_level = 0.95\n",
    "np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# Perform bootstrapping and calculate means and confidence intervals\n",
    "results = []\n",
    "\n",
    "for (model, prompt, dataset), group in df.groupby(['model', 'prompt', 'dataset']):\n",
    "    bootstrapped_means = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        resampled = group['correct_answer'].sample(n=len(group), replace=True)\n",
    "        bootstrapped_means.append(resampled.mean())\n",
    "    \n",
    "    mean = np.mean(bootstrapped_means)\n",
    "    lower = np.percentile(bootstrapped_means, (1 - confidence_level) / 2 * 100)\n",
    "    upper = np.percentile(bootstrapped_means, (1 + confidence_level) / 2 * 100)\n",
    "    \n",
    "    results.append({\n",
    "        'dataset': dataset,\n",
    "        'model': model,\n",
    "        'prompt': prompt,\n",
    "        'mean': mean,\n",
    "        'ci_lower': lower,\n",
    "        'ci_upper': upper\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame and pivot\n",
    "results_df = pd.DataFrame(results)\n",
    "# mean_pivot = results_df.pivot_table(values='mean', index='model', columns='prompt')\n",
    "# ci_pivot_lower = results_df.pivot_table(values='ci_lower', index='model', columns='prompt')\n",
    "# ci_pivot_upper = results_df.pivot_table(values='ci_upper', index='model', columns='prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KRIPPENDORFF ALPHA\n",
    "# Define bootstrapping parameters\n",
    "n_bootstraps = 1000\n",
    "confidence_level = 0.95\n",
    "np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# Perform bootstrapping and calculate means and confidence intervals\n",
    "results = []\n",
    "\n",
    "for (model, prompt, dataset), group in df.groupby(['model', 'prompt', 'dataset']):\n",
    "    bootstrapped_means = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        answer_label = group['answer_label'].sample(n=len(group), replace=True)\n",
    "        indices = answer_label.index\n",
    "        answer_from_choices = group.loc[indices, 'answer_from_choices']\n",
    "\n",
    "        metric = krippendorff.alpha(reliability_data=[list(answer_label), list(answer_from_choices)],level_of_measurement='nominal')\n",
    "\n",
    "        bootstrapped_means.append(metric)\n",
    "    \n",
    "    mean = np.mean(bootstrapped_means)\n",
    "    lower = np.percentile(bootstrapped_means, (1 - confidence_level) / 2 * 100)\n",
    "    upper = np.percentile(bootstrapped_means, (1 + confidence_level) / 2 * 100)\n",
    "    \n",
    "    results.append({\n",
    "        'dataset': dataset,\n",
    "        'model': model,\n",
    "        'prompt': prompt,\n",
    "        'mean': mean,\n",
    "        'ci_lower': lower,\n",
    "        'ci_upper': upper\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame and pivot\n",
    "results_df = pd.DataFrame(results)\n",
    "# mean_pivot = results_df.pivot_table(values='mean', index='model', columns='prompt')\n",
    "# ci_pivot_lower = results_df.pivot_table(values='ci_lower', index='model', columns='prompt')\n",
    "# ci_pivot_upper = results_df.pivot_table(values='ci_upper', index='model', columns='prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_None</td>\n",
       "      <td>0.379762</td>\n",
       "      <td>0.167625</td>\n",
       "      <td>0.591751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_kojima-01</td>\n",
       "      <td>0.342267</td>\n",
       "      <td>0.117617</td>\n",
       "      <td>0.548108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_zhou-01</td>\n",
       "      <td>0.644224</td>\n",
       "      <td>0.444049</td>\n",
       "      <td>0.843281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>qa-10_None</td>\n",
       "      <td>0.610482</td>\n",
       "      <td>0.400533</td>\n",
       "      <td>0.805062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>qa-12_None</td>\n",
       "      <td>0.616859</td>\n",
       "      <td>0.400213</td>\n",
       "      <td>0.810719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>qa-13_None</td>\n",
       "      <td>0.688805</td>\n",
       "      <td>0.497202</td>\n",
       "      <td>0.877627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>qa-16_None</td>\n",
       "      <td>0.575817</td>\n",
       "      <td>0.367378</td>\n",
       "      <td>0.770895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>qa-17_None</td>\n",
       "      <td>0.501976</td>\n",
       "      <td>0.295127</td>\n",
       "      <td>0.703509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>refl-01_None</td>\n",
       "      <td>0.608241</td>\n",
       "      <td>0.394005</td>\n",
       "      <td>0.799259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>zhou-01-ins_None</td>\n",
       "      <td>0.654134</td>\n",
       "      <td>0.456700</td>\n",
       "      <td>0.841367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset                   model            prompt      mean  \\\n",
       "0   commonsense_qa  command-xlarge-nightly         None_None  0.379762   \n",
       "6   commonsense_qa  command-xlarge-nightly    None_kojima-01  0.342267   \n",
       "12  commonsense_qa  command-xlarge-nightly      None_zhou-01  0.644224   \n",
       "18  commonsense_qa  command-xlarge-nightly        qa-10_None  0.610482   \n",
       "24  commonsense_qa  command-xlarge-nightly        qa-12_None  0.616859   \n",
       "30  commonsense_qa  command-xlarge-nightly        qa-13_None  0.688805   \n",
       "36  commonsense_qa  command-xlarge-nightly        qa-16_None  0.575817   \n",
       "42  commonsense_qa  command-xlarge-nightly        qa-17_None  0.501976   \n",
       "48  commonsense_qa  command-xlarge-nightly      refl-01_None  0.608241   \n",
       "54  commonsense_qa  command-xlarge-nightly  zhou-01-ins_None  0.654134   \n",
       "\n",
       "    ci_lower  ci_upper  \n",
       "0   0.167625  0.591751  \n",
       "6   0.117617  0.548108  \n",
       "12  0.444049  0.843281  \n",
       "18  0.400533  0.805062  \n",
       "24  0.400213  0.810719  \n",
       "30  0.497202  0.877627  \n",
       "36  0.367378  0.770895  \n",
       "42  0.295127  0.703509  \n",
       "48  0.394005  0.799259  \n",
       "54  0.456700  0.841367  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = results_df[(results_df['dataset'] == 'commonsense_qa') & (results_df['model'] == 'command-xlarge-nightly')]\n",
    "filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_None</td>\n",
       "      <td>0.379762</td>\n",
       "      <td>0.167625</td>\n",
       "      <td>0.591751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_kojima-01</td>\n",
       "      <td>0.342267</td>\n",
       "      <td>0.117617</td>\n",
       "      <td>0.548108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_zhou-01</td>\n",
       "      <td>0.644224</td>\n",
       "      <td>0.444049</td>\n",
       "      <td>0.843281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>qa-10_None</td>\n",
       "      <td>0.610482</td>\n",
       "      <td>0.400533</td>\n",
       "      <td>0.805062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>qa-12_None</td>\n",
       "      <td>0.616859</td>\n",
       "      <td>0.400213</td>\n",
       "      <td>0.810719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>qa-13_None</td>\n",
       "      <td>0.688805</td>\n",
       "      <td>0.497202</td>\n",
       "      <td>0.877627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>qa-16_None</td>\n",
       "      <td>0.575817</td>\n",
       "      <td>0.367378</td>\n",
       "      <td>0.770895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>qa-17_None</td>\n",
       "      <td>0.501976</td>\n",
       "      <td>0.295127</td>\n",
       "      <td>0.703509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>refl-01_None</td>\n",
       "      <td>0.608241</td>\n",
       "      <td>0.394005</td>\n",
       "      <td>0.799259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>zhou-01-ins_None</td>\n",
       "      <td>0.654134</td>\n",
       "      <td>0.456700</td>\n",
       "      <td>0.841367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset                   model            prompt      mean  \\\n",
       "0   commonsense_qa  command-xlarge-nightly         None_None  0.379762   \n",
       "6   commonsense_qa  command-xlarge-nightly    None_kojima-01  0.342267   \n",
       "12  commonsense_qa  command-xlarge-nightly      None_zhou-01  0.644224   \n",
       "18  commonsense_qa  command-xlarge-nightly        qa-10_None  0.610482   \n",
       "24  commonsense_qa  command-xlarge-nightly        qa-12_None  0.616859   \n",
       "30  commonsense_qa  command-xlarge-nightly        qa-13_None  0.688805   \n",
       "36  commonsense_qa  command-xlarge-nightly        qa-16_None  0.575817   \n",
       "42  commonsense_qa  command-xlarge-nightly        qa-17_None  0.501976   \n",
       "48  commonsense_qa  command-xlarge-nightly      refl-01_None  0.608241   \n",
       "54  commonsense_qa  command-xlarge-nightly  zhou-01-ins_None  0.654134   \n",
       "\n",
       "    ci_lower  ci_upper  \n",
       "0   0.167625  0.591751  \n",
       "6   0.117617  0.548108  \n",
       "12  0.444049  0.843281  \n",
       "18  0.400533  0.805062  \n",
       "24  0.400213  0.810719  \n",
       "30  0.497202  0.877627  \n",
       "36  0.367378  0.770895  \n",
       "42  0.295127  0.703509  \n",
       "48  0.394005  0.799259  \n",
       "54  0.456700  0.841367  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_df = results_df[(results_df['dataset'] == 'strategy_qa') & (results_df['model'] == 'command-xlarge-nightly')]\n",
    "filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The problem is that I have to compute the difference of ci_lower to ci_mean first and then compute sqrt of the values squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_None</td>\n",
       "      <td>0.379762</td>\n",
       "      <td>0.167625</td>\n",
       "      <td>0.591751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>med_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_None</td>\n",
       "      <td>-0.008886</td>\n",
       "      <td>-0.158063</td>\n",
       "      <td>0.152357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medmc_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_None</td>\n",
       "      <td>0.032149</td>\n",
       "      <td>-0.160714</td>\n",
       "      <td>0.251061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open_book_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_None</td>\n",
       "      <td>0.411786</td>\n",
       "      <td>0.178722</td>\n",
       "      <td>0.636001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strategy_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>med_qa</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>zhou-01-ins_None</td>\n",
       "      <td>0.187988</td>\n",
       "      <td>0.006933</td>\n",
       "      <td>0.397459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>medmc_qa</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>zhou-01-ins_None</td>\n",
       "      <td>0.111358</td>\n",
       "      <td>-0.101770</td>\n",
       "      <td>0.330338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>open_book_qa</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>zhou-01-ins_None</td>\n",
       "      <td>0.747855</td>\n",
       "      <td>0.565523</td>\n",
       "      <td>0.917669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>strategy_qa</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>zhou-01-ins_None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>zhou-01-ins_None</td>\n",
       "      <td>0.829630</td>\n",
       "      <td>0.658074</td>\n",
       "      <td>0.959452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset                   model            prompt      mean  \\\n",
       "0    commonsense_qa  command-xlarge-nightly         None_None  0.379762   \n",
       "1            med_qa  command-xlarge-nightly         None_None -0.008886   \n",
       "2          medmc_qa  command-xlarge-nightly         None_None  0.032149   \n",
       "3      open_book_qa  command-xlarge-nightly         None_None  0.411786   \n",
       "4       strategy_qa  command-xlarge-nightly         None_None  1.000000   \n",
       "..              ...                     ...               ...       ...   \n",
       "355          med_qa        text-davinci-003  zhou-01-ins_None  0.187988   \n",
       "356        medmc_qa        text-davinci-003  zhou-01-ins_None  0.111358   \n",
       "357    open_book_qa        text-davinci-003  zhou-01-ins_None  0.747855   \n",
       "358     strategy_qa        text-davinci-003  zhou-01-ins_None  1.000000   \n",
       "359       worldtree        text-davinci-003  zhou-01-ins_None  0.829630   \n",
       "\n",
       "     ci_lower  ci_upper  \n",
       "0    0.167625  0.591751  \n",
       "1   -0.158063  0.152357  \n",
       "2   -0.160714  0.251061  \n",
       "3    0.178722  0.636001  \n",
       "4    1.000000  1.000000  \n",
       "..        ...       ...  \n",
       "355  0.006933  0.397459  \n",
       "356 -0.101770  0.330338  \n",
       "357  0.565523  0.917669  \n",
       "358  1.000000  1.000000  \n",
       "359  0.658074  0.959452  \n",
       "\n",
       "[360 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_function(x):\n",
    "    squared_values = x**2\n",
    "    return np.sqrt(squared_values.sum())\n",
    "\n",
    "# Group the DataFrame by 'model', 'prompt', and 'dataset'\n",
    "grouped_df = df.groupby(['model', 'prompt', 'dataset'])\n",
    "\n",
    "# Apply the custom function to each group\n",
    "custom_results = grouped_df.agg(custom_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6759/3233886831.py:1: FutureWarning: Dropping invalid columns in DataFrameGroupBy.agg is deprecated. In a future version, a TypeError will be raised. Before calling .agg, select only columns which should be valid for the function.\n",
      "  df.groupby(['model', 'prompt']).agg(custom_function)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">command-xlarge-nightly</th>\n",
       "      <th>None_None</th>\n",
       "      <td>1.241314</td>\n",
       "      <td>1.089474</td>\n",
       "      <td>1.528231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_kojima-01</th>\n",
       "      <td>1.089987</td>\n",
       "      <td>0.827710</td>\n",
       "      <td>1.425526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_zhou-01</th>\n",
       "      <td>1.091961</td>\n",
       "      <td>0.697572</td>\n",
       "      <td>1.536680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-10_None</th>\n",
       "      <td>1.012295</td>\n",
       "      <td>0.813503</td>\n",
       "      <td>1.350927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-12_None</th>\n",
       "      <td>1.079459</td>\n",
       "      <td>0.829556</td>\n",
       "      <td>1.447083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-13_None</th>\n",
       "      <td>1.195796</td>\n",
       "      <td>0.989189</td>\n",
       "      <td>1.511650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-16_None</th>\n",
       "      <td>1.089998</td>\n",
       "      <td>0.762856</td>\n",
       "      <td>1.523165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-17_None</th>\n",
       "      <td>0.909037</td>\n",
       "      <td>0.474838</td>\n",
       "      <td>1.392879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refl-01_None</th>\n",
       "      <td>1.061583</td>\n",
       "      <td>0.848915</td>\n",
       "      <td>1.387753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zhou-01-ins_None</th>\n",
       "      <td>1.173808</td>\n",
       "      <td>0.970207</td>\n",
       "      <td>1.495002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">flan-T5-xxl</th>\n",
       "      <th>None_None</th>\n",
       "      <td>1.674424</td>\n",
       "      <td>1.457095</td>\n",
       "      <td>1.940163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_kojima-01</th>\n",
       "      <td>1.649051</td>\n",
       "      <td>1.423904</td>\n",
       "      <td>1.897808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_zhou-01</th>\n",
       "      <td>1.549017</td>\n",
       "      <td>1.215815</td>\n",
       "      <td>1.896926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-10_None</th>\n",
       "      <td>1.648143</td>\n",
       "      <td>1.427552</td>\n",
       "      <td>1.895562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-12_None</th>\n",
       "      <td>1.713612</td>\n",
       "      <td>1.494980</td>\n",
       "      <td>1.945492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-13_None</th>\n",
       "      <td>1.618413</td>\n",
       "      <td>1.380689</td>\n",
       "      <td>1.866871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-16_None</th>\n",
       "      <td>1.421127</td>\n",
       "      <td>1.221863</td>\n",
       "      <td>1.705495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-17_None</th>\n",
       "      <td>1.605361</td>\n",
       "      <td>1.370889</td>\n",
       "      <td>1.890703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refl-01_None</th>\n",
       "      <td>1.636359</td>\n",
       "      <td>1.350920</td>\n",
       "      <td>1.918262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zhou-01-ins_None</th>\n",
       "      <td>1.626880</td>\n",
       "      <td>1.408275</td>\n",
       "      <td>1.869233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">gpt-3.5-turbo</th>\n",
       "      <th>None_None</th>\n",
       "      <td>1.739306</td>\n",
       "      <td>1.325418</td>\n",
       "      <td>2.125028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_kojima-01</th>\n",
       "      <td>1.556716</td>\n",
       "      <td>1.119960</td>\n",
       "      <td>1.962951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_zhou-01</th>\n",
       "      <td>1.620638</td>\n",
       "      <td>1.197891</td>\n",
       "      <td>2.037962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-10_None</th>\n",
       "      <td>1.475451</td>\n",
       "      <td>1.020739</td>\n",
       "      <td>1.906597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-12_None</th>\n",
       "      <td>1.550899</td>\n",
       "      <td>1.106139</td>\n",
       "      <td>1.974751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-13_None</th>\n",
       "      <td>1.570305</td>\n",
       "      <td>1.195914</td>\n",
       "      <td>1.958496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-16_None</th>\n",
       "      <td>1.480640</td>\n",
       "      <td>1.002305</td>\n",
       "      <td>1.944308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-17_None</th>\n",
       "      <td>1.626976</td>\n",
       "      <td>1.202983</td>\n",
       "      <td>2.030203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refl-01_None</th>\n",
       "      <td>1.470504</td>\n",
       "      <td>1.019652</td>\n",
       "      <td>1.913693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zhou-01-ins_None</th>\n",
       "      <td>1.545990</td>\n",
       "      <td>1.178499</td>\n",
       "      <td>1.909527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">gpt-4</th>\n",
       "      <th>None_None</th>\n",
       "      <td>1.944968</td>\n",
       "      <td>1.598623</td>\n",
       "      <td>2.240375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_kojima-01</th>\n",
       "      <td>2.030896</td>\n",
       "      <td>1.753762</td>\n",
       "      <td>2.282689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_zhou-01</th>\n",
       "      <td>2.090378</td>\n",
       "      <td>1.829292</td>\n",
       "      <td>2.324307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-10_None</th>\n",
       "      <td>2.011531</td>\n",
       "      <td>1.679062</td>\n",
       "      <td>2.272574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-12_None</th>\n",
       "      <td>1.882386</td>\n",
       "      <td>1.564116</td>\n",
       "      <td>2.198962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-13_None</th>\n",
       "      <td>1.998585</td>\n",
       "      <td>1.766875</td>\n",
       "      <td>2.236025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-16_None</th>\n",
       "      <td>1.935845</td>\n",
       "      <td>1.641368</td>\n",
       "      <td>2.227457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-17_None</th>\n",
       "      <td>1.880984</td>\n",
       "      <td>1.610620</td>\n",
       "      <td>2.147270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refl-01_None</th>\n",
       "      <td>1.906924</td>\n",
       "      <td>1.577620</td>\n",
       "      <td>2.215068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zhou-01-ins_None</th>\n",
       "      <td>1.936998</td>\n",
       "      <td>1.566946</td>\n",
       "      <td>2.262292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">text-davinci-002</th>\n",
       "      <th>None_None</th>\n",
       "      <td>1.365005</td>\n",
       "      <td>0.980056</td>\n",
       "      <td>1.760428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_kojima-01</th>\n",
       "      <td>1.284387</td>\n",
       "      <td>0.920053</td>\n",
       "      <td>1.683092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_zhou-01</th>\n",
       "      <td>1.449094</td>\n",
       "      <td>1.076456</td>\n",
       "      <td>1.854100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-10_None</th>\n",
       "      <td>1.363100</td>\n",
       "      <td>1.010836</td>\n",
       "      <td>1.769689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-12_None</th>\n",
       "      <td>1.403015</td>\n",
       "      <td>1.070128</td>\n",
       "      <td>1.779926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-13_None</th>\n",
       "      <td>1.424398</td>\n",
       "      <td>1.081639</td>\n",
       "      <td>1.794640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-16_None</th>\n",
       "      <td>1.356822</td>\n",
       "      <td>0.953245</td>\n",
       "      <td>1.771314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-17_None</th>\n",
       "      <td>1.118038</td>\n",
       "      <td>0.735880</td>\n",
       "      <td>1.531888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refl-01_None</th>\n",
       "      <td>1.346799</td>\n",
       "      <td>0.953217</td>\n",
       "      <td>1.752739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zhou-01-ins_None</th>\n",
       "      <td>1.439003</td>\n",
       "      <td>1.148343</td>\n",
       "      <td>1.762589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">text-davinci-003</th>\n",
       "      <th>None_None</th>\n",
       "      <td>1.528794</td>\n",
       "      <td>1.207971</td>\n",
       "      <td>1.852601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_kojima-01</th>\n",
       "      <td>1.459057</td>\n",
       "      <td>1.127275</td>\n",
       "      <td>1.827988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None_zhou-01</th>\n",
       "      <td>1.602936</td>\n",
       "      <td>1.317066</td>\n",
       "      <td>1.921515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-10_None</th>\n",
       "      <td>1.532028</td>\n",
       "      <td>1.157423</td>\n",
       "      <td>1.891545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-12_None</th>\n",
       "      <td>1.647469</td>\n",
       "      <td>1.320008</td>\n",
       "      <td>1.946179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-13_None</th>\n",
       "      <td>1.510099</td>\n",
       "      <td>1.267027</td>\n",
       "      <td>1.819927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-16_None</th>\n",
       "      <td>1.463050</td>\n",
       "      <td>1.222241</td>\n",
       "      <td>1.777473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa-17_None</th>\n",
       "      <td>1.580726</td>\n",
       "      <td>1.369923</td>\n",
       "      <td>1.857851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refl-01_None</th>\n",
       "      <td>1.565606</td>\n",
       "      <td>1.232998</td>\n",
       "      <td>1.892271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zhou-01-ins_None</th>\n",
       "      <td>1.648273</td>\n",
       "      <td>1.406848</td>\n",
       "      <td>1.921574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             mean  ci_lower  ci_upper\n",
       "model                  prompt                                        \n",
       "command-xlarge-nightly None_None         1.241314  1.089474  1.528231\n",
       "                       None_kojima-01    1.089987  0.827710  1.425526\n",
       "                       None_zhou-01      1.091961  0.697572  1.536680\n",
       "                       qa-10_None        1.012295  0.813503  1.350927\n",
       "                       qa-12_None        1.079459  0.829556  1.447083\n",
       "                       qa-13_None        1.195796  0.989189  1.511650\n",
       "                       qa-16_None        1.089998  0.762856  1.523165\n",
       "                       qa-17_None        0.909037  0.474838  1.392879\n",
       "                       refl-01_None      1.061583  0.848915  1.387753\n",
       "                       zhou-01-ins_None  1.173808  0.970207  1.495002\n",
       "flan-T5-xxl            None_None         1.674424  1.457095  1.940163\n",
       "                       None_kojima-01    1.649051  1.423904  1.897808\n",
       "                       None_zhou-01      1.549017  1.215815  1.896926\n",
       "                       qa-10_None        1.648143  1.427552  1.895562\n",
       "                       qa-12_None        1.713612  1.494980  1.945492\n",
       "                       qa-13_None        1.618413  1.380689  1.866871\n",
       "                       qa-16_None        1.421127  1.221863  1.705495\n",
       "                       qa-17_None        1.605361  1.370889  1.890703\n",
       "                       refl-01_None      1.636359  1.350920  1.918262\n",
       "                       zhou-01-ins_None  1.626880  1.408275  1.869233\n",
       "gpt-3.5-turbo          None_None         1.739306  1.325418  2.125028\n",
       "                       None_kojima-01    1.556716  1.119960  1.962951\n",
       "                       None_zhou-01      1.620638  1.197891  2.037962\n",
       "                       qa-10_None        1.475451  1.020739  1.906597\n",
       "                       qa-12_None        1.550899  1.106139  1.974751\n",
       "                       qa-13_None        1.570305  1.195914  1.958496\n",
       "                       qa-16_None        1.480640  1.002305  1.944308\n",
       "                       qa-17_None        1.626976  1.202983  2.030203\n",
       "                       refl-01_None      1.470504  1.019652  1.913693\n",
       "                       zhou-01-ins_None  1.545990  1.178499  1.909527\n",
       "gpt-4                  None_None         1.944968  1.598623  2.240375\n",
       "                       None_kojima-01    2.030896  1.753762  2.282689\n",
       "                       None_zhou-01      2.090378  1.829292  2.324307\n",
       "                       qa-10_None        2.011531  1.679062  2.272574\n",
       "                       qa-12_None        1.882386  1.564116  2.198962\n",
       "                       qa-13_None        1.998585  1.766875  2.236025\n",
       "                       qa-16_None        1.935845  1.641368  2.227457\n",
       "                       qa-17_None        1.880984  1.610620  2.147270\n",
       "                       refl-01_None      1.906924  1.577620  2.215068\n",
       "                       zhou-01-ins_None  1.936998  1.566946  2.262292\n",
       "text-davinci-002       None_None         1.365005  0.980056  1.760428\n",
       "                       None_kojima-01    1.284387  0.920053  1.683092\n",
       "                       None_zhou-01      1.449094  1.076456  1.854100\n",
       "                       qa-10_None        1.363100  1.010836  1.769689\n",
       "                       qa-12_None        1.403015  1.070128  1.779926\n",
       "                       qa-13_None        1.424398  1.081639  1.794640\n",
       "                       qa-16_None        1.356822  0.953245  1.771314\n",
       "                       qa-17_None        1.118038  0.735880  1.531888\n",
       "                       refl-01_None      1.346799  0.953217  1.752739\n",
       "                       zhou-01-ins_None  1.439003  1.148343  1.762589\n",
       "text-davinci-003       None_None         1.528794  1.207971  1.852601\n",
       "                       None_kojima-01    1.459057  1.127275  1.827988\n",
       "                       None_zhou-01      1.602936  1.317066  1.921515\n",
       "                       qa-10_None        1.532028  1.157423  1.891545\n",
       "                       qa-12_None        1.647469  1.320008  1.946179\n",
       "                       qa-13_None        1.510099  1.267027  1.819927\n",
       "                       qa-16_None        1.463050  1.222241  1.777473\n",
       "                       qa-17_None        1.580726  1.369923  1.857851\n",
       "                       refl-01_None      1.565606  1.232998  1.892271\n",
       "                       zhou-01-ins_None  1.648273  1.406848  1.921574"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['model', 'prompt']).agg(custom_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">command-xlarge-nightly</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">None_None</th>\n",
       "      <th>commonsense_qa</th>\n",
       "      <td>0.379762</td>\n",
       "      <td>0.167625</td>\n",
       "      <td>0.591751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_qa</th>\n",
       "      <td>0.008886</td>\n",
       "      <td>0.158063</td>\n",
       "      <td>0.152357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medmc_qa</th>\n",
       "      <td>0.032149</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.251061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_book_qa</th>\n",
       "      <td>0.411786</td>\n",
       "      <td>0.178722</td>\n",
       "      <td>0.636001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategy_qa</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">text-davinci-003</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">zhou-01-ins_None</th>\n",
       "      <th>med_qa</th>\n",
       "      <td>0.187988</td>\n",
       "      <td>0.006933</td>\n",
       "      <td>0.397459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medmc_qa</th>\n",
       "      <td>0.111358</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>0.330338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_book_qa</th>\n",
       "      <td>0.747855</td>\n",
       "      <td>0.565523</td>\n",
       "      <td>0.917669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategy_qa</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldtree</th>\n",
       "      <td>0.829630</td>\n",
       "      <td>0.658074</td>\n",
       "      <td>0.959452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            mean  ci_lower  \\\n",
       "model                  prompt           dataset                              \n",
       "command-xlarge-nightly None_None        commonsense_qa  0.379762  0.167625   \n",
       "                                        med_qa          0.008886  0.158063   \n",
       "                                        medmc_qa        0.032149  0.160714   \n",
       "                                        open_book_qa    0.411786  0.178722   \n",
       "                                        strategy_qa     1.000000  1.000000   \n",
       "...                                                          ...       ...   \n",
       "text-davinci-003       zhou-01-ins_None med_qa          0.187988  0.006933   \n",
       "                                        medmc_qa        0.111358  0.101770   \n",
       "                                        open_book_qa    0.747855  0.565523   \n",
       "                                        strategy_qa     1.000000  1.000000   \n",
       "                                        worldtree       0.829630  0.658074   \n",
       "\n",
       "                                                        ci_upper  \n",
       "model                  prompt           dataset                   \n",
       "command-xlarge-nightly None_None        commonsense_qa  0.591751  \n",
       "                                        med_qa          0.152357  \n",
       "                                        medmc_qa        0.251061  \n",
       "                                        open_book_qa    0.636001  \n",
       "                                        strategy_qa     1.000000  \n",
       "...                                                          ...  \n",
       "text-davinci-003       zhou-01-ins_None med_qa          0.397459  \n",
       "                                        medmc_qa        0.330338  \n",
       "                                        open_book_qa    0.917669  \n",
       "                                        strategy_qa     1.000000  \n",
       "                                        worldtree       0.959452  \n",
       "\n",
       "[360 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bootstrapping parameters\n",
    "n_bootstraps = 1000\n",
    "confidence_level = 0.95\n",
    "np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# Perform bootstrapping and calculate means and confidence intervals\n",
    "results = []\n",
    "\n",
    "for (model, prompt, dataset), group in df.groupby(['model', 'prompt', 'dataset']):\n",
    "    bootstrapped_means = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        resampled = group['correct_answer'].sample(n=len(group), replace=True)\n",
    "        bootstrapped_means.append(resampled.mean())\n",
    "    \n",
    "    mean = np.mean(bootstrapped_means)\n",
    "    lower = np.percentile(bootstrapped_means, (1 - confidence_level) / 2 * 100)\n",
    "    upper = np.percentile(bootstrapped_means, (1 + confidence_level) / 2 * 100)\n",
    "    \n",
    "    results.append({\n",
    "        'dataset': dataset,\n",
    "        'model': model,\n",
    "        'prompt': prompt,\n",
    "        'mean': mean,\n",
    "        'ci_lower': lower,\n",
    "        'ci_upper': upper\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame and pivot\n",
    "results_df = pd.DataFrame(results)\n",
    "mean_pivot = results_df.pivot_table(values='mean', index='model', columns='prompt')\n",
    "ci_pivot_lower = results_df.pivot_table(values='ci_lower', index='model', columns='prompt')\n",
    "ci_pivot_upper = results_df.pivot_table(values='ci_upper', index='model', columns='prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_None</td>\n",
       "      <td>0.5139</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.6970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>med_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_None</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.3030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medmc_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_None</td>\n",
       "      <td>0.2764</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.4545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open_book_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_None</td>\n",
       "      <td>0.5718</td>\n",
       "      <td>0.3939</td>\n",
       "      <td>0.7273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strategy_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>None_None</td>\n",
       "      <td>0.5385</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.6970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>med_qa</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>zhou-01-ins_None</td>\n",
       "      <td>0.3573</td>\n",
       "      <td>0.2121</td>\n",
       "      <td>0.5152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>medmc_qa</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>zhou-01-ins_None</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.4848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>open_book_qa</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>zhou-01-ins_None</td>\n",
       "      <td>0.8153</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.9394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>strategy_qa</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>zhou-01-ins_None</td>\n",
       "      <td>0.6358</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.7879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>zhou-01-ins_None</td>\n",
       "      <td>0.8771</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.9697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset                   model            prompt   mean  \\\n",
       "0    commonsense_qa  command-xlarge-nightly         None_None 0.5139   \n",
       "1            med_qa  command-xlarge-nightly         None_None 0.1840   \n",
       "2          medmc_qa  command-xlarge-nightly         None_None 0.2764   \n",
       "3      open_book_qa  command-xlarge-nightly         None_None 0.5718   \n",
       "4       strategy_qa  command-xlarge-nightly         None_None 0.5385   \n",
       "..              ...                     ...               ...    ...   \n",
       "355          med_qa        text-davinci-003  zhou-01-ins_None 0.3573   \n",
       "356        medmc_qa        text-davinci-003  zhou-01-ins_None 0.3257   \n",
       "357    open_book_qa        text-davinci-003  zhou-01-ins_None 0.8153   \n",
       "358     strategy_qa        text-davinci-003  zhou-01-ins_None 0.6358   \n",
       "359       worldtree        text-davinci-003  zhou-01-ins_None 0.8771   \n",
       "\n",
       "     ci_lower  ci_upper  \n",
       "0      0.3636    0.6970  \n",
       "1      0.0606    0.3030  \n",
       "2      0.1212    0.4545  \n",
       "3      0.3939    0.7273  \n",
       "4      0.3636    0.6970  \n",
       "..        ...       ...  \n",
       "355    0.2121    0.5152  \n",
       "356    0.1811    0.4848  \n",
       "357    0.6970    0.9394  \n",
       "358    0.4848    0.7879  \n",
       "359    0.7576    0.9697  \n",
       "\n",
       "[360 rows x 6 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "command-xlarge-nightly    0.449747\n",
       "flan-T5-xxl               0.620707\n",
       "gpt-3.5-turbo             0.711854\n",
       "gpt-4                     0.792465\n",
       "text-davinci-002          0.566076\n",
       "text-davinci-003          0.594848\n",
       "Name: None_None, dtype: float64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pivot[\"None_None\"]\n",
    "ci_pivot_lower[\"None_None\"]\n",
    "ci_pivot_upper[\"None_None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142.56"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.72*198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:.4f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcccccccccc}\n",
      "\\toprule\n",
      "prompt &                              None_None &                         None_kojima-01 &                           None_zhou-01 &                             qa-10_None &                             qa-12_None &                             qa-13_None &                             qa-16_None &                             qa-17_None &                           refl-01_None &                       zhou-01-ins_None \\\\\n",
      "model                  &                                        &                                        &                                        &                                        &                                        &                                        &                                        &                                        &                                        &                                        \\\\\n",
      "\\midrule\n",
      "command-xlarge-nightly &  0.4497 ({\\scriptsize 0.3838, 0.5152}) &  0.4239 ({\\scriptsize 0.3535, 0.4899}) &   0.506 ({\\scriptsize 0.4343, 0.5707}) &  0.4443 ({\\scriptsize 0.3737, 0.5202}) &  0.4597 ({\\scriptsize 0.3939, 0.5254}) &  0.4861 ({\\scriptsize 0.4192, 0.5606}) &  0.5141 ({\\scriptsize 0.4495, 0.5859}) &   0.4715 ({\\scriptsize 0.404, 0.5455}) &  0.4348 ({\\scriptsize 0.3687, 0.5051}) &  0.4757 ({\\scriptsize 0.4091, 0.5404}) \\\\\n",
      "flan-T5-xxl            &  0.6207 ({\\scriptsize 0.5505, 0.6869}) &  0.6191 ({\\scriptsize 0.5505, 0.6869}) &   0.577 ({\\scriptsize 0.5051, 0.6415}) &  0.6009 ({\\scriptsize 0.5352, 0.6667}) &   0.6307 ({\\scriptsize 0.5657, 0.697}) &  0.6117 ({\\scriptsize 0.5455, 0.6768}) &  0.5407 ({\\scriptsize 0.4697, 0.6061}) &  0.6108 ({\\scriptsize 0.5455, 0.6769}) &     0.5716 ({\\scriptsize 0.5, 0.6414}) &  0.5902 ({\\scriptsize 0.5253, 0.6566}) \\\\\n",
      "gpt-3.5-turbo          &  0.7119 ({\\scriptsize 0.6515, 0.7778}) &  0.6873 ({\\scriptsize 0.6212, 0.7475}) &  0.6967 ({\\scriptsize 0.6364, 0.7576}) &    0.666 ({\\scriptsize 0.601, 0.7273}) &    0.667 ({\\scriptsize 0.596, 0.7323}) &   0.655 ({\\scriptsize 0.5859, 0.7222}) &  0.6526 ({\\scriptsize 0.5909, 0.7172}) &  0.6824 ({\\scriptsize 0.6162, 0.7475}) &   0.652 ({\\scriptsize 0.5908, 0.7121}) &  0.6735 ({\\scriptsize 0.6111, 0.7424}) \\\\\n",
      "gpt-4                  &  0.7925 ({\\scriptsize 0.7374, 0.8485}) &   0.834 ({\\scriptsize 0.7778, 0.8838}) &  0.8619 ({\\scriptsize 0.8131, 0.9091}) &  0.8328 ({\\scriptsize 0.7778, 0.8838}) &  0.7981 ({\\scriptsize 0.7424, 0.8535}) &  0.8185 ({\\scriptsize 0.7626, 0.8737}) &  0.7971 ({\\scriptsize 0.7424, 0.8485}) &  0.7759 ({\\scriptsize 0.7221, 0.8283}) &  0.7975 ({\\scriptsize 0.7374, 0.8535}) &  0.8122 ({\\scriptsize 0.7576, 0.8636}) \\\\\n",
      "text-davinci-002       &  0.5661 ({\\scriptsize 0.4949, 0.6364}) &  0.5246 ({\\scriptsize 0.4495, 0.5859}) &  0.6101 ({\\scriptsize 0.5404, 0.6718}) &  0.5317 ({\\scriptsize 0.4646, 0.5961}) &  0.5812 ({\\scriptsize 0.5101, 0.6465}) &  0.5652 ({\\scriptsize 0.4949, 0.6314}) &  0.6107 ({\\scriptsize 0.5455, 0.6717}) &  0.4945 ({\\scriptsize 0.4242, 0.5607}) &    0.54 ({\\scriptsize 0.4747, 0.6111}) &    0.525 ({\\scriptsize 0.4595, 0.596}) \\\\\n",
      "text-davinci-003       &  0.5948 ({\\scriptsize 0.5253, 0.6616}) &  0.5802 ({\\scriptsize 0.5101, 0.6465}) &   0.6322 ({\\scriptsize 0.5657, 0.697}) &  0.6054 ({\\scriptsize 0.5404, 0.6717}) &   0.6346 ({\\scriptsize 0.5657, 0.702}) &  0.5952 ({\\scriptsize 0.5253, 0.6667}) &  0.5553 ({\\scriptsize 0.4898, 0.6263}) &  0.5851 ({\\scriptsize 0.5202, 0.6515}) &  0.6121 ({\\scriptsize 0.5404, 0.6768}) &   0.626 ({\\scriptsize 0.5556, 0.6919}) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1390/2982337073.py:9: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = final_df.to_latex(column_format=\"l\" + \"c\" * len(final_df.columns), float_format=\"{:.2f}\".format, escape=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine the DataFrames\n",
    "final_df = mean_pivot.copy()\n",
    "for col in mean_pivot.columns:\n",
    "    final_df[col] = mean_pivot[col].round(4).astype(str) + \" ({\\\\scriptsize \" + ci_pivot_lower[col].round(4).astype(str) + \", \" + ci_pivot_upper[col].round(4).astype(str) + \"})\"\n",
    "\n",
    "# Apply custom formatting (use LaTeX format for a scientific paper)\n",
    "latex_table = final_df.to_latex(column_format=\"l\" + \"c\" * len(final_df.columns), float_format=\"{:.2f}\".format, escape=False)\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcccccccccc}\n",
      "\\toprule\n",
      "prompt &                              None_None &                         None_kojima-01 &                           None_zhou-01 &                             qa-10_None &                             qa-12_None &                             qa-13_None &                             qa-16_None &                             qa-17_None &                           refl-01_None &                       zhou-01-ins_None \\\\\n",
      "model                  &                                        &                                        &                                        &                                        &                                        &                                        &                                        &                                        &                                        &                                        \\\\\n",
      "\\midrule\n",
      "command-xlarge-nightly &  0.4497 ({\\scriptsize 0.3838, 0.5152}) &  0.4239 ({\\scriptsize 0.3535, 0.4899}) &   0.506 ({\\scriptsize 0.4343, 0.5707}) &  0.4443 ({\\scriptsize 0.3737, 0.5202}) &  0.4597 ({\\scriptsize 0.3939, 0.5254}) &  0.4861 ({\\scriptsize 0.4192, 0.5606}) &  0.5141 ({\\scriptsize 0.4495, 0.5859}) &   0.4715 ({\\scriptsize 0.404, 0.5455}) &  0.4348 ({\\scriptsize 0.3687, 0.5051}) &  0.4757 ({\\scriptsize 0.4091, 0.5404}) \\\\\n",
      "flan-T5-xxl            &  0.6207 ({\\scriptsize 0.5505, 0.6869}) &  0.6191 ({\\scriptsize 0.5505, 0.6869}) &   0.577 ({\\scriptsize 0.5051, 0.6415}) &  0.6009 ({\\scriptsize 0.5352, 0.6667}) &   0.6307 ({\\scriptsize 0.5657, 0.697}) &  0.6117 ({\\scriptsize 0.5455, 0.6768}) &  0.5407 ({\\scriptsize 0.4697, 0.6061}) &  0.6108 ({\\scriptsize 0.5455, 0.6769}) &     0.5716 ({\\scriptsize 0.5, 0.6414}) &  0.5902 ({\\scriptsize 0.5253, 0.6566}) \\\\\n",
      "gpt-3.5-turbo          &  0.7119 ({\\scriptsize 0.6515, 0.7778}) &  0.6873 ({\\scriptsize 0.6212, 0.7475}) &  0.6967 ({\\scriptsize 0.6364, 0.7576}) &    0.666 ({\\scriptsize 0.601, 0.7273}) &    0.667 ({\\scriptsize 0.596, 0.7323}) &   0.655 ({\\scriptsize 0.5859, 0.7222}) &  0.6526 ({\\scriptsize 0.5909, 0.7172}) &  0.6824 ({\\scriptsize 0.6162, 0.7475}) &   0.652 ({\\scriptsize 0.5908, 0.7121}) &  0.6735 ({\\scriptsize 0.6111, 0.7424}) \\\\\n",
      "gpt-4                  &  0.7925 ({\\scriptsize 0.7374, 0.8485}) &   0.834 ({\\scriptsize 0.7778, 0.8838}) &  0.8619 ({\\scriptsize 0.8131, 0.9091}) &  0.8328 ({\\scriptsize 0.7778, 0.8838}) &  0.7981 ({\\scriptsize 0.7424, 0.8535}) &  0.8185 ({\\scriptsize 0.7626, 0.8737}) &  0.7971 ({\\scriptsize 0.7424, 0.8485}) &  0.7759 ({\\scriptsize 0.7221, 0.8283}) &  0.7975 ({\\scriptsize 0.7374, 0.8535}) &  0.8122 ({\\scriptsize 0.7576, 0.8636}) \\\\\n",
      "text-davinci-002       &  0.5661 ({\\scriptsize 0.4949, 0.6364}) &  0.5246 ({\\scriptsize 0.4495, 0.5859}) &  0.6101 ({\\scriptsize 0.5404, 0.6718}) &  0.5317 ({\\scriptsize 0.4646, 0.5961}) &  0.5812 ({\\scriptsize 0.5101, 0.6465}) &  0.5652 ({\\scriptsize 0.4949, 0.6314}) &  0.6107 ({\\scriptsize 0.5455, 0.6717}) &  0.4945 ({\\scriptsize 0.4242, 0.5607}) &    0.54 ({\\scriptsize 0.4747, 0.6111}) &    0.525 ({\\scriptsize 0.4595, 0.596}) \\\\\n",
      "text-davinci-003       &  0.5948 ({\\scriptsize 0.5253, 0.6616}) &  0.5802 ({\\scriptsize 0.5101, 0.6465}) &   0.6322 ({\\scriptsize 0.5657, 0.697}) &  0.6054 ({\\scriptsize 0.5404, 0.6717}) &   0.6346 ({\\scriptsize 0.5657, 0.702}) &  0.5952 ({\\scriptsize 0.5253, 0.6667}) &  0.5553 ({\\scriptsize 0.4898, 0.6263}) &  0.5851 ({\\scriptsize 0.5202, 0.6515}) &  0.6121 ({\\scriptsize 0.5404, 0.6768}) &   0.626 ({\\scriptsize 0.5556, 0.6919}) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{tabular}{lcc}\n",
    "\\toprule\n",
    "Prompt &                p1 &                p2 \\\\\n",
    "Model &                   &                   \\\\\n",
    "\\midrule\n",
    "A     &  0.5 (0.25, 0.75) &  0.5 (0.25, 0.75) \\\\\n",
    "B     &   0.75 (0.5, 1.0) &  0.5 (0.25, 0.75) \\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cot.stats import evaluation_as_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9183aa7fa1545f8a007107e3ad53def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bffce36316b4ba5bbbd14b374a8ad56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ecf6a34d1f4c46a441503d7efa1991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea296783f6c438890b9e7c27db951a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f52a0fa56f44f6ea64c31828d365b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c96752b8e6448aa29aa5f972d28b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kon/work/ThoughtSource/libs/cot/cot/stats.py:406: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  df.loc[dataset, (instruction + \"_\" + cot_trigger, model)] = v\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7091b_row0_col21, #T_7091b_row1_col15, #T_7091b_row2_col15, #T_7091b_row3_col15, #T_7091b_row4_col15, #T_7091b_row5_col27, #T_7091b_row6_col15 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7091b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7091b_level0_col0\" class=\"col_heading level0 col0\" colspan=\"6\">None_None</th>\n",
       "      <th id=\"T_7091b_level0_col6\" class=\"col_heading level0 col6\" colspan=\"6\">None_kojima-01</th>\n",
       "      <th id=\"T_7091b_level0_col12\" class=\"col_heading level0 col12\" colspan=\"6\">None_zhou-01</th>\n",
       "      <th id=\"T_7091b_level0_col18\" class=\"col_heading level0 col18\" colspan=\"6\">qa-10_None</th>\n",
       "      <th id=\"T_7091b_level0_col24\" class=\"col_heading level0 col24\" colspan=\"6\">qa-12_None</th>\n",
       "      <th id=\"T_7091b_level0_col30\" class=\"col_heading level0 col30\" colspan=\"6\">qa-13_None</th>\n",
       "      <th id=\"T_7091b_level0_col36\" class=\"col_heading level0 col36\" colspan=\"6\">qa-16_None</th>\n",
       "      <th id=\"T_7091b_level0_col42\" class=\"col_heading level0 col42\" colspan=\"6\">qa-17_None</th>\n",
       "      <th id=\"T_7091b_level0_col48\" class=\"col_heading level0 col48\" colspan=\"6\">refl-01_None</th>\n",
       "      <th id=\"T_7091b_level0_col54\" class=\"col_heading level0 col54\" colspan=\"6\">zhou-01-ins_None</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_7091b_level1_col0\" class=\"col_heading level1 col0\" >command-xlarge-nightly</th>\n",
       "      <th id=\"T_7091b_level1_col1\" class=\"col_heading level1 col1\" >flan-T5-xxl</th>\n",
       "      <th id=\"T_7091b_level1_col2\" class=\"col_heading level1 col2\" >gpt-3.5-turbo</th>\n",
       "      <th id=\"T_7091b_level1_col3\" class=\"col_heading level1 col3\" >gpt-4</th>\n",
       "      <th id=\"T_7091b_level1_col4\" class=\"col_heading level1 col4\" >text-davinci-002</th>\n",
       "      <th id=\"T_7091b_level1_col5\" class=\"col_heading level1 col5\" >text-davinci-003</th>\n",
       "      <th id=\"T_7091b_level1_col6\" class=\"col_heading level1 col6\" >command-xlarge-nightly</th>\n",
       "      <th id=\"T_7091b_level1_col7\" class=\"col_heading level1 col7\" >flan-T5-xxl</th>\n",
       "      <th id=\"T_7091b_level1_col8\" class=\"col_heading level1 col8\" >gpt-3.5-turbo</th>\n",
       "      <th id=\"T_7091b_level1_col9\" class=\"col_heading level1 col9\" >gpt-4</th>\n",
       "      <th id=\"T_7091b_level1_col10\" class=\"col_heading level1 col10\" >text-davinci-002</th>\n",
       "      <th id=\"T_7091b_level1_col11\" class=\"col_heading level1 col11\" >text-davinci-003</th>\n",
       "      <th id=\"T_7091b_level1_col12\" class=\"col_heading level1 col12\" >command-xlarge-nightly</th>\n",
       "      <th id=\"T_7091b_level1_col13\" class=\"col_heading level1 col13\" >flan-T5-xxl</th>\n",
       "      <th id=\"T_7091b_level1_col14\" class=\"col_heading level1 col14\" >gpt-3.5-turbo</th>\n",
       "      <th id=\"T_7091b_level1_col15\" class=\"col_heading level1 col15\" >gpt-4</th>\n",
       "      <th id=\"T_7091b_level1_col16\" class=\"col_heading level1 col16\" >text-davinci-002</th>\n",
       "      <th id=\"T_7091b_level1_col17\" class=\"col_heading level1 col17\" >text-davinci-003</th>\n",
       "      <th id=\"T_7091b_level1_col18\" class=\"col_heading level1 col18\" >command-xlarge-nightly</th>\n",
       "      <th id=\"T_7091b_level1_col19\" class=\"col_heading level1 col19\" >flan-T5-xxl</th>\n",
       "      <th id=\"T_7091b_level1_col20\" class=\"col_heading level1 col20\" >gpt-3.5-turbo</th>\n",
       "      <th id=\"T_7091b_level1_col21\" class=\"col_heading level1 col21\" >gpt-4</th>\n",
       "      <th id=\"T_7091b_level1_col22\" class=\"col_heading level1 col22\" >text-davinci-002</th>\n",
       "      <th id=\"T_7091b_level1_col23\" class=\"col_heading level1 col23\" >text-davinci-003</th>\n",
       "      <th id=\"T_7091b_level1_col24\" class=\"col_heading level1 col24\" >command-xlarge-nightly</th>\n",
       "      <th id=\"T_7091b_level1_col25\" class=\"col_heading level1 col25\" >flan-T5-xxl</th>\n",
       "      <th id=\"T_7091b_level1_col26\" class=\"col_heading level1 col26\" >gpt-3.5-turbo</th>\n",
       "      <th id=\"T_7091b_level1_col27\" class=\"col_heading level1 col27\" >gpt-4</th>\n",
       "      <th id=\"T_7091b_level1_col28\" class=\"col_heading level1 col28\" >text-davinci-002</th>\n",
       "      <th id=\"T_7091b_level1_col29\" class=\"col_heading level1 col29\" >text-davinci-003</th>\n",
       "      <th id=\"T_7091b_level1_col30\" class=\"col_heading level1 col30\" >command-xlarge-nightly</th>\n",
       "      <th id=\"T_7091b_level1_col31\" class=\"col_heading level1 col31\" >flan-T5-xxl</th>\n",
       "      <th id=\"T_7091b_level1_col32\" class=\"col_heading level1 col32\" >gpt-3.5-turbo</th>\n",
       "      <th id=\"T_7091b_level1_col33\" class=\"col_heading level1 col33\" >gpt-4</th>\n",
       "      <th id=\"T_7091b_level1_col34\" class=\"col_heading level1 col34\" >text-davinci-002</th>\n",
       "      <th id=\"T_7091b_level1_col35\" class=\"col_heading level1 col35\" >text-davinci-003</th>\n",
       "      <th id=\"T_7091b_level1_col36\" class=\"col_heading level1 col36\" >command-xlarge-nightly</th>\n",
       "      <th id=\"T_7091b_level1_col37\" class=\"col_heading level1 col37\" >flan-T5-xxl</th>\n",
       "      <th id=\"T_7091b_level1_col38\" class=\"col_heading level1 col38\" >gpt-3.5-turbo</th>\n",
       "      <th id=\"T_7091b_level1_col39\" class=\"col_heading level1 col39\" >gpt-4</th>\n",
       "      <th id=\"T_7091b_level1_col40\" class=\"col_heading level1 col40\" >text-davinci-002</th>\n",
       "      <th id=\"T_7091b_level1_col41\" class=\"col_heading level1 col41\" >text-davinci-003</th>\n",
       "      <th id=\"T_7091b_level1_col42\" class=\"col_heading level1 col42\" >command-xlarge-nightly</th>\n",
       "      <th id=\"T_7091b_level1_col43\" class=\"col_heading level1 col43\" >flan-T5-xxl</th>\n",
       "      <th id=\"T_7091b_level1_col44\" class=\"col_heading level1 col44\" >gpt-3.5-turbo</th>\n",
       "      <th id=\"T_7091b_level1_col45\" class=\"col_heading level1 col45\" >gpt-4</th>\n",
       "      <th id=\"T_7091b_level1_col46\" class=\"col_heading level1 col46\" >text-davinci-002</th>\n",
       "      <th id=\"T_7091b_level1_col47\" class=\"col_heading level1 col47\" >text-davinci-003</th>\n",
       "      <th id=\"T_7091b_level1_col48\" class=\"col_heading level1 col48\" >command-xlarge-nightly</th>\n",
       "      <th id=\"T_7091b_level1_col49\" class=\"col_heading level1 col49\" >flan-T5-xxl</th>\n",
       "      <th id=\"T_7091b_level1_col50\" class=\"col_heading level1 col50\" >gpt-3.5-turbo</th>\n",
       "      <th id=\"T_7091b_level1_col51\" class=\"col_heading level1 col51\" >gpt-4</th>\n",
       "      <th id=\"T_7091b_level1_col52\" class=\"col_heading level1 col52\" >text-davinci-002</th>\n",
       "      <th id=\"T_7091b_level1_col53\" class=\"col_heading level1 col53\" >text-davinci-003</th>\n",
       "      <th id=\"T_7091b_level1_col54\" class=\"col_heading level1 col54\" >command-xlarge-nightly</th>\n",
       "      <th id=\"T_7091b_level1_col55\" class=\"col_heading level1 col55\" >flan-T5-xxl</th>\n",
       "      <th id=\"T_7091b_level1_col56\" class=\"col_heading level1 col56\" >gpt-3.5-turbo</th>\n",
       "      <th id=\"T_7091b_level1_col57\" class=\"col_heading level1 col57\" >gpt-4</th>\n",
       "      <th id=\"T_7091b_level1_col58\" class=\"col_heading level1 col58\" >text-davinci-002</th>\n",
       "      <th id=\"T_7091b_level1_col59\" class=\"col_heading level1 col59\" >text-davinci-003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7091b_level0_row0\" class=\"row_heading level0 row0\" >commonsense_qa</th>\n",
       "      <td id=\"T_7091b_row0_col0\" class=\"data row0 col0\" >0.52</td>\n",
       "      <td id=\"T_7091b_row0_col1\" class=\"data row0 col1\" >0.85</td>\n",
       "      <td id=\"T_7091b_row0_col2\" class=\"data row0 col2\" >0.76</td>\n",
       "      <td id=\"T_7091b_row0_col3\" class=\"data row0 col3\" >0.73</td>\n",
       "      <td id=\"T_7091b_row0_col4\" class=\"data row0 col4\" >0.76</td>\n",
       "      <td id=\"T_7091b_row0_col5\" class=\"data row0 col5\" >0.73</td>\n",
       "      <td id=\"T_7091b_row0_col6\" class=\"data row0 col6\" >0.48</td>\n",
       "      <td id=\"T_7091b_row0_col7\" class=\"data row0 col7\" >0.85</td>\n",
       "      <td id=\"T_7091b_row0_col8\" class=\"data row0 col8\" >0.73</td>\n",
       "      <td id=\"T_7091b_row0_col9\" class=\"data row0 col9\" >0.73</td>\n",
       "      <td id=\"T_7091b_row0_col10\" class=\"data row0 col10\" >0.73</td>\n",
       "      <td id=\"T_7091b_row0_col11\" class=\"data row0 col11\" >0.67</td>\n",
       "      <td id=\"T_7091b_row0_col12\" class=\"data row0 col12\" >0.73</td>\n",
       "      <td id=\"T_7091b_row0_col13\" class=\"data row0 col13\" >0.85</td>\n",
       "      <td id=\"T_7091b_row0_col14\" class=\"data row0 col14\" >0.70</td>\n",
       "      <td id=\"T_7091b_row0_col15\" class=\"data row0 col15\" >0.76</td>\n",
       "      <td id=\"T_7091b_row0_col16\" class=\"data row0 col16\" >0.61</td>\n",
       "      <td id=\"T_7091b_row0_col17\" class=\"data row0 col17\" >0.67</td>\n",
       "      <td id=\"T_7091b_row0_col18\" class=\"data row0 col18\" >0.70</td>\n",
       "      <td id=\"T_7091b_row0_col19\" class=\"data row0 col19\" >0.85</td>\n",
       "      <td id=\"T_7091b_row0_col20\" class=\"data row0 col20\" >0.70</td>\n",
       "      <td id=\"T_7091b_row0_col21\" class=\"data row0 col21\" >0.88</td>\n",
       "      <td id=\"T_7091b_row0_col22\" class=\"data row0 col22\" >0.70</td>\n",
       "      <td id=\"T_7091b_row0_col23\" class=\"data row0 col23\" >0.70</td>\n",
       "      <td id=\"T_7091b_row0_col24\" class=\"data row0 col24\" >0.70</td>\n",
       "      <td id=\"T_7091b_row0_col25\" class=\"data row0 col25\" >0.85</td>\n",
       "      <td id=\"T_7091b_row0_col26\" class=\"data row0 col26\" >0.58</td>\n",
       "      <td id=\"T_7091b_row0_col27\" class=\"data row0 col27\" >0.70</td>\n",
       "      <td id=\"T_7091b_row0_col28\" class=\"data row0 col28\" >0.73</td>\n",
       "      <td id=\"T_7091b_row0_col29\" class=\"data row0 col29\" >0.79</td>\n",
       "      <td id=\"T_7091b_row0_col30\" class=\"data row0 col30\" >0.76</td>\n",
       "      <td id=\"T_7091b_row0_col31\" class=\"data row0 col31\" >0.85</td>\n",
       "      <td id=\"T_7091b_row0_col32\" class=\"data row0 col32\" >0.64</td>\n",
       "      <td id=\"T_7091b_row0_col33\" class=\"data row0 col33\" >0.82</td>\n",
       "      <td id=\"T_7091b_row0_col34\" class=\"data row0 col34\" >0.73</td>\n",
       "      <td id=\"T_7091b_row0_col35\" class=\"data row0 col35\" >0.67</td>\n",
       "      <td id=\"T_7091b_row0_col36\" class=\"data row0 col36\" >0.67</td>\n",
       "      <td id=\"T_7091b_row0_col37\" class=\"data row0 col37\" >0.73</td>\n",
       "      <td id=\"T_7091b_row0_col38\" class=\"data row0 col38\" >0.64</td>\n",
       "      <td id=\"T_7091b_row0_col39\" class=\"data row0 col39\" >0.67</td>\n",
       "      <td id=\"T_7091b_row0_col40\" class=\"data row0 col40\" >0.70</td>\n",
       "      <td id=\"T_7091b_row0_col41\" class=\"data row0 col41\" >0.58</td>\n",
       "      <td id=\"T_7091b_row0_col42\" class=\"data row0 col42\" >0.61</td>\n",
       "      <td id=\"T_7091b_row0_col43\" class=\"data row0 col43\" >0.85</td>\n",
       "      <td id=\"T_7091b_row0_col44\" class=\"data row0 col44\" >0.61</td>\n",
       "      <td id=\"T_7091b_row0_col45\" class=\"data row0 col45\" >0.64</td>\n",
       "      <td id=\"T_7091b_row0_col46\" class=\"data row0 col46\" >0.55</td>\n",
       "      <td id=\"T_7091b_row0_col47\" class=\"data row0 col47\" >0.64</td>\n",
       "      <td id=\"T_7091b_row0_col48\" class=\"data row0 col48\" >0.70</td>\n",
       "      <td id=\"T_7091b_row0_col49\" class=\"data row0 col49\" >0.85</td>\n",
       "      <td id=\"T_7091b_row0_col50\" class=\"data row0 col50\" >0.73</td>\n",
       "      <td id=\"T_7091b_row0_col51\" class=\"data row0 col51\" >0.82</td>\n",
       "      <td id=\"T_7091b_row0_col52\" class=\"data row0 col52\" >0.70</td>\n",
       "      <td id=\"T_7091b_row0_col53\" class=\"data row0 col53\" >0.76</td>\n",
       "      <td id=\"T_7091b_row0_col54\" class=\"data row0 col54\" >0.73</td>\n",
       "      <td id=\"T_7091b_row0_col55\" class=\"data row0 col55\" >0.82</td>\n",
       "      <td id=\"T_7091b_row0_col56\" class=\"data row0 col56\" >0.79</td>\n",
       "      <td id=\"T_7091b_row0_col57\" class=\"data row0 col57\" >0.76</td>\n",
       "      <td id=\"T_7091b_row0_col58\" class=\"data row0 col58\" >0.73</td>\n",
       "      <td id=\"T_7091b_row0_col59\" class=\"data row0 col59\" >0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7091b_level0_row1\" class=\"row_heading level0 row1\" >med_qa</th>\n",
       "      <td id=\"T_7091b_row1_col0\" class=\"data row1 col0\" >0.18</td>\n",
       "      <td id=\"T_7091b_row1_col1\" class=\"data row1 col1\" >0.21</td>\n",
       "      <td id=\"T_7091b_row1_col2\" class=\"data row1 col2\" >0.55</td>\n",
       "      <td id=\"T_7091b_row1_col3\" class=\"data row1 col3\" >0.64</td>\n",
       "      <td id=\"T_7091b_row1_col4\" class=\"data row1 col4\" >0.33</td>\n",
       "      <td id=\"T_7091b_row1_col5\" class=\"data row1 col5\" >0.30</td>\n",
       "      <td id=\"T_7091b_row1_col6\" class=\"data row1 col6\" >0.30</td>\n",
       "      <td id=\"T_7091b_row1_col7\" class=\"data row1 col7\" >0.27</td>\n",
       "      <td id=\"T_7091b_row1_col8\" class=\"data row1 col8\" >0.52</td>\n",
       "      <td id=\"T_7091b_row1_col9\" class=\"data row1 col9\" >0.70</td>\n",
       "      <td id=\"T_7091b_row1_col10\" class=\"data row1 col10\" >0.12</td>\n",
       "      <td id=\"T_7091b_row1_col11\" class=\"data row1 col11\" >0.33</td>\n",
       "      <td id=\"T_7091b_row1_col12\" class=\"data row1 col12\" >0.27</td>\n",
       "      <td id=\"T_7091b_row1_col13\" class=\"data row1 col13\" >0.12</td>\n",
       "      <td id=\"T_7091b_row1_col14\" class=\"data row1 col14\" >0.61</td>\n",
       "      <td id=\"T_7091b_row1_col15\" class=\"data row1 col15\" >0.73</td>\n",
       "      <td id=\"T_7091b_row1_col16\" class=\"data row1 col16\" >0.24</td>\n",
       "      <td id=\"T_7091b_row1_col17\" class=\"data row1 col17\" >0.39</td>\n",
       "      <td id=\"T_7091b_row1_col18\" class=\"data row1 col18\" >0.27</td>\n",
       "      <td id=\"T_7091b_row1_col19\" class=\"data row1 col19\" >0.24</td>\n",
       "      <td id=\"T_7091b_row1_col20\" class=\"data row1 col20\" >0.42</td>\n",
       "      <td id=\"T_7091b_row1_col21\" class=\"data row1 col21\" >0.61</td>\n",
       "      <td id=\"T_7091b_row1_col22\" class=\"data row1 col22\" >0.24</td>\n",
       "      <td id=\"T_7091b_row1_col23\" class=\"data row1 col23\" >0.36</td>\n",
       "      <td id=\"T_7091b_row1_col24\" class=\"data row1 col24\" >0.27</td>\n",
       "      <td id=\"T_7091b_row1_col25\" class=\"data row1 col25\" >0.15</td>\n",
       "      <td id=\"T_7091b_row1_col26\" class=\"data row1 col26\" >0.55</td>\n",
       "      <td id=\"T_7091b_row1_col27\" class=\"data row1 col27\" >0.67</td>\n",
       "      <td id=\"T_7091b_row1_col28\" class=\"data row1 col28\" >0.36</td>\n",
       "      <td id=\"T_7091b_row1_col29\" class=\"data row1 col29\" >0.30</td>\n",
       "      <td id=\"T_7091b_row1_col30\" class=\"data row1 col30\" >0.24</td>\n",
       "      <td id=\"T_7091b_row1_col31\" class=\"data row1 col31\" >0.24</td>\n",
       "      <td id=\"T_7091b_row1_col32\" class=\"data row1 col32\" >0.42</td>\n",
       "      <td id=\"T_7091b_row1_col33\" class=\"data row1 col33\" >0.61</td>\n",
       "      <td id=\"T_7091b_row1_col34\" class=\"data row1 col34\" >0.30</td>\n",
       "      <td id=\"T_7091b_row1_col35\" class=\"data row1 col35\" >0.39</td>\n",
       "      <td id=\"T_7091b_row1_col36\" class=\"data row1 col36\" >0.33</td>\n",
       "      <td id=\"T_7091b_row1_col37\" class=\"data row1 col37\" >0.24</td>\n",
       "      <td id=\"T_7091b_row1_col38\" class=\"data row1 col38\" >0.48</td>\n",
       "      <td id=\"T_7091b_row1_col39\" class=\"data row1 col39\" >0.64</td>\n",
       "      <td id=\"T_7091b_row1_col40\" class=\"data row1 col40\" >0.33</td>\n",
       "      <td id=\"T_7091b_row1_col41\" class=\"data row1 col41\" >0.36</td>\n",
       "      <td id=\"T_7091b_row1_col42\" class=\"data row1 col42\" >0.30</td>\n",
       "      <td id=\"T_7091b_row1_col43\" class=\"data row1 col43\" >0.24</td>\n",
       "      <td id=\"T_7091b_row1_col44\" class=\"data row1 col44\" >0.52</td>\n",
       "      <td id=\"T_7091b_row1_col45\" class=\"data row1 col45\" >0.61</td>\n",
       "      <td id=\"T_7091b_row1_col46\" class=\"data row1 col46\" >0.27</td>\n",
       "      <td id=\"T_7091b_row1_col47\" class=\"data row1 col47\" >0.24</td>\n",
       "      <td id=\"T_7091b_row1_col48\" class=\"data row1 col48\" >0.21</td>\n",
       "      <td id=\"T_7091b_row1_col49\" class=\"data row1 col49\" >0.18</td>\n",
       "      <td id=\"T_7091b_row1_col50\" class=\"data row1 col50\" >0.48</td>\n",
       "      <td id=\"T_7091b_row1_col51\" class=\"data row1 col51\" >0.64</td>\n",
       "      <td id=\"T_7091b_row1_col52\" class=\"data row1 col52\" >0.27</td>\n",
       "      <td id=\"T_7091b_row1_col53\" class=\"data row1 col53\" >0.33</td>\n",
       "      <td id=\"T_7091b_row1_col54\" class=\"data row1 col54\" >0.24</td>\n",
       "      <td id=\"T_7091b_row1_col55\" class=\"data row1 col55\" >0.21</td>\n",
       "      <td id=\"T_7091b_row1_col56\" class=\"data row1 col56\" >0.48</td>\n",
       "      <td id=\"T_7091b_row1_col57\" class=\"data row1 col57\" >0.61</td>\n",
       "      <td id=\"T_7091b_row1_col58\" class=\"data row1 col58\" >0.24</td>\n",
       "      <td id=\"T_7091b_row1_col59\" class=\"data row1 col59\" >0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7091b_level0_row2\" class=\"row_heading level0 row2\" >medmc_qa</th>\n",
       "      <td id=\"T_7091b_row2_col0\" class=\"data row2 col0\" >0.27</td>\n",
       "      <td id=\"T_7091b_row2_col1\" class=\"data row2 col1\" >0.36</td>\n",
       "      <td id=\"T_7091b_row2_col2\" class=\"data row2 col2\" >0.64</td>\n",
       "      <td id=\"T_7091b_row2_col3\" class=\"data row2 col3\" >0.79</td>\n",
       "      <td id=\"T_7091b_row2_col4\" class=\"data row2 col4\" >0.30</td>\n",
       "      <td id=\"T_7091b_row2_col5\" class=\"data row2 col5\" >0.36</td>\n",
       "      <td id=\"T_7091b_row2_col6\" class=\"data row2 col6\" >0.15</td>\n",
       "      <td id=\"T_7091b_row2_col7\" class=\"data row2 col7\" >0.30</td>\n",
       "      <td id=\"T_7091b_row2_col8\" class=\"data row2 col8\" >0.58</td>\n",
       "      <td id=\"T_7091b_row2_col9\" class=\"data row2 col9\" >0.82</td>\n",
       "      <td id=\"T_7091b_row2_col10\" class=\"data row2 col10\" >0.33</td>\n",
       "      <td id=\"T_7091b_row2_col11\" class=\"data row2 col11\" >0.36</td>\n",
       "      <td id=\"T_7091b_row2_col12\" class=\"data row2 col12\" >0.42</td>\n",
       "      <td id=\"T_7091b_row2_col13\" class=\"data row2 col13\" >0.36</td>\n",
       "      <td id=\"T_7091b_row2_col14\" class=\"data row2 col14\" >0.61</td>\n",
       "      <td id=\"T_7091b_row2_col15\" class=\"data row2 col15\" >0.85</td>\n",
       "      <td id=\"T_7091b_row2_col16\" class=\"data row2 col16\" >0.45</td>\n",
       "      <td id=\"T_7091b_row2_col17\" class=\"data row2 col17\" >0.48</td>\n",
       "      <td id=\"T_7091b_row2_col18\" class=\"data row2 col18\" >0.27</td>\n",
       "      <td id=\"T_7091b_row2_col19\" class=\"data row2 col19\" >0.33</td>\n",
       "      <td id=\"T_7091b_row2_col20\" class=\"data row2 col20\" >0.64</td>\n",
       "      <td id=\"T_7091b_row2_col21\" class=\"data row2 col21\" >0.76</td>\n",
       "      <td id=\"T_7091b_row2_col22\" class=\"data row2 col22\" >0.39</td>\n",
       "      <td id=\"T_7091b_row2_col23\" class=\"data row2 col23\" >0.45</td>\n",
       "      <td id=\"T_7091b_row2_col24\" class=\"data row2 col24\" >0.30</td>\n",
       "      <td id=\"T_7091b_row2_col25\" class=\"data row2 col25\" >0.42</td>\n",
       "      <td id=\"T_7091b_row2_col26\" class=\"data row2 col26\" >0.64</td>\n",
       "      <td id=\"T_7091b_row2_col27\" class=\"data row2 col27\" >0.76</td>\n",
       "      <td id=\"T_7091b_row2_col28\" class=\"data row2 col28\" >0.48</td>\n",
       "      <td id=\"T_7091b_row2_col29\" class=\"data row2 col29\" >0.36</td>\n",
       "      <td id=\"T_7091b_row2_col30\" class=\"data row2 col30\" >0.36</td>\n",
       "      <td id=\"T_7091b_row2_col31\" class=\"data row2 col31\" >0.36</td>\n",
       "      <td id=\"T_7091b_row2_col32\" class=\"data row2 col32\" >0.52</td>\n",
       "      <td id=\"T_7091b_row2_col33\" class=\"data row2 col33\" >0.76</td>\n",
       "      <td id=\"T_7091b_row2_col34\" class=\"data row2 col34\" >0.45</td>\n",
       "      <td id=\"T_7091b_row2_col35\" class=\"data row2 col35\" >0.36</td>\n",
       "      <td id=\"T_7091b_row2_col36\" class=\"data row2 col36\" >0.36</td>\n",
       "      <td id=\"T_7091b_row2_col37\" class=\"data row2 col37\" >0.30</td>\n",
       "      <td id=\"T_7091b_row2_col38\" class=\"data row2 col38\" >0.64</td>\n",
       "      <td id=\"T_7091b_row2_col39\" class=\"data row2 col39\" >0.85</td>\n",
       "      <td id=\"T_7091b_row2_col40\" class=\"data row2 col40\" >0.52</td>\n",
       "      <td id=\"T_7091b_row2_col41\" class=\"data row2 col41\" >0.39</td>\n",
       "      <td id=\"T_7091b_row2_col42\" class=\"data row2 col42\" >0.36</td>\n",
       "      <td id=\"T_7091b_row2_col43\" class=\"data row2 col43\" >0.39</td>\n",
       "      <td id=\"T_7091b_row2_col44\" class=\"data row2 col44\" >0.67</td>\n",
       "      <td id=\"T_7091b_row2_col45\" class=\"data row2 col45\" >0.67</td>\n",
       "      <td id=\"T_7091b_row2_col46\" class=\"data row2 col46\" >0.39</td>\n",
       "      <td id=\"T_7091b_row2_col47\" class=\"data row2 col47\" >0.42</td>\n",
       "      <td id=\"T_7091b_row2_col48\" class=\"data row2 col48\" >0.24</td>\n",
       "      <td id=\"T_7091b_row2_col49\" class=\"data row2 col49\" >0.27</td>\n",
       "      <td id=\"T_7091b_row2_col50\" class=\"data row2 col50\" >0.55</td>\n",
       "      <td id=\"T_7091b_row2_col51\" class=\"data row2 col51\" >0.76</td>\n",
       "      <td id=\"T_7091b_row2_col52\" class=\"data row2 col52\" >0.30</td>\n",
       "      <td id=\"T_7091b_row2_col53\" class=\"data row2 col53\" >0.39</td>\n",
       "      <td id=\"T_7091b_row2_col54\" class=\"data row2 col54\" >0.33</td>\n",
       "      <td id=\"T_7091b_row2_col55\" class=\"data row2 col55\" >0.30</td>\n",
       "      <td id=\"T_7091b_row2_col56\" class=\"data row2 col56\" >0.48</td>\n",
       "      <td id=\"T_7091b_row2_col57\" class=\"data row2 col57\" >0.82</td>\n",
       "      <td id=\"T_7091b_row2_col58\" class=\"data row2 col58\" >0.33</td>\n",
       "      <td id=\"T_7091b_row2_col59\" class=\"data row2 col59\" >0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7091b_level0_row3\" class=\"row_heading level0 row3\" >open_book_qa</th>\n",
       "      <td id=\"T_7091b_row3_col0\" class=\"data row3 col0\" >0.58</td>\n",
       "      <td id=\"T_7091b_row3_col1\" class=\"data row3 col1\" >0.76</td>\n",
       "      <td id=\"T_7091b_row3_col2\" class=\"data row3 col2\" >0.85</td>\n",
       "      <td id=\"T_7091b_row3_col3\" class=\"data row3 col3\" >0.91</td>\n",
       "      <td id=\"T_7091b_row3_col4\" class=\"data row3 col4\" >0.64</td>\n",
       "      <td id=\"T_7091b_row3_col5\" class=\"data row3 col5\" >0.64</td>\n",
       "      <td id=\"T_7091b_row3_col6\" class=\"data row3 col6\" >0.42</td>\n",
       "      <td id=\"T_7091b_row3_col7\" class=\"data row3 col7\" >0.82</td>\n",
       "      <td id=\"T_7091b_row3_col8\" class=\"data row3 col8\" >0.79</td>\n",
       "      <td id=\"T_7091b_row3_col9\" class=\"data row3 col9\" >0.94</td>\n",
       "      <td id=\"T_7091b_row3_col10\" class=\"data row3 col10\" >0.55</td>\n",
       "      <td id=\"T_7091b_row3_col11\" class=\"data row3 col11\" >0.58</td>\n",
       "      <td id=\"T_7091b_row3_col12\" class=\"data row3 col12\" >0.61</td>\n",
       "      <td id=\"T_7091b_row3_col13\" class=\"data row3 col13\" >0.82</td>\n",
       "      <td id=\"T_7091b_row3_col14\" class=\"data row3 col14\" >0.73</td>\n",
       "      <td id=\"T_7091b_row3_col15\" class=\"data row3 col15\" >0.97</td>\n",
       "      <td id=\"T_7091b_row3_col16\" class=\"data row3 col16\" >0.76</td>\n",
       "      <td id=\"T_7091b_row3_col17\" class=\"data row3 col17\" >0.79</td>\n",
       "      <td id=\"T_7091b_row3_col18\" class=\"data row3 col18\" >0.58</td>\n",
       "      <td id=\"T_7091b_row3_col19\" class=\"data row3 col19\" >0.79</td>\n",
       "      <td id=\"T_7091b_row3_col20\" class=\"data row3 col20\" >0.76</td>\n",
       "      <td id=\"T_7091b_row3_col21\" class=\"data row3 col21\" >0.94</td>\n",
       "      <td id=\"T_7091b_row3_col22\" class=\"data row3 col22\" >0.55</td>\n",
       "      <td id=\"T_7091b_row3_col23\" class=\"data row3 col23\" >0.73</td>\n",
       "      <td id=\"T_7091b_row3_col24\" class=\"data row3 col24\" >0.58</td>\n",
       "      <td id=\"T_7091b_row3_col25\" class=\"data row3 col25\" >0.79</td>\n",
       "      <td id=\"T_7091b_row3_col26\" class=\"data row3 col26\" >0.85</td>\n",
       "      <td id=\"T_7091b_row3_col27\" class=\"data row3 col27\" >0.91</td>\n",
       "      <td id=\"T_7091b_row3_col28\" class=\"data row3 col28\" >0.52</td>\n",
       "      <td id=\"T_7091b_row3_col29\" class=\"data row3 col29\" >0.79</td>\n",
       "      <td id=\"T_7091b_row3_col30\" class=\"data row3 col30\" >0.58</td>\n",
       "      <td id=\"T_7091b_row3_col31\" class=\"data row3 col31\" >0.76</td>\n",
       "      <td id=\"T_7091b_row3_col32\" class=\"data row3 col32\" >0.73</td>\n",
       "      <td id=\"T_7091b_row3_col33\" class=\"data row3 col33\" >0.88</td>\n",
       "      <td id=\"T_7091b_row3_col34\" class=\"data row3 col34\" >0.39</td>\n",
       "      <td id=\"T_7091b_row3_col35\" class=\"data row3 col35\" >0.61</td>\n",
       "      <td id=\"T_7091b_row3_col36\" class=\"data row3 col36\" >0.55</td>\n",
       "      <td id=\"T_7091b_row3_col37\" class=\"data row3 col37\" >0.67</td>\n",
       "      <td id=\"T_7091b_row3_col38\" class=\"data row3 col38\" >0.67</td>\n",
       "      <td id=\"T_7091b_row3_col39\" class=\"data row3 col39\" >0.85</td>\n",
       "      <td id=\"T_7091b_row3_col40\" class=\"data row3 col40\" >0.61</td>\n",
       "      <td id=\"T_7091b_row3_col41\" class=\"data row3 col41\" >0.64</td>\n",
       "      <td id=\"T_7091b_row3_col42\" class=\"data row3 col42\" >0.61</td>\n",
       "      <td id=\"T_7091b_row3_col43\" class=\"data row3 col43\" >0.73</td>\n",
       "      <td id=\"T_7091b_row3_col44\" class=\"data row3 col44\" >0.73</td>\n",
       "      <td id=\"T_7091b_row3_col45\" class=\"data row3 col45\" >0.91</td>\n",
       "      <td id=\"T_7091b_row3_col46\" class=\"data row3 col46\" >0.48</td>\n",
       "      <td id=\"T_7091b_row3_col47\" class=\"data row3 col47\" >0.73</td>\n",
       "      <td id=\"T_7091b_row3_col48\" class=\"data row3 col48\" >0.61</td>\n",
       "      <td id=\"T_7091b_row3_col49\" class=\"data row3 col49\" >0.79</td>\n",
       "      <td id=\"T_7091b_row3_col50\" class=\"data row3 col50\" >0.76</td>\n",
       "      <td id=\"T_7091b_row3_col51\" class=\"data row3 col51\" >0.88</td>\n",
       "      <td id=\"T_7091b_row3_col52\" class=\"data row3 col52\" >0.67</td>\n",
       "      <td id=\"T_7091b_row3_col53\" class=\"data row3 col53\" >0.64</td>\n",
       "      <td id=\"T_7091b_row3_col54\" class=\"data row3 col54\" >0.64</td>\n",
       "      <td id=\"T_7091b_row3_col55\" class=\"data row3 col55\" >0.76</td>\n",
       "      <td id=\"T_7091b_row3_col56\" class=\"data row3 col56\" >0.73</td>\n",
       "      <td id=\"T_7091b_row3_col57\" class=\"data row3 col57\" >0.94</td>\n",
       "      <td id=\"T_7091b_row3_col58\" class=\"data row3 col58\" >0.45</td>\n",
       "      <td id=\"T_7091b_row3_col59\" class=\"data row3 col59\" >0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7091b_level0_row4\" class=\"row_heading level0 row4\" >strategy_qa</th>\n",
       "      <td id=\"T_7091b_row4_col0\" class=\"data row4 col0\" >0.55</td>\n",
       "      <td id=\"T_7091b_row4_col1\" class=\"data row4 col1\" >0.67</td>\n",
       "      <td id=\"T_7091b_row4_col2\" class=\"data row4 col2\" >0.55</td>\n",
       "      <td id=\"T_7091b_row4_col3\" class=\"data row4 col3\" >0.73</td>\n",
       "      <td id=\"T_7091b_row4_col4\" class=\"data row4 col4\" >0.39</td>\n",
       "      <td id=\"T_7091b_row4_col5\" class=\"data row4 col5\" >0.61</td>\n",
       "      <td id=\"T_7091b_row4_col6\" class=\"data row4 col6\" >0.58</td>\n",
       "      <td id=\"T_7091b_row4_col7\" class=\"data row4 col7\" >0.70</td>\n",
       "      <td id=\"T_7091b_row4_col8\" class=\"data row4 col8\" >0.61</td>\n",
       "      <td id=\"T_7091b_row4_col9\" class=\"data row4 col9\" >0.85</td>\n",
       "      <td id=\"T_7091b_row4_col10\" class=\"data row4 col10\" >0.42</td>\n",
       "      <td id=\"T_7091b_row4_col11\" class=\"data row4 col11\" >0.64</td>\n",
       "      <td id=\"T_7091b_row4_col12\" class=\"data row4 col12\" >0.24</td>\n",
       "      <td id=\"T_7091b_row4_col13\" class=\"data row4 col13\" >0.48</td>\n",
       "      <td id=\"T_7091b_row4_col14\" class=\"data row4 col14\" >0.61</td>\n",
       "      <td id=\"T_7091b_row4_col15\" class=\"data row4 col15\" >0.91</td>\n",
       "      <td id=\"T_7091b_row4_col16\" class=\"data row4 col16\" >0.70</td>\n",
       "      <td id=\"T_7091b_row4_col17\" class=\"data row4 col17\" >0.64</td>\n",
       "      <td id=\"T_7091b_row4_col18\" class=\"data row4 col18\" >0.12</td>\n",
       "      <td id=\"T_7091b_row4_col19\" class=\"data row4 col19\" >0.58</td>\n",
       "      <td id=\"T_7091b_row4_col20\" class=\"data row4 col20\" >0.61</td>\n",
       "      <td id=\"T_7091b_row4_col21\" class=\"data row4 col21\" >0.85</td>\n",
       "      <td id=\"T_7091b_row4_col22\" class=\"data row4 col22\" >0.39</td>\n",
       "      <td id=\"T_7091b_row4_col23\" class=\"data row4 col23\" >0.58</td>\n",
       "      <td id=\"T_7091b_row4_col24\" class=\"data row4 col24\" >0.09</td>\n",
       "      <td id=\"T_7091b_row4_col25\" class=\"data row4 col25\" >0.67</td>\n",
       "      <td id=\"T_7091b_row4_col26\" class=\"data row4 col26\" >0.52</td>\n",
       "      <td id=\"T_7091b_row4_col27\" class=\"data row4 col27\" >0.76</td>\n",
       "      <td id=\"T_7091b_row4_col28\" class=\"data row4 col28\" >0.42</td>\n",
       "      <td id=\"T_7091b_row4_col29\" class=\"data row4 col29\" >0.67</td>\n",
       "      <td id=\"T_7091b_row4_col30\" class=\"data row4 col30\" >0.12</td>\n",
       "      <td id=\"T_7091b_row4_col31\" class=\"data row4 col31\" >0.67</td>\n",
       "      <td id=\"T_7091b_row4_col32\" class=\"data row4 col32\" >0.70</td>\n",
       "      <td id=\"T_7091b_row4_col33\" class=\"data row4 col33\" >0.85</td>\n",
       "      <td id=\"T_7091b_row4_col34\" class=\"data row4 col34\" >0.61</td>\n",
       "      <td id=\"T_7091b_row4_col35\" class=\"data row4 col35\" >0.70</td>\n",
       "      <td id=\"T_7091b_row4_col36\" class=\"data row4 col36\" >0.33</td>\n",
       "      <td id=\"T_7091b_row4_col37\" class=\"data row4 col37\" >0.67</td>\n",
       "      <td id=\"T_7091b_row4_col38\" class=\"data row4 col38\" >0.64</td>\n",
       "      <td id=\"T_7091b_row4_col39\" class=\"data row4 col39\" >0.85</td>\n",
       "      <td id=\"T_7091b_row4_col40\" class=\"data row4 col40\" >0.61</td>\n",
       "      <td id=\"T_7091b_row4_col41\" class=\"data row4 col41\" >0.55</td>\n",
       "      <td id=\"T_7091b_row4_col42\" class=\"data row4 col42\" >0.30</td>\n",
       "      <td id=\"T_7091b_row4_col43\" class=\"data row4 col43\" >0.67</td>\n",
       "      <td id=\"T_7091b_row4_col44\" class=\"data row4 col44\" >0.67</td>\n",
       "      <td id=\"T_7091b_row4_col45\" class=\"data row4 col45\" >0.88</td>\n",
       "      <td id=\"T_7091b_row4_col46\" class=\"data row4 col46\" >0.45</td>\n",
       "      <td id=\"T_7091b_row4_col47\" class=\"data row4 col47\" >0.58</td>\n",
       "      <td id=\"T_7091b_row4_col48\" class=\"data row4 col48\" >0.06</td>\n",
       "      <td id=\"T_7091b_row4_col49\" class=\"data row4 col49\" >0.48</td>\n",
       "      <td id=\"T_7091b_row4_col50\" class=\"data row4 col50\" >0.52</td>\n",
       "      <td id=\"T_7091b_row4_col51\" class=\"data row4 col51\" >0.70</td>\n",
       "      <td id=\"T_7091b_row4_col52\" class=\"data row4 col52\" >0.55</td>\n",
       "      <td id=\"T_7091b_row4_col53\" class=\"data row4 col53\" >0.64</td>\n",
       "      <td id=\"T_7091b_row4_col54\" class=\"data row4 col54\" >0.09</td>\n",
       "      <td id=\"T_7091b_row4_col55\" class=\"data row4 col55\" >0.61</td>\n",
       "      <td id=\"T_7091b_row4_col56\" class=\"data row4 col56\" >0.58</td>\n",
       "      <td id=\"T_7091b_row4_col57\" class=\"data row4 col57\" >0.79</td>\n",
       "      <td id=\"T_7091b_row4_col58\" class=\"data row4 col58\" >0.48</td>\n",
       "      <td id=\"T_7091b_row4_col59\" class=\"data row4 col59\" >0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7091b_level0_row5\" class=\"row_heading level0 row5\" >worldtree</th>\n",
       "      <td id=\"T_7091b_row5_col0\" class=\"data row5 col0\" >0.61</td>\n",
       "      <td id=\"T_7091b_row5_col1\" class=\"data row5 col1\" >0.88</td>\n",
       "      <td id=\"T_7091b_row5_col2\" class=\"data row5 col2\" >0.94</td>\n",
       "      <td id=\"T_7091b_row5_col3\" class=\"data row5 col3\" >0.97</td>\n",
       "      <td id=\"T_7091b_row5_col4\" class=\"data row5 col4\" >0.88</td>\n",
       "      <td id=\"T_7091b_row5_col5\" class=\"data row5 col5\" >0.94</td>\n",
       "      <td id=\"T_7091b_row5_col6\" class=\"data row5 col6\" >0.61</td>\n",
       "      <td id=\"T_7091b_row5_col7\" class=\"data row5 col7\" >0.79</td>\n",
       "      <td id=\"T_7091b_row5_col8\" class=\"data row5 col8\" >0.91</td>\n",
       "      <td id=\"T_7091b_row5_col9\" class=\"data row5 col9\" >0.97</td>\n",
       "      <td id=\"T_7091b_row5_col10\" class=\"data row5 col10\" >0.79</td>\n",
       "      <td id=\"T_7091b_row5_col11\" class=\"data row5 col11\" >0.91</td>\n",
       "      <td id=\"T_7091b_row5_col12\" class=\"data row5 col12\" >0.76</td>\n",
       "      <td id=\"T_7091b_row5_col13\" class=\"data row5 col13\" >0.82</td>\n",
       "      <td id=\"T_7091b_row5_col14\" class=\"data row5 col14\" >0.94</td>\n",
       "      <td id=\"T_7091b_row5_col15\" class=\"data row5 col15\" >0.97</td>\n",
       "      <td id=\"T_7091b_row5_col16\" class=\"data row5 col16\" >0.91</td>\n",
       "      <td id=\"T_7091b_row5_col17\" class=\"data row5 col17\" >0.82</td>\n",
       "      <td id=\"T_7091b_row5_col18\" class=\"data row5 col18\" >0.73</td>\n",
       "      <td id=\"T_7091b_row5_col19\" class=\"data row5 col19\" >0.82</td>\n",
       "      <td id=\"T_7091b_row5_col20\" class=\"data row5 col20\" >0.88</td>\n",
       "      <td id=\"T_7091b_row5_col21\" class=\"data row5 col21\" >0.97</td>\n",
       "      <td id=\"T_7091b_row5_col22\" class=\"data row5 col22\" >0.91</td>\n",
       "      <td id=\"T_7091b_row5_col23\" class=\"data row5 col23\" >0.82</td>\n",
       "      <td id=\"T_7091b_row5_col24\" class=\"data row5 col24\" >0.82</td>\n",
       "      <td id=\"T_7091b_row5_col25\" class=\"data row5 col25\" >0.91</td>\n",
       "      <td id=\"T_7091b_row5_col26\" class=\"data row5 col26\" >0.88</td>\n",
       "      <td id=\"T_7091b_row5_col27\" class=\"data row5 col27\" >1.00</td>\n",
       "      <td id=\"T_7091b_row5_col28\" class=\"data row5 col28\" >0.97</td>\n",
       "      <td id=\"T_7091b_row5_col29\" class=\"data row5 col29\" >0.91</td>\n",
       "      <td id=\"T_7091b_row5_col30\" class=\"data row5 col30\" >0.85</td>\n",
       "      <td id=\"T_7091b_row5_col31\" class=\"data row5 col31\" >0.79</td>\n",
       "      <td id=\"T_7091b_row5_col32\" class=\"data row5 col32\" >0.94</td>\n",
       "      <td id=\"T_7091b_row5_col33\" class=\"data row5 col33\" >1.00</td>\n",
       "      <td id=\"T_7091b_row5_col34\" class=\"data row5 col34\" >0.91</td>\n",
       "      <td id=\"T_7091b_row5_col35\" class=\"data row5 col35\" >0.85</td>\n",
       "      <td id=\"T_7091b_row5_col36\" class=\"data row5 col36\" >0.85</td>\n",
       "      <td id=\"T_7091b_row5_col37\" class=\"data row5 col37\" >0.64</td>\n",
       "      <td id=\"T_7091b_row5_col38\" class=\"data row5 col38\" >0.85</td>\n",
       "      <td id=\"T_7091b_row5_col39\" class=\"data row5 col39\" >0.94</td>\n",
       "      <td id=\"T_7091b_row5_col40\" class=\"data row5 col40\" >0.91</td>\n",
       "      <td id=\"T_7091b_row5_col41\" class=\"data row5 col41\" >0.82</td>\n",
       "      <td id=\"T_7091b_row5_col42\" class=\"data row5 col42\" >0.64</td>\n",
       "      <td id=\"T_7091b_row5_col43\" class=\"data row5 col43\" >0.79</td>\n",
       "      <td id=\"T_7091b_row5_col44\" class=\"data row5 col44\" >0.91</td>\n",
       "      <td id=\"T_7091b_row5_col45\" class=\"data row5 col45\" >0.97</td>\n",
       "      <td id=\"T_7091b_row5_col46\" class=\"data row5 col46\" >0.82</td>\n",
       "      <td id=\"T_7091b_row5_col47\" class=\"data row5 col47\" >0.91</td>\n",
       "      <td id=\"T_7091b_row5_col48\" class=\"data row5 col48\" >0.79</td>\n",
       "      <td id=\"T_7091b_row5_col49\" class=\"data row5 col49\" >0.85</td>\n",
       "      <td id=\"T_7091b_row5_col50\" class=\"data row5 col50\" >0.88</td>\n",
       "      <td id=\"T_7091b_row5_col51\" class=\"data row5 col51\" >1.00</td>\n",
       "      <td id=\"T_7091b_row5_col52\" class=\"data row5 col52\" >0.76</td>\n",
       "      <td id=\"T_7091b_row5_col53\" class=\"data row5 col53\" >0.91</td>\n",
       "      <td id=\"T_7091b_row5_col54\" class=\"data row5 col54\" >0.82</td>\n",
       "      <td id=\"T_7091b_row5_col55\" class=\"data row5 col55\" >0.85</td>\n",
       "      <td id=\"T_7091b_row5_col56\" class=\"data row5 col56\" >0.97</td>\n",
       "      <td id=\"T_7091b_row5_col57\" class=\"data row5 col57\" >0.97</td>\n",
       "      <td id=\"T_7091b_row5_col58\" class=\"data row5 col58\" >0.91</td>\n",
       "      <td id=\"T_7091b_row5_col59\" class=\"data row5 col59\" >0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7091b_level0_row6\" class=\"row_heading level0 row6\" >Average</th>\n",
       "      <td id=\"T_7091b_row6_col0\" class=\"data row6 col0\" >0.45</td>\n",
       "      <td id=\"T_7091b_row6_col1\" class=\"data row6 col1\" >0.62</td>\n",
       "      <td id=\"T_7091b_row6_col2\" class=\"data row6 col2\" >0.71</td>\n",
       "      <td id=\"T_7091b_row6_col3\" class=\"data row6 col3\" >0.79</td>\n",
       "      <td id=\"T_7091b_row6_col4\" class=\"data row6 col4\" >0.55</td>\n",
       "      <td id=\"T_7091b_row6_col5\" class=\"data row6 col5\" >0.60</td>\n",
       "      <td id=\"T_7091b_row6_col6\" class=\"data row6 col6\" >0.42</td>\n",
       "      <td id=\"T_7091b_row6_col7\" class=\"data row6 col7\" >0.62</td>\n",
       "      <td id=\"T_7091b_row6_col8\" class=\"data row6 col8\" >0.69</td>\n",
       "      <td id=\"T_7091b_row6_col9\" class=\"data row6 col9\" >0.83</td>\n",
       "      <td id=\"T_7091b_row6_col10\" class=\"data row6 col10\" >0.49</td>\n",
       "      <td id=\"T_7091b_row6_col11\" class=\"data row6 col11\" >0.58</td>\n",
       "      <td id=\"T_7091b_row6_col12\" class=\"data row6 col12\" >0.51</td>\n",
       "      <td id=\"T_7091b_row6_col13\" class=\"data row6 col13\" >0.58</td>\n",
       "      <td id=\"T_7091b_row6_col14\" class=\"data row6 col14\" >0.70</td>\n",
       "      <td id=\"T_7091b_row6_col15\" class=\"data row6 col15\" >0.86</td>\n",
       "      <td id=\"T_7091b_row6_col16\" class=\"data row6 col16\" >0.61</td>\n",
       "      <td id=\"T_7091b_row6_col17\" class=\"data row6 col17\" >0.63</td>\n",
       "      <td id=\"T_7091b_row6_col18\" class=\"data row6 col18\" >0.44</td>\n",
       "      <td id=\"T_7091b_row6_col19\" class=\"data row6 col19\" >0.60</td>\n",
       "      <td id=\"T_7091b_row6_col20\" class=\"data row6 col20\" >0.67</td>\n",
       "      <td id=\"T_7091b_row6_col21\" class=\"data row6 col21\" >0.83</td>\n",
       "      <td id=\"T_7091b_row6_col22\" class=\"data row6 col22\" >0.53</td>\n",
       "      <td id=\"T_7091b_row6_col23\" class=\"data row6 col23\" >0.61</td>\n",
       "      <td id=\"T_7091b_row6_col24\" class=\"data row6 col24\" >0.46</td>\n",
       "      <td id=\"T_7091b_row6_col25\" class=\"data row6 col25\" >0.63</td>\n",
       "      <td id=\"T_7091b_row6_col26\" class=\"data row6 col26\" >0.67</td>\n",
       "      <td id=\"T_7091b_row6_col27\" class=\"data row6 col27\" >0.80</td>\n",
       "      <td id=\"T_7091b_row6_col28\" class=\"data row6 col28\" >0.58</td>\n",
       "      <td id=\"T_7091b_row6_col29\" class=\"data row6 col29\" >0.64</td>\n",
       "      <td id=\"T_7091b_row6_col30\" class=\"data row6 col30\" >0.48</td>\n",
       "      <td id=\"T_7091b_row6_col31\" class=\"data row6 col31\" >0.61</td>\n",
       "      <td id=\"T_7091b_row6_col32\" class=\"data row6 col32\" >0.66</td>\n",
       "      <td id=\"T_7091b_row6_col33\" class=\"data row6 col33\" >0.82</td>\n",
       "      <td id=\"T_7091b_row6_col34\" class=\"data row6 col34\" >0.57</td>\n",
       "      <td id=\"T_7091b_row6_col35\" class=\"data row6 col35\" >0.60</td>\n",
       "      <td id=\"T_7091b_row6_col36\" class=\"data row6 col36\" >0.52</td>\n",
       "      <td id=\"T_7091b_row6_col37\" class=\"data row6 col37\" >0.54</td>\n",
       "      <td id=\"T_7091b_row6_col38\" class=\"data row6 col38\" >0.65</td>\n",
       "      <td id=\"T_7091b_row6_col39\" class=\"data row6 col39\" >0.80</td>\n",
       "      <td id=\"T_7091b_row6_col40\" class=\"data row6 col40\" >0.61</td>\n",
       "      <td id=\"T_7091b_row6_col41\" class=\"data row6 col41\" >0.56</td>\n",
       "      <td id=\"T_7091b_row6_col42\" class=\"data row6 col42\" >0.47</td>\n",
       "      <td id=\"T_7091b_row6_col43\" class=\"data row6 col43\" >0.61</td>\n",
       "      <td id=\"T_7091b_row6_col44\" class=\"data row6 col44\" >0.68</td>\n",
       "      <td id=\"T_7091b_row6_col45\" class=\"data row6 col45\" >0.78</td>\n",
       "      <td id=\"T_7091b_row6_col46\" class=\"data row6 col46\" >0.49</td>\n",
       "      <td id=\"T_7091b_row6_col47\" class=\"data row6 col47\" >0.59</td>\n",
       "      <td id=\"T_7091b_row6_col48\" class=\"data row6 col48\" >0.43</td>\n",
       "      <td id=\"T_7091b_row6_col49\" class=\"data row6 col49\" >0.57</td>\n",
       "      <td id=\"T_7091b_row6_col50\" class=\"data row6 col50\" >0.65</td>\n",
       "      <td id=\"T_7091b_row6_col51\" class=\"data row6 col51\" >0.80</td>\n",
       "      <td id=\"T_7091b_row6_col52\" class=\"data row6 col52\" >0.54</td>\n",
       "      <td id=\"T_7091b_row6_col53\" class=\"data row6 col53\" >0.61</td>\n",
       "      <td id=\"T_7091b_row6_col54\" class=\"data row6 col54\" >0.47</td>\n",
       "      <td id=\"T_7091b_row6_col55\" class=\"data row6 col55\" >0.59</td>\n",
       "      <td id=\"T_7091b_row6_col56\" class=\"data row6 col56\" >0.67</td>\n",
       "      <td id=\"T_7091b_row6_col57\" class=\"data row6 col57\" >0.81</td>\n",
       "      <td id=\"T_7091b_row6_col58\" class=\"data row6 col58\" >0.53</td>\n",
       "      <td id=\"T_7091b_row6_col59\" class=\"data row6 col59\" >0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5fe1f04e20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval = coll.evaluate()\n",
    "table = evaluation_as_table(eval)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_function_new(eval:dict):\n",
    "    import pandas as pd\n",
    "    eval_dict = pd.json_normalize(eval).to_dict('records')[0]\n",
    "    eval_list = list(eval_dict.keys())\n",
    "    datasets = sorted(list(eval.keys()))\n",
    "\n",
    "    models = []\n",
    "    prompts = []\n",
    "    for i in eval_list:\n",
    "        # fast fix for chat gpt model:\n",
    "        i = i.replace(\"gpt-3.5-turbo\",\"gpt-3-5-turbo\")\n",
    "        dataset,split,metric,model,prompt = i.split(\".\")\n",
    "        model = model.replace(\"gpt-3-5-turbo\",\"gpt-3.5-turbo\")\n",
    "        if model not in models:\n",
    "            models.append(model)\n",
    "        if prompt not in prompts:\n",
    "            prompts.append(prompt)\n",
    "            \n",
    "    models = sorted(models)\n",
    "\n",
    "    if \"None_None_None\" in prompts: prompts.remove(\"None_None_None\")\n",
    "\n",
    "    # no instructions implemented yet\n",
    "    # instructions = []\n",
    "    cot_triggers = []\n",
    "    for i in prompts:\n",
    "        instruction, cot_trigger, _ = i.split(\"_\")\n",
    "        # if instruction not in instructions:\n",
    "        #     instructions.append(instruction)\n",
    "\n",
    "        # old: only cot_trigger\n",
    "        # if cot_trigger not in cot_triggers:\n",
    "        #     cot_triggers.append(cot_trigger)\n",
    "\n",
    "        # new: instruction + cot_trigger\n",
    "        if cot_trigger not in cot_triggers:\n",
    "            cot_triggers.append(instruction + \"_\" + cot_trigger)\n",
    "\n",
    "    cot_triggers = sorted(cot_triggers)\n",
    "\n",
    "    cot_trigger_header = sorted(cot_triggers*len(models))\n",
    "    model_header = models*len(cot_triggers)\n",
    "\n",
    "    # Create a dictionary to store the data\n",
    "    data_dict = {}\n",
    "    for k,v in eval_dict.items():\n",
    "        # fast fix for chat gpt model:\n",
    "        k = k.replace(\"gpt-3.5-turbo\",\"gpt-3-5-turbo\")\n",
    "        dataset,split,metric,model,prompt = k.split(\".\")\n",
    "        model = model.replace(\"gpt-3-5-turbo\",\"gpt-3.5-turbo\")\n",
    "        instruction, cot_trigger, _ = prompt.split(\"_\")\n",
    "        # old: only cot_trigger\n",
    "        # df.loc[dataset, (cot_trigger, model)] = v\n",
    "\n",
    "        # new: instruction + cot_trigger\n",
    "        col_name = instruction + \"_\" + cot_trigger + \"_\" + model\n",
    "        if dataset not in data_dict:\n",
    "            data_dict[dataset] = {}\n",
    "        data_dict[dataset][col_name] = v\n",
    "\n",
    "    # Create a dataframe from the dictionary\n",
    "    df = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "\n",
    "    # Calculate the average row and add it to the dataframe\n",
    "    df.loc['Average'] = df.mean()\n",
    "\n",
    "    # Round the dataframe to 2 decimal places\n",
    "    df = df.round(2)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None_None_command-xlarge-nightly</th>\n",
       "      <th>None_kojima-01_command-xlarge-nightly</th>\n",
       "      <th>None_zhou-01_command-xlarge-nightly</th>\n",
       "      <th>qa-10_None_command-xlarge-nightly</th>\n",
       "      <th>qa-12_None_command-xlarge-nightly</th>\n",
       "      <th>qa-13_None_command-xlarge-nightly</th>\n",
       "      <th>qa-16_None_command-xlarge-nightly</th>\n",
       "      <th>qa-17_None_command-xlarge-nightly</th>\n",
       "      <th>refl-01_None_command-xlarge-nightly</th>\n",
       "      <th>zhou-01-ins_None_command-xlarge-nightly</th>\n",
       "      <th>...</th>\n",
       "      <th>None_None_text-davinci-003</th>\n",
       "      <th>None_kojima-01_text-davinci-003</th>\n",
       "      <th>None_zhou-01_text-davinci-003</th>\n",
       "      <th>qa-10_None_text-davinci-003</th>\n",
       "      <th>qa-12_None_text-davinci-003</th>\n",
       "      <th>qa-13_None_text-davinci-003</th>\n",
       "      <th>qa-16_None_text-davinci-003</th>\n",
       "      <th>qa-17_None_text-davinci-003</th>\n",
       "      <th>refl-01_None_text-davinci-003</th>\n",
       "      <th>zhou-01-ins_None_text-davinci-003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>commonsense_qa</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_qa</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medmc_qa</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_book_qa</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategy_qa</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldtree</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                None_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                              0.52   \n",
       "med_qa                                      0.18   \n",
       "medmc_qa                                    0.27   \n",
       "open_book_qa                                0.58   \n",
       "strategy_qa                                 0.55   \n",
       "worldtree                                   0.61   \n",
       "Average                                     0.45   \n",
       "\n",
       "                None_kojima-01_command-xlarge-nightly  \\\n",
       "commonsense_qa                                   0.48   \n",
       "med_qa                                           0.30   \n",
       "medmc_qa                                         0.15   \n",
       "open_book_qa                                     0.42   \n",
       "strategy_qa                                      0.58   \n",
       "worldtree                                        0.61   \n",
       "Average                                          0.42   \n",
       "\n",
       "                None_zhou-01_command-xlarge-nightly  \\\n",
       "commonsense_qa                                 0.73   \n",
       "med_qa                                         0.27   \n",
       "medmc_qa                                       0.42   \n",
       "open_book_qa                                   0.61   \n",
       "strategy_qa                                    0.24   \n",
       "worldtree                                      0.76   \n",
       "Average                                        0.51   \n",
       "\n",
       "                qa-10_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                               0.70   \n",
       "med_qa                                       0.27   \n",
       "medmc_qa                                     0.27   \n",
       "open_book_qa                                 0.58   \n",
       "strategy_qa                                  0.12   \n",
       "worldtree                                    0.73   \n",
       "Average                                      0.44   \n",
       "\n",
       "                qa-12_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                               0.70   \n",
       "med_qa                                       0.27   \n",
       "medmc_qa                                     0.30   \n",
       "open_book_qa                                 0.58   \n",
       "strategy_qa                                  0.09   \n",
       "worldtree                                    0.82   \n",
       "Average                                      0.46   \n",
       "\n",
       "                qa-13_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                               0.76   \n",
       "med_qa                                       0.24   \n",
       "medmc_qa                                     0.36   \n",
       "open_book_qa                                 0.58   \n",
       "strategy_qa                                  0.12   \n",
       "worldtree                                    0.85   \n",
       "Average                                      0.48   \n",
       "\n",
       "                qa-16_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                               0.67   \n",
       "med_qa                                       0.33   \n",
       "medmc_qa                                     0.36   \n",
       "open_book_qa                                 0.55   \n",
       "strategy_qa                                  0.33   \n",
       "worldtree                                    0.85   \n",
       "Average                                      0.52   \n",
       "\n",
       "                qa-17_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                               0.61   \n",
       "med_qa                                       0.30   \n",
       "medmc_qa                                     0.36   \n",
       "open_book_qa                                 0.61   \n",
       "strategy_qa                                  0.30   \n",
       "worldtree                                    0.64   \n",
       "Average                                      0.47   \n",
       "\n",
       "                refl-01_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                                 0.70   \n",
       "med_qa                                         0.21   \n",
       "medmc_qa                                       0.24   \n",
       "open_book_qa                                   0.61   \n",
       "strategy_qa                                    0.06   \n",
       "worldtree                                      0.79   \n",
       "Average                                        0.43   \n",
       "\n",
       "                zhou-01-ins_None_command-xlarge-nightly  ...  \\\n",
       "commonsense_qa                                     0.73  ...   \n",
       "med_qa                                             0.24  ...   \n",
       "medmc_qa                                           0.33  ...   \n",
       "open_book_qa                                       0.64  ...   \n",
       "strategy_qa                                        0.09  ...   \n",
       "worldtree                                          0.82  ...   \n",
       "Average                                            0.47  ...   \n",
       "\n",
       "                None_None_text-davinci-003  None_kojima-01_text-davinci-003  \\\n",
       "commonsense_qa                        0.73                             0.67   \n",
       "med_qa                                0.30                             0.33   \n",
       "medmc_qa                              0.36                             0.36   \n",
       "open_book_qa                          0.64                             0.58   \n",
       "strategy_qa                           0.61                             0.64   \n",
       "worldtree                             0.94                             0.91   \n",
       "Average                               0.60                             0.58   \n",
       "\n",
       "                None_zhou-01_text-davinci-003  qa-10_None_text-davinci-003  \\\n",
       "commonsense_qa                           0.67                         0.70   \n",
       "med_qa                                   0.39                         0.36   \n",
       "medmc_qa                                 0.48                         0.45   \n",
       "open_book_qa                             0.79                         0.73   \n",
       "strategy_qa                              0.64                         0.58   \n",
       "worldtree                                0.82                         0.82   \n",
       "Average                                  0.63                         0.61   \n",
       "\n",
       "                qa-12_None_text-davinci-003  qa-13_None_text-davinci-003  \\\n",
       "commonsense_qa                         0.79                         0.67   \n",
       "med_qa                                 0.30                         0.39   \n",
       "medmc_qa                               0.36                         0.36   \n",
       "open_book_qa                           0.79                         0.61   \n",
       "strategy_qa                            0.67                         0.70   \n",
       "worldtree                              0.91                         0.85   \n",
       "Average                                0.64                         0.60   \n",
       "\n",
       "                qa-16_None_text-davinci-003  qa-17_None_text-davinci-003  \\\n",
       "commonsense_qa                         0.58                         0.64   \n",
       "med_qa                                 0.36                         0.24   \n",
       "medmc_qa                               0.39                         0.42   \n",
       "open_book_qa                           0.64                         0.73   \n",
       "strategy_qa                            0.55                         0.58   \n",
       "worldtree                              0.82                         0.91   \n",
       "Average                                0.56                         0.59   \n",
       "\n",
       "                refl-01_None_text-davinci-003  \\\n",
       "commonsense_qa                           0.76   \n",
       "med_qa                                   0.33   \n",
       "medmc_qa                                 0.39   \n",
       "open_book_qa                             0.64   \n",
       "strategy_qa                              0.64   \n",
       "worldtree                                0.91   \n",
       "Average                                  0.61   \n",
       "\n",
       "                zhou-01-ins_None_text-davinci-003  \n",
       "commonsense_qa                               0.73  \n",
       "med_qa                                       0.36  \n",
       "medmc_qa                                     0.33  \n",
       "open_book_qa                                 0.82  \n",
       "strategy_qa                                  0.64  \n",
       "worldtree                                    0.88  \n",
       "Average                                      0.63  \n",
       "\n",
       "[7 rows x 60 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = table_function_new(eval)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None_None_command-xlarge-nightly</th>\n",
       "      <th>None_kojima-01_command-xlarge-nightly</th>\n",
       "      <th>None_zhou-01_command-xlarge-nightly</th>\n",
       "      <th>qa-10_None_command-xlarge-nightly</th>\n",
       "      <th>qa-12_None_command-xlarge-nightly</th>\n",
       "      <th>qa-13_None_command-xlarge-nightly</th>\n",
       "      <th>qa-16_None_command-xlarge-nightly</th>\n",
       "      <th>qa-17_None_command-xlarge-nightly</th>\n",
       "      <th>refl-01_None_command-xlarge-nightly</th>\n",
       "      <th>zhou-01-ins_None_command-xlarge-nightly</th>\n",
       "      <th>...</th>\n",
       "      <th>None_None_text-davinci-003</th>\n",
       "      <th>None_kojima-01_text-davinci-003</th>\n",
       "      <th>None_zhou-01_text-davinci-003</th>\n",
       "      <th>qa-10_None_text-davinci-003</th>\n",
       "      <th>qa-12_None_text-davinci-003</th>\n",
       "      <th>qa-13_None_text-davinci-003</th>\n",
       "      <th>qa-16_None_text-davinci-003</th>\n",
       "      <th>qa-17_None_text-davinci-003</th>\n",
       "      <th>refl-01_None_text-davinci-003</th>\n",
       "      <th>zhou-01-ins_None_text-davinci-003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         None_None_command-xlarge-nightly  \\\n",
       "Average                              0.45   \n",
       "\n",
       "         None_kojima-01_command-xlarge-nightly  \\\n",
       "Average                                   0.42   \n",
       "\n",
       "         None_zhou-01_command-xlarge-nightly  \\\n",
       "Average                                 0.51   \n",
       "\n",
       "         qa-10_None_command-xlarge-nightly  qa-12_None_command-xlarge-nightly  \\\n",
       "Average                               0.44                               0.46   \n",
       "\n",
       "         qa-13_None_command-xlarge-nightly  qa-16_None_command-xlarge-nightly  \\\n",
       "Average                               0.48                               0.52   \n",
       "\n",
       "         qa-17_None_command-xlarge-nightly  \\\n",
       "Average                               0.47   \n",
       "\n",
       "         refl-01_None_command-xlarge-nightly  \\\n",
       "Average                                 0.43   \n",
       "\n",
       "         zhou-01-ins_None_command-xlarge-nightly  ...  \\\n",
       "Average                                     0.47  ...   \n",
       "\n",
       "         None_None_text-davinci-003  None_kojima-01_text-davinci-003  \\\n",
       "Average                         0.6                             0.58   \n",
       "\n",
       "         None_zhou-01_text-davinci-003  qa-10_None_text-davinci-003  \\\n",
       "Average                           0.63                         0.61   \n",
       "\n",
       "         qa-12_None_text-davinci-003  qa-13_None_text-davinci-003  \\\n",
       "Average                         0.64                          0.6   \n",
       "\n",
       "         qa-16_None_text-davinci-003  qa-17_None_text-davinci-003  \\\n",
       "Average                         0.56                         0.59   \n",
       "\n",
       "         refl-01_None_text-davinci-003  zhou-01-ins_None_text-davinci-003  \n",
       "Average                           0.61                               0.63  \n",
       "\n",
       "[1 rows x 60 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (df[df.index==\"Average\"])\n",
    "#df.to_csv(\"Average_values_df.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "import pandas as pd\n",
    "def clean_column(df, col_name):\n",
    "    pattern = r\"^.?'(.?)'.?'(.?)'.?'(.?)'.?'(.?)'.*$\"\n",
    "    return(df[col_name].apply(lambda x: re.sub(pattern, r\"'\\3\", x)[1:]))\n",
    "\n",
    "def json_to_dataframe_3(json_data):\n",
    "    df_data = []\n",
    "    for category, data in json_data.items():\n",
    "        for subset, questions in data.items():\n",
    "            for question in questions:\n",
    "                for generated_cot in question['generated_cot']:\n",
    "                    row = {\n",
    "                        'dataset': category,\n",
    "                        'split': subset,\n",
    "                        'id': question['id'],\n",
    "                        'model': generated_cot['model'],\n",
    "                        'instruction': generated_cot['instruction'],\n",
    "                        'cot_trigger': generated_cot[\"cot_trigger\"],\n",
    "                        'generated_cot': generated_cot['cot'],\n",
    "                        'correct_answer': generated_cot['answers'][0]['correct_answer'],\n",
    "                    }\n",
    "                    df_data.append(row)\n",
    "    df = pd.DataFrame(df_data)\n",
    "    # df[\"model\"] = clean_column(df, \"model\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'name': 'command-xlarge-nightly', 'temperature': 0, 'max_tokens': 512}\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"model\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>instruction</th>\n",
       "      <th>cot_trigger</th>\n",
       "      <th>generated_cot</th>\n",
       "      <th>correct_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>'name': 'command-xlarge-nightly', 'temperature...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The main purpose of farmers is to supply food.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>'name': 'text-davinci-003', 'temperature': 0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>E) supply food</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>'name': 'flan-T5-xxl', 'temperature': 0, 'max_...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>'name': 'gpt-3.5-turbo', 'temperature': 0, 'ma...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>E) supply food</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>'name': 'text-davinci-002', 'temperature': 0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\\nE) supply food</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11875</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>test</td>\n",
       "      <td>worldtree_test_1659</td>\n",
       "      <td>'name': 'flan-T5-xxl', 'temperature': 0, 'max_...</td>\n",
       "      <td>None</td>\n",
       "      <td>zhou-01</td>\n",
       "      <td>C is the dependent variable. The dependent var...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11876</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>test</td>\n",
       "      <td>worldtree_test_1659</td>\n",
       "      <td>'name': 'text-davinci-003', 'temperature': 0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>zhou-01</td>\n",
       "      <td>\\n\\nStep 1: The vertical axis on a graph is t...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11877</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>test</td>\n",
       "      <td>worldtree_test_1659</td>\n",
       "      <td>'name': 'text-davinci-002', 'temperature': 0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>zhou-01</td>\n",
       "      <td>\\n\\nThe first thing we need to do is identify...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11878</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>test</td>\n",
       "      <td>worldtree_test_1659</td>\n",
       "      <td>'name': 'command-xlarge-nightly', 'temperature...</td>\n",
       "      <td>None</td>\n",
       "      <td>zhou-01</td>\n",
       "      <td>\\nThe y-axis is the vertical axis on a graph. ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11879</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>test</td>\n",
       "      <td>worldtree_test_1659</td>\n",
       "      <td>'name': 'gpt-4', 'temperature': 0, 'max_tokens...</td>\n",
       "      <td>None</td>\n",
       "      <td>kojima-01</td>\n",
       "      <td>The vertical axis on a graph is the y-axis, wh...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11880 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset       split                                id  \\\n",
       "0      commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "1      commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "2      commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "3      commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "4      commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "...               ...         ...                               ...   \n",
       "11875       worldtree        test               worldtree_test_1659   \n",
       "11876       worldtree        test               worldtree_test_1659   \n",
       "11877       worldtree        test               worldtree_test_1659   \n",
       "11878       worldtree        test               worldtree_test_1659   \n",
       "11879       worldtree        test               worldtree_test_1659   \n",
       "\n",
       "                                                   model instruction  \\\n",
       "0      'name': 'command-xlarge-nightly', 'temperature...        None   \n",
       "1      'name': 'text-davinci-003', 'temperature': 0, ...        None   \n",
       "2      'name': 'flan-T5-xxl', 'temperature': 0, 'max_...        None   \n",
       "3      'name': 'gpt-3.5-turbo', 'temperature': 0, 'ma...        None   \n",
       "4      'name': 'text-davinci-002', 'temperature': 0, ...        None   \n",
       "...                                                  ...         ...   \n",
       "11875  'name': 'flan-T5-xxl', 'temperature': 0, 'max_...        None   \n",
       "11876  'name': 'text-davinci-003', 'temperature': 0, ...        None   \n",
       "11877  'name': 'text-davinci-002', 'temperature': 0, ...        None   \n",
       "11878  'name': 'command-xlarge-nightly', 'temperature...        None   \n",
       "11879  'name': 'gpt-4', 'temperature': 0, 'max_tokens...        None   \n",
       "\n",
       "      cot_trigger                                      generated_cot  \\\n",
       "0            None     The main purpose of farmers is to supply food.   \n",
       "1            None                                     E) supply food   \n",
       "2            None                                                  E   \n",
       "3            None                                     E) supply food   \n",
       "4            None                                   \\nE) supply food   \n",
       "...           ...                                                ...   \n",
       "11875     zhou-01  C is the dependent variable. The dependent var...   \n",
       "11876     zhou-01   \\n\\nStep 1: The vertical axis on a graph is t...   \n",
       "11877     zhou-01   \\n\\nThe first thing we need to do is identify...   \n",
       "11878     zhou-01  \\nThe y-axis is the vertical axis on a graph. ...   \n",
       "11879   kojima-01  The vertical axis on a graph is the y-axis, wh...   \n",
       "\n",
       "       correct_answer  \n",
       "0                True  \n",
       "1                True  \n",
       "2                True  \n",
       "3                True  \n",
       "4                True  \n",
       "...               ...  \n",
       "11875            True  \n",
       "11876           False  \n",
       "11877            True  \n",
       "11878            True  \n",
       "11879            True  \n",
       "\n",
       "[11880 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/home/kon/work/ThoughtSource/libs/cot/cot/datasets/thoughtsource/thoughtsource_33_paper.json\"\n",
    "\n",
    "\n",
    "with open(path, \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "df = json_to_dataframe_3(data)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
