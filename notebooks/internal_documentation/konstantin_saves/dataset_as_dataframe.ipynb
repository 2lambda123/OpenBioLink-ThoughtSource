{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.2f'"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cot import Collection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import krippendorff\n",
    "import random\n",
    "import scipy\n",
    "from scipy import stats\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "%precision 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll = Collection.from_json(\"/home/kon/work/ThoughtSource/libs/cot/cot/datasets/thoughtsource/thoughtsource_33_paper.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603c99b2b098410495a397f60e237249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ebd72e37b64671a44f91bd609da4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33fc726f30544d68ad7d046078ec9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130d62c28b3248178b7d34046e62ec2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3992b7774b4568bd454e2ffcdacd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1a258660a548cab6e85f39314473ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ev = coll.evaluate(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = coll.collection_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    'None_None': 'Direct',\n",
    "    'qa-10_None': 'Ins-10',\n",
    "    'qa-12_None': 'Ins-12',\n",
    "    'qa-13_None': 'Ins-13',\n",
    "    'qa-16_None': 'Ins-16',\n",
    "    'qa-17_None': 'Ins-17',\n",
    "    'zhou-01-ins_None': 'Zhou-Ins',\n",
    "    'refl-01_None': 'Reflection',\n",
    "    'None_kojima-01': 'Kojima',\n",
    "    'None_zhou-01': 'Zhou'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompt'].replace(replacements, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>answer_label</th>\n",
       "      <th>prompt</th>\n",
       "      <th>instruction</th>\n",
       "      <th>cot_trigger</th>\n",
       "      <th>answer_from_choices</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>multiplechoice</td>\n",
       "      <td>E</td>\n",
       "      <td>Direct</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset       split                                id  \\\n",
       "0  commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "\n",
       "             type answer_label  prompt instruction cot_trigger  \\\n",
       "0  multiplechoice            E  Direct        None        None   \n",
       "\n",
       "  answer_from_choices  correct_answer                   model  \n",
       "0                   E            True  command-xlarge-nightly  "
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prompt</th>\n",
       "      <th>Direct</th>\n",
       "      <th>Ins-10</th>\n",
       "      <th>Ins-12</th>\n",
       "      <th>Ins-13</th>\n",
       "      <th>Ins-16</th>\n",
       "      <th>Ins-17</th>\n",
       "      <th>Kojima</th>\n",
       "      <th>Reflection</th>\n",
       "      <th>Zhou</th>\n",
       "      <th>Zhou-Ins</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>command-xlarge-nightly</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan-T5-xxl</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-002</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-003</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prompt                  Direct  Ins-10  Ins-12  Ins-13  Ins-16  Ins-17  \\\n",
       "model                                                                    \n",
       "command-xlarge-nightly    0.45    0.44    0.46    0.48    0.52    0.47   \n",
       "flan-T5-xxl               0.62    0.60    0.63    0.61    0.54    0.61   \n",
       "gpt-3.5-turbo             0.71    0.67    0.67    0.66    0.65    0.68   \n",
       "gpt-4                     0.79    0.83    0.80    0.82    0.80    0.78   \n",
       "text-davinci-002          0.57    0.53    0.58    0.57    0.61    0.49   \n",
       "text-davinci-003          0.60    0.61    0.64    0.60    0.56    0.59   \n",
       "\n",
       "prompt                  Kojima  Reflection  Zhou  Zhou-Ins  \n",
       "model                                                       \n",
       "command-xlarge-nightly    0.42        0.43  0.51      0.47  \n",
       "flan-T5-xxl               0.62        0.57  0.58      0.59  \n",
       "gpt-3.5-turbo             0.69        0.65  0.70      0.67  \n",
       "gpt-4                     0.83        0.80  0.86      0.81  \n",
       "text-davinci-002          0.53        0.54  0.61      0.53  \n",
       "text-davinci-003          0.58        0.61  0.63      0.63  "
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_model_prompt = df.groupby([\"model\", \"prompt\"]).mean(\"correct_answer\").pivot_table(index=\"model\", columns=\"prompt\", values=\"correct_answer\")\n",
    "acc_model_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prompt</th>\n",
       "      <th>None_None</th>\n",
       "      <th>None_kojima-01</th>\n",
       "      <th>None_zhou-01</th>\n",
       "      <th>qa-10_None</th>\n",
       "      <th>qa-12_None</th>\n",
       "      <th>qa-13_None</th>\n",
       "      <th>qa-16_None</th>\n",
       "      <th>qa-17_None</th>\n",
       "      <th>refl-01_None</th>\n",
       "      <th>zhou-01-ins_None</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>command-xlarge-nightly</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan-T5-xxl</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-002</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-003</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prompt                  None_None  None_kojima-01  None_zhou-01  qa-10_None  \\\n",
       "model                                                                         \n",
       "command-xlarge-nightly       0.23            0.21          0.31         NaN   \n",
       "flan-T5-xxl                  0.46            0.46          0.39        0.43   \n",
       "gpt-3.5-turbo                0.62            0.66          0.63        0.62   \n",
       "gpt-4                        0.72            0.81          0.84        0.78   \n",
       "text-davinci-002             0.40            0.39          0.53        0.30   \n",
       "text-davinci-003             0.43            0.44          0.50        0.45   \n",
       "\n",
       "prompt                  qa-12_None  qa-13_None  qa-16_None  qa-17_None  \\\n",
       "model                                                                    \n",
       "command-xlarge-nightly         NaN         NaN        0.34        0.28   \n",
       "flan-T5-xxl                   0.47        0.45        0.40        0.45   \n",
       "gpt-3.5-turbo                 0.60        0.61        0.61        0.59   \n",
       "gpt-4                         0.79        0.77        0.77        0.74   \n",
       "text-davinci-002              0.42        0.46        0.52        0.36   \n",
       "text-davinci-003              0.50        0.47        0.40        0.44   \n",
       "\n",
       "prompt                  refl-01_None  zhou-01-ins_None  \n",
       "model                                                   \n",
       "command-xlarge-nightly           NaN               NaN  \n",
       "flan-T5-xxl                     0.36              0.40  \n",
       "gpt-3.5-turbo                   0.60              0.64  \n",
       "gpt-4                           0.77              0.79  \n",
       "text-davinci-002                0.35              0.30  \n",
       "text-davinci-003                0.48              0.48  "
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kripp_model_prompt.pivot_table(index=\"model\", columns=\"prompt\", values=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>command-xlarge-nightly</th>\n",
       "      <th>flan-T5-xxl</th>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <th>gpt-4</th>\n",
       "      <th>text-davinci-002</th>\n",
       "      <th>text-davinci-003</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>commonsense_qa</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_qa</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medmc_qa</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_book_qa</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategy_qa</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldtree</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model           command-xlarge-nightly  flan-T5-xxl  gpt-3.5-turbo  gpt-4  \\\n",
       "dataset                                                                     \n",
       "commonsense_qa                    0.66         0.83           0.68   0.75   \n",
       "med_qa                            0.26         0.21           0.50   0.64   \n",
       "medmc_qa                          0.31         0.34           0.59   0.78   \n",
       "open_book_qa                      0.57         0.77           0.76   0.91   \n",
       "strategy_qa                       0.25         0.62           0.60   0.82   \n",
       "worldtree                         0.75         0.81           0.91   0.98   \n",
       "\n",
       "model           text-davinci-002  text-davinci-003  \n",
       "dataset                                             \n",
       "commonsense_qa              0.69              0.69  \n",
       "med_qa                      0.27              0.34  \n",
       "medmc_qa                    0.40              0.39  \n",
       "open_book_qa                0.56              0.69  \n",
       "strategy_qa                 0.53              0.62  \n",
       "worldtree                   0.88              0.88  "
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_dataset_model = df.groupby([\"model\", \"dataset\"]).mean(\"correct_answer\").pivot_table(index=\"dataset\", columns=\"model\", values=\"correct_answer\")\n",
    "acc_dataset_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prompt</th>\n",
       "      <th>Direct</th>\n",
       "      <th>Ins-10</th>\n",
       "      <th>Ins-12</th>\n",
       "      <th>Ins-13</th>\n",
       "      <th>Ins-16</th>\n",
       "      <th>Ins-17</th>\n",
       "      <th>Kojima</th>\n",
       "      <th>Reflection</th>\n",
       "      <th>Zhou</th>\n",
       "      <th>Zhou-Ins</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>commonsense_qa</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_qa</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medmc_qa</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_book_qa</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategy_qa</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldtree</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prompt          Direct  Ins-10  Ins-12  Ins-13  Ins-16  Ins-17  Kojima  \\\n",
       "dataset                                                                  \n",
       "commonsense_qa    0.72    0.75    0.72    0.74    0.66    0.65    0.70   \n",
       "med_qa            0.37    0.36    0.38    0.37    0.40    0.36    0.37   \n",
       "medmc_qa          0.45    0.47    0.49    0.47    0.51    0.48    0.42   \n",
       "open_book_qa      0.73    0.72    0.74    0.66    0.66    0.70    0.68   \n",
       "strategy_qa       0.60    0.52    0.52    0.61    0.61    0.59    0.67   \n",
       "worldtree         0.87    0.85    0.91    0.89    0.83    0.84    0.83   \n",
       "\n",
       "prompt          Reflection  Zhou  Zhou-Ins  \n",
       "dataset                                     \n",
       "commonsense_qa        0.76  0.72      0.76  \n",
       "med_qa                0.35  0.39      0.36  \n",
       "medmc_qa              0.42  0.53      0.43  \n",
       "open_book_qa          0.72  0.78      0.72  \n",
       "strategy_qa           0.49  0.60      0.53  \n",
       "worldtree             0.86  0.87      0.90  "
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_dataset_prompt = df.groupby([\"prompt\", \"dataset\"]).mean(\"correct_answer\").pivot_table(index=\"dataset\", columns=\"prompt\", values=\"correct_answer\")\n",
    "acc_dataset_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kon/work/ThoughtSource/venv/lib/python3.10/site-packages/krippendorff/krippendorff.py:364: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - (o * d).sum() / (e * d).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There has to be at least one unit with values assigned by at least two coders.\n",
      "strategy_qa command-xlarge-nightly Ins-12\n",
      "There has to be at least one unit with values assigned by at least two coders.\n",
      "strategy_qa command-xlarge-nightly Ins-13\n",
      "There has to be at least one unit with values assigned by at least two coders.\n",
      "strategy_qa command-xlarge-nightly Ins-13\n",
      "There has to be at least one unit with values assigned by at least two coders.\n",
      "strategy_qa command-xlarge-nightly Zhou-Ins\n"
     ]
    }
   ],
   "source": [
    "# KRIPPENDORFF ALPHA all datasets together, pooling over datasets\n",
    "# Define bootstrapping parameters\n",
    "n_bootstraps = 1000\n",
    "confidence_level = 0.95\n",
    "np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# Perform bootstrapping and calculate means and confidence intervals\n",
    "results = []\n",
    "\n",
    "for (model, prompt), group in df.groupby(['model', 'prompt']):\n",
    "    unique_datasets = group['dataset'].unique()\n",
    "    dataset_means = {dataset: [] for dataset in unique_datasets}\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        random_dataset = random.choice(unique_datasets)\n",
    "        random_group = group[group['dataset'] == random_dataset]\n",
    "\n",
    "        answer_label = random_group['answer_label'].sample(n=len(random_group), replace=True)\n",
    "        indices = answer_label.index\n",
    "        answer_from_choices = random_group.loc[indices, 'answer_from_choices']\n",
    "\n",
    "        # since we only sample from few samples here, sometimes there are only samples with no label sampled\n",
    "        try:\n",
    "            metric = krippendorff.alpha(reliability_data=[list(answer_label), list(answer_from_choices)], level_of_measurement='nominal')\n",
    "            dataset_means[random_dataset].append(metric)\n",
    "\n",
    "        except Exception as e:\n",
    "                print(e)\n",
    "                print(random_dataset, model, prompt)\n",
    "                continue\n",
    "        \n",
    "\n",
    "    all_means = [np.mean(means) for means in dataset_means.values()]\n",
    "    mean = np.mean(all_means)\n",
    "\n",
    "    # Calculate the pooled standard deviation\n",
    "    dataset_stds = {dataset: np.std(means) for dataset, means in dataset_means.items()}\n",
    "\n",
    "    squared_stds = [std ** 2 for std in dataset_stds.values()]\n",
    "    pooled_std_dev = np.sqrt(sum(squared_stds) / len(squared_stds))\n",
    "\n",
    "    # Calculate the margin of error using the z-score\n",
    "    z_score = scipy.stats.norm.ppf((1 + confidence_level) / 2)\n",
    "    margin_of_error = z_score * (pooled_std_dev / np.sqrt(len(unique_datasets)))\n",
    "\n",
    "    # Compute the confidence interval\n",
    "    ci_lower = mean - margin_of_error\n",
    "    ci_upper = mean + margin_of_error\n",
    "\n",
    "    results.append({\n",
    "        'model': model,\n",
    "        'prompt': prompt,\n",
    "        'mean': mean,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[173, 168, 164, 156, 174, 165]"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in dataset_means.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>Direct</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  prompt  mean  ci_lower  ci_upper\n",
       "0  command-xlarge-nightly  Direct  0.23      0.13      0.33"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kripp_model_prompt = results_df.copy()\n",
    "kripp_model_prompt.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prompt</th>\n",
       "      <th>Direct</th>\n",
       "      <th>Ins-10</th>\n",
       "      <th>Ins-12</th>\n",
       "      <th>Ins-13</th>\n",
       "      <th>Ins-16</th>\n",
       "      <th>Ins-17</th>\n",
       "      <th>Kojima</th>\n",
       "      <th>Reflection</th>\n",
       "      <th>Zhou</th>\n",
       "      <th>Zhou-Ins</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>command-xlarge-nightly</th>\n",
       "      <td>0.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan-T5-xxl</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-002</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-003</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prompt                  Direct  Ins-10  Ins-12  Ins-13  Ins-16  Ins-17  \\\n",
       "model                                                                    \n",
       "command-xlarge-nightly    0.23     NaN     NaN     NaN    0.34    0.28   \n",
       "flan-T5-xxl               0.46    0.43    0.48    0.45    0.40    0.45   \n",
       "gpt-3.5-turbo             0.62    0.63    0.60    0.61    0.61    0.59   \n",
       "gpt-4                     0.72    0.78    0.79    0.77    0.77    0.74   \n",
       "text-davinci-002          0.40    0.31    0.43    0.45    0.52    0.36   \n",
       "text-davinci-003          0.43    0.44    0.49    0.47    0.40    0.44   \n",
       "\n",
       "prompt                  Kojima  Reflection  Zhou  Zhou-Ins  \n",
       "model                                                       \n",
       "command-xlarge-nightly    0.20         NaN  0.31       NaN  \n",
       "flan-T5-xxl               0.46        0.36  0.39      0.41  \n",
       "gpt-3.5-turbo             0.66        0.58  0.63      0.64  \n",
       "gpt-4                     0.81        0.76  0.84      0.80  \n",
       "text-davinci-002          0.40        0.35  0.52      0.31  \n",
       "text-davinci-003          0.45        0.48  0.50      0.48  "
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kripp_model_prompt_mean = kripp_model_prompt.pivot_table(values='mean', index='model', columns='prompt')\n",
    "kripp_model_prompt_ci_lower = kripp_model_prompt.pivot_table(values='ci_lower', index='model', columns='prompt')\n",
    "kripp_model_prompt_ci_upper = kripp_model_prompt.pivot_table(values='ci_upper', index='model', columns='prompt')\n",
    "kripp_model_prompt_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_model_prompt/kripp_model_prompt.pivot_table(index=\"model\", columns=\"prompt\", values=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KRIPPENDORFF ALPHA dataset by prompt sum over models\n",
    "\n",
    "# Define bootstrapping parameters\n",
    "n_bootstraps = 1000\n",
    "confidence_level = 0.95\n",
    "np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# Perform bootstrapping and calculate means and confidence intervals\n",
    "results = []\n",
    "\n",
    "for (dataset, prompt), group in df.groupby(['dataset', 'prompt']):\n",
    "    bootstrapped_means = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        answer_label = group['answer_label'].sample(n=len(group), replace=True)\n",
    "        indices = answer_label.index\n",
    "        answer_from_choices = group.loc[indices, 'answer_from_choices']\n",
    "\n",
    "        metric = krippendorff.alpha(reliability_data=[list(answer_label), list(answer_from_choices)],level_of_measurement='nominal')\n",
    "\n",
    "        bootstrapped_means.append(metric)\n",
    "    \n",
    "    mean = np.mean(bootstrapped_means)\n",
    "    lower = np.percentile(bootstrapped_means, (1 - confidence_level) / 2 * 100)\n",
    "    upper = np.percentile(bootstrapped_means, (1 + confidence_level) / 2 * 100)\n",
    "    \n",
    "    results.append({\n",
    "        'dataset': dataset,\n",
    "        # 'model': model,\n",
    "        'prompt': prompt,\n",
    "        'mean': mean,\n",
    "        'ci_lower': lower,\n",
    "        'ci_upper': upper\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame and pivot\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>prompt</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>Direct</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset  prompt  mean  ci_lower  ci_upper\n",
       "0  commonsense_qa  Direct  0.68      0.60      0.76"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kripp_dataset_prompt = results_df.copy()\n",
    "kripp_dataset_prompt.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prompt</th>\n",
       "      <th>Direct</th>\n",
       "      <th>Ins-10</th>\n",
       "      <th>Ins-12</th>\n",
       "      <th>Ins-13</th>\n",
       "      <th>Ins-16</th>\n",
       "      <th>Ins-17</th>\n",
       "      <th>Kojima</th>\n",
       "      <th>Reflection</th>\n",
       "      <th>Zhou</th>\n",
       "      <th>Zhou-Ins</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>commonsense_qa</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_qa</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medmc_qa</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_book_qa</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategy_qa</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldtree</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prompt          Direct  Ins-10  Ins-12  Ins-13  Ins-16  Ins-17  Kojima  \\\n",
       "dataset                                                                  \n",
       "commonsense_qa    0.68    0.73    0.73    0.75    0.68    0.63    0.69   \n",
       "med_qa            0.21    0.20    0.23    0.21    0.26    0.21    0.23   \n",
       "medmc_qa          0.28    0.30    0.35    0.31    0.36    0.32    0.25   \n",
       "open_book_qa      0.65    0.65    0.67    0.60    0.64    0.63    0.61   \n",
       "strategy_qa       0.24    0.29    0.32    0.46    0.40    0.33    0.44   \n",
       "worldtree         0.84    0.82    0.88    0.87    0.82    0.78    0.79   \n",
       "\n",
       "prompt          Reflection  Zhou  Zhou-Ins  \n",
       "dataset                                     \n",
       "commonsense_qa        0.73  0.72      0.73  \n",
       "med_qa                0.19  0.24      0.20  \n",
       "medmc_qa              0.25  0.37      0.27  \n",
       "open_book_qa          0.66  0.74      0.65  \n",
       "strategy_qa           0.21  0.38      0.31  \n",
       "worldtree             0.82  0.83      0.86  "
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kripp_dataset_prompt_mean = kripp_dataset_prompt.pivot_table(values='mean', index='dataset', columns='prompt')\n",
    "kripp_dataset_prompt_ci_lower = kripp_dataset_prompt.pivot_table(values='ci_lower', index='dataset', columns='prompt')\n",
    "kripp_dataset_prompt_ci_upper = kripp_dataset_prompt.pivot_table(values='ci_upper', index='dataset', columns='prompt')\n",
    "kripp_dataset_prompt_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kripp_dataset_prompt_mean.std(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kripp_dataset_prompt_mean.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_dataset_prompt/kripp_dataset_prompt.pivot_table(values='mean', index='dataset', columns='prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KRIPPENDORFF ALPHA dataset by model, sum over prompts\n",
    "# Define bootstrapping parameters\n",
    "n_bootstraps = 1000\n",
    "confidence_level = 0.95\n",
    "np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# Perform bootstrapping and calculate means and confidence intervals\n",
    "results = []\n",
    "\n",
    "for (dataset, model), group in df.groupby(['dataset', 'model']):\n",
    "    bootstrapped_means = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        answer_label = group['answer_label'].sample(n=len(group), replace=True)\n",
    "        indices = answer_label.index\n",
    "        answer_from_choices = group.loc[indices, 'answer_from_choices']\n",
    "\n",
    "        metric = krippendorff.alpha(reliability_data=[list(answer_label), list(answer_from_choices)],level_of_measurement='nominal')\n",
    "\n",
    "        bootstrapped_means.append(metric)\n",
    "    \n",
    "    mean = np.mean(bootstrapped_means)\n",
    "    lower = np.percentile(bootstrapped_means, (1 - confidence_level) / 2 * 100)\n",
    "    upper = np.percentile(bootstrapped_means, (1 + confidence_level) / 2 * 100)\n",
    "    \n",
    "    results.append({\n",
    "        'dataset': dataset,\n",
    "        'model': model,\n",
    "        # 'prompt': prompt,\n",
    "        'mean': mean,\n",
    "        'ci_lower': lower,\n",
    "        'ci_upper': upper\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame and pivot\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset                   model  mean  ci_lower  ci_upper\n",
       "0  commonsense_qa  command-xlarge-nightly  0.57      0.50      0.64"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kripp_dataset_model = results_df.copy()\n",
    "kripp_dataset_model.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>command-xlarge-nightly</th>\n",
       "      <th>flan-T5-xxl</th>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <th>gpt-4</th>\n",
       "      <th>text-davinci-002</th>\n",
       "      <th>text-davinci-003</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>commonsense_qa</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_qa</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medmc_qa</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_book_qa</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategy_qa</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldtree</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model           command-xlarge-nightly  flan-T5-xxl  gpt-3.5-turbo  gpt-4  \\\n",
       "dataset                                                                     \n",
       "commonsense_qa                    0.57         0.81           0.70   0.82   \n",
       "med_qa                            0.06         0.01           0.41   0.57   \n",
       "medmc_qa                          0.08         0.09           0.51   0.73   \n",
       "open_book_qa                      0.43         0.69           0.77   0.91   \n",
       "strategy_qa                       0.05         0.24           0.44   0.69   \n",
       "worldtree                         0.67         0.77           0.89   0.97   \n",
       "\n",
       "model           text-davinci-002  text-davinci-003  \n",
       "dataset                                             \n",
       "commonsense_qa              0.68              0.68  \n",
       "med_qa                      0.09              0.18  \n",
       "medmc_qa                    0.20              0.21  \n",
       "open_book_qa                0.45              0.66  \n",
       "strategy_qa                 0.22              0.22  \n",
       "worldtree                   0.84              0.84  "
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kripp_dataset_model_mean = kripp_dataset_model.pivot_table(values='mean', index='dataset', columns='model')\n",
    "kripp_dataset_model_ci_lower = kripp_dataset_model.pivot_table(values='ci_lower', index='dataset', columns='model')\n",
    "kripp_dataset_model_ci_upper = kripp_dataset_model.pivot_table(values='ci_upper', index='dataset', columns='model')\n",
    "kripp_dataset_model_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_dataset_model/kripp_dataset_model.pivot_table(values='mean', index='dataset', columns='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KRIPPENDORFF ALPHA only DATASET, sum over prompts and models\n",
    "# Define bootstrapping parameters\n",
    "n_bootstraps = 1000\n",
    "confidence_level = 0.95\n",
    "np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# Perform bootstrapping and calculate means and confidence intervals\n",
    "results = []\n",
    "\n",
    "for dataset, group in df.groupby('dataset'):\n",
    "    bootstrapped_means = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        answer_label = group['answer_label'].sample(n=len(group), replace=True)\n",
    "        indices = answer_label.index\n",
    "        answer_from_choices = group.loc[indices, 'answer_from_choices']\n",
    "\n",
    "        metric = krippendorff.alpha(reliability_data=[list(answer_label), list(answer_from_choices)],level_of_measurement='nominal')\n",
    "\n",
    "        bootstrapped_means.append(metric)\n",
    "    \n",
    "    mean = np.mean(bootstrapped_means)\n",
    "    lower = np.percentile(bootstrapped_means, (1 - confidence_level) / 2 * 100)\n",
    "    upper = np.percentile(bootstrapped_means, (1 + confidence_level) / 2 * 100)\n",
    "    \n",
    "    results.append({\n",
    "        'dataset': dataset,\n",
    "        # 'model': model,\n",
    "        # 'prompt': prompt,\n",
    "        'mean': mean,\n",
    "        'ci_lower': lower,\n",
    "        'ci_upper': upper\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame and pivot\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "kripp_dataset = results_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>med_qa</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medmc_qa</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open_book_qa</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strategy_qa</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset  mean  ci_lower  ci_upper\n",
       "0  commonsense_qa  0.71      0.68      0.73\n",
       "1          med_qa  0.22      0.19      0.25\n",
       "2        medmc_qa  0.31      0.27      0.34\n",
       "3    open_book_qa  0.65      0.63      0.68\n",
       "4     strategy_qa  0.34      0.30      0.39\n",
       "5       worldtree  0.83      0.81      0.85"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kripp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KRIPPENDORFF ALPHA model scores by summing over prompts and datasets\n",
    "# BOOTSTRAPPING SEPERATELY FOR EACH DATASET, SINCE THE NUMBER OF CHOICES IS DIFFERENT\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.stats\n",
    "\n",
    "n_bootstraps = 1000\n",
    "confidence_level = 0.95\n",
    "np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# Perform bootstrapping and calculate means and confidence intervals\n",
    "results = []\n",
    "\n",
    "for model, group in df.groupby('model'):\n",
    "    unique_datasets = group['dataset'].unique()\n",
    "    dataset_means = {dataset: [] for dataset in unique_datasets}\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "\n",
    "        random_dataset = random.choice(unique_datasets)\n",
    "        random_group = group[group['dataset'] == random_dataset]\n",
    "\n",
    "        answer_label = random_group['answer_label'].sample(n=len(random_group), replace=True)\n",
    "        indices = answer_label.index\n",
    "        answer_from_choices = random_group.loc[indices, 'answer_from_choices']\n",
    "\n",
    "        metric = krippendorff.alpha(reliability_data=[list(answer_label), list(answer_from_choices)], level_of_measurement='nominal')\n",
    "\n",
    "        dataset_means[random_dataset].append(metric)\n",
    "\n",
    "    all_means = [np.mean(means) for means in dataset_means.values()]\n",
    "    mean = np.mean(all_means)\n",
    "\n",
    "    # Calculate the pooled standard deviation\n",
    "    dataset_stds = {dataset: np.std(means) for dataset, means in dataset_means.items()}\n",
    "\n",
    "    squared_stds = [std ** 2 for std in dataset_stds.values()]\n",
    "    pooled_std_dev = np.sqrt(sum(squared_stds) / len(squared_stds))\n",
    "\n",
    "    # Calculate the margin of error using the z-score\n",
    "    z_score = scipy.stats.norm.ppf((1 + confidence_level) / 2)\n",
    "    margin_of_error = z_score * (pooled_std_dev / np.sqrt(len(unique_datasets)))\n",
    "\n",
    "    # Compute the confidence interval\n",
    "    ci_lower = mean - margin_of_error\n",
    "    ci_upper = mean + margin_of_error\n",
    "\n",
    "    results.append({\n",
    "        'model': model,\n",
    "        'mean': mean,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "kripp_model = results_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flan-T5-xxl</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  mean  ci_lower  ci_upper\n",
       "0  command-xlarge-nightly  0.31      0.27      0.35\n",
       "1             flan-T5-xxl  0.44      0.41      0.46\n",
       "2           gpt-3.5-turbo  0.62      0.59      0.65\n",
       "3                   gpt-4  0.78      0.76      0.81\n",
       "4        text-davinci-002  0.41      0.38      0.44\n",
       "5        text-davinci-003  0.46      0.43      0.49"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kripp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KRIPPENDORFF ALPHA prompt scores by summing over models and datasets\n",
    "# BOOTSTRAPPING SEPERATELY FOR EACH DATASET, SINCE THE NUMBER OF CHOICES IS DIFFERENT\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.stats\n",
    "\n",
    "n_bootstraps = 1000\n",
    "confidence_level = 0.95\n",
    "np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# Perform bootstrapping and calculate means and confidence intervals\n",
    "results = []\n",
    "\n",
    "for prompt, group in df.groupby('prompt'):\n",
    "    unique_datasets = group['dataset'].unique()\n",
    "    dataset_means = {dataset: [] for dataset in unique_datasets}\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "\n",
    "        random_dataset = random.choice(unique_datasets)\n",
    "        random_group = group[group['dataset'] == random_dataset]\n",
    "\n",
    "        answer_label = random_group['answer_label'].sample(n=len(random_group), replace=True)\n",
    "        indices = answer_label.index\n",
    "        answer_from_choices = random_group.loc[indices, 'answer_from_choices']\n",
    "\n",
    "        metric = krippendorff.alpha(reliability_data=[list(answer_label), list(answer_from_choices)], level_of_measurement='nominal')\n",
    "\n",
    "        dataset_means[random_dataset].append(metric)\n",
    "\n",
    "    all_means = [np.mean(means) for means in dataset_means.values()]\n",
    "    mean = np.mean(all_means)\n",
    "\n",
    "    # Calculate the pooled standard deviation\n",
    "    dataset_stds = {dataset: np.std(means) for dataset, means in dataset_means.items()}\n",
    "\n",
    "    squared_stds = [std ** 2 for std in dataset_stds.values()]\n",
    "    pooled_std_dev = np.sqrt(sum(squared_stds) / len(squared_stds))\n",
    "\n",
    "    # Calculate the margin of error using the z-score\n",
    "    z_score = scipy.stats.norm.ppf((1 + confidence_level) / 2)\n",
    "    margin_of_error = z_score * (pooled_std_dev / np.sqrt(len(unique_datasets)))\n",
    "\n",
    "    # Compute the confidence interval\n",
    "    ci_lower = mean - margin_of_error\n",
    "    ci_upper = mean + margin_of_error\n",
    "\n",
    "    results.append({\n",
    "        'prompt': prompt,\n",
    "        'mean': mean,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "kripp_prompt = results_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direct</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ins-10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ins-12</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ins-13</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ins-16</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ins-17</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kojima</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Reflection</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zhou</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zhou-Ins</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prompt  mean  ci_lower  ci_upper\n",
       "0      Direct  0.48      0.44      0.52\n",
       "1      Ins-10  0.50      0.46      0.54\n",
       "2      Ins-12  0.53      0.49      0.57\n",
       "3      Ins-13  0.53      0.49      0.57\n",
       "4      Ins-16  0.53      0.49      0.57\n",
       "5      Ins-17  0.48      0.44      0.52\n",
       "6      Kojima  0.50      0.47      0.54\n",
       "7  Reflection  0.47      0.44      0.51\n",
       "8        Zhou  0.55      0.51      0.58\n",
       "9    Zhou-Ins  0.50      0.47      0.54"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kripp_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = kripp_prompt.copy()\n",
    "# df = kripp_model.copy()\n",
    "df = kripp_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcc}\n",
      "\\toprule\n",
      "       dataset &           mean_ci \\\\\n",
      "\\midrule\n",
      "commonsense_qa & 0.71 (0.68, 0.73) \\\\\n",
      "        med_qa & 0.22 (0.19, 0.25) \\\\\n",
      "      medmc_qa & 0.31 (0.27, 0.34) \\\\\n",
      "  open_book_qa & 0.65 (0.63, 0.68) \\\\\n",
      "   strategy_qa &  0.34 (0.3, 0.39) \\\\\n",
      "     worldtree & 0.83 (0.81, 0.85) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_273/3894489030.py:7: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = df.to_latex(column_format=\"l\" + \"c\" * len(df.columns), float_format=\"{:.2f}\".format, escape=False, index=False)\n"
     ]
    }
   ],
   "source": [
    "df['mean_ci'] = df['mean'].round(2).astype(str) + \" (\" + df['ci_lower'].round(2).astype(str) + \", \" + df['ci_upper'].round(2).astype(str) + \")\"\n",
    "\n",
    "# Drop the original 'mean', 'ci_lower', and 'ci_upper' columns\n",
    "df = df.drop(columns=['mean', 'ci_lower', 'ci_upper'])\n",
    "\n",
    "# Convert the DataFrame to a LaTeX table\n",
    "latex_table = df.to_latex(column_format=\"l\" + \"c\" * len(df.columns), float_format=\"{:.2f}\".format, escape=False, index=False)\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pivot = kripp_dataset_model_mean.copy().round(2)\n",
    "ci_lower = kripp_dataset_model_ci_lower.copy().round(2)\n",
    "ci_upper = kripp_dataset_model_ci_upper.copy().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcccccc}\n",
      "\\toprule\n",
      "model &            command-xlarge-nightly &                       flan-T5-xxl &                    gpt-3.5-turbo &                            gpt-4 &                 text-davinci-002 &                 text-davinci-003 \\\\\n",
      "dataset        &                                   &                                   &                                  &                                  &                                  &                                  \\\\\n",
      "\\midrule\n",
      "commonsense_qa &    0.57 ({\\scriptsize 0.5, 0.64}) &   0.81 ({\\scriptsize 0.75, 0.85}) &   0.7 ({\\scriptsize 0.64, 0.76}) &  0.82 ({\\scriptsize 0.76, 0.87}) &  0.68 ({\\scriptsize 0.62, 0.74}) &  0.68 ({\\scriptsize 0.62, 0.74}) \\\\\n",
      "med_qa         &   0.06 ({\\scriptsize 0.01, 0.13}) &  0.01 ({\\scriptsize -0.04, 0.07}) &  0.41 ({\\scriptsize 0.35, 0.48}) &   0.57 ({\\scriptsize 0.5, 0.64}) &  0.09 ({\\scriptsize 0.03, 0.15}) &  0.18 ({\\scriptsize 0.12, 0.25}) \\\\\n",
      "medmc_qa       &   0.08 ({\\scriptsize 0.01, 0.14}) &   0.09 ({\\scriptsize 0.02, 0.16}) &  0.51 ({\\scriptsize 0.44, 0.58}) &  0.73 ({\\scriptsize 0.67, 0.79}) &   0.2 ({\\scriptsize 0.13, 0.27}) &  0.21 ({\\scriptsize 0.14, 0.28}) \\\\\n",
      "open_book_qa   &    0.43 ({\\scriptsize 0.36, 0.5}) &   0.69 ({\\scriptsize 0.63, 0.76}) &  0.77 ({\\scriptsize 0.71, 0.83}) &  0.91 ({\\scriptsize 0.87, 0.95}) &  0.45 ({\\scriptsize 0.37, 0.52}) &  0.66 ({\\scriptsize 0.59, 0.72}) \\\\\n",
      "strategy_qa    &  0.05 ({\\scriptsize -0.11, 0.21}) &   0.24 ({\\scriptsize 0.13, 0.34}) &  0.44 ({\\scriptsize 0.33, 0.55}) &  0.69 ({\\scriptsize 0.61, 0.76}) &  0.22 ({\\scriptsize 0.09, 0.34}) &  0.22 ({\\scriptsize 0.12, 0.31}) \\\\\n",
      "worldtree      &   0.67 ({\\scriptsize 0.61, 0.73}) &   0.77 ({\\scriptsize 0.72, 0.83}) &  0.89 ({\\scriptsize 0.85, 0.93}) &  0.97 ({\\scriptsize 0.95, 0.99}) &  0.84 ({\\scriptsize 0.79, 0.89}) &   0.84 ({\\scriptsize 0.8, 0.89}) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_273/1925743105.py:8: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = final_df.to_latex(column_format=\"l\" + \"c\" * len(final_df.columns), float_format=\"{:.2f}\".format, escape=False)\n"
     ]
    }
   ],
   "source": [
    "# Combine the DataFrames\n",
    "\n",
    "final_df = mean_pivot.copy()\n",
    "for col in mean_pivot.columns:\n",
    "    final_df[col] = mean_pivot[col].round(4).astype(str) + \" ({\\\\scriptsize \" + ci_lower[col].round(4).astype(str) + \", \" + ci_upper[col].round(4).astype(str) + \"})\"\n",
    "\n",
    "# Apply custom formatting (use LaTeX format for a scientific paper)\n",
    "latex_table = final_df.to_latex(column_format=\"l\" + \"c\" * len(final_df.columns), float_format=\"{:.2f}\".format, escape=False)\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test runs for checking scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_273/1604803771.py:16: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for (dataset), group in df.groupby(['dataset']):\n"
     ]
    }
   ],
   "source": [
    "# test run to see if the pooling is correct for the dataset option\n",
    "# bootstrapping per dataset is not needed for the dataset option, we can check if it leads to the same results\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.stats\n",
    "\n",
    "n_bootstraps = 1000\n",
    "confidence_level = 0.95\n",
    "np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# Perform bootstrapping and calculate means and confidence intervals\n",
    "results = []\n",
    "\n",
    "for (dataset), group in df.groupby(['dataset']):\n",
    "    unique_datasets = group['model'].unique()\n",
    "    dataset_means = {dataset: [] for dataset in unique_datasets}\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "\n",
    "        random_dataset = random.choice(unique_datasets)\n",
    "        random_group = group[group['model'] == random_dataset]\n",
    "\n",
    "        answer_label = random_group['answer_label'].sample(n=len(random_group), replace=True)\n",
    "        indices = answer_label.index\n",
    "        answer_from_choices = random_group.loc[indices, 'answer_from_choices']\n",
    "\n",
    "        metric = krippendorff.alpha(reliability_data=[list(answer_label), list(answer_from_choices)], level_of_measurement='nominal')\n",
    "\n",
    "        dataset_means[random_dataset].append(metric)\n",
    "\n",
    "    all_means = [np.mean(means) for means in dataset_means.values()]\n",
    "    mean = np.mean(all_means)\n",
    "\n",
    "    # Calculate the pooled standard deviation\n",
    "    dataset_stds = {dataset: np.std(means) for dataset, means in dataset_means.items()}\n",
    "\n",
    "    squared_stds = [std ** 2 for std in dataset_stds.values()]\n",
    "    pooled_std_dev = np.sqrt(sum(squared_stds) / len(squared_stds))\n",
    "\n",
    "    # Calculate the margin of error using the z-score\n",
    "    z_score = scipy.stats.norm.ppf((1 + confidence_level) / 2)\n",
    "    margin_of_error = z_score * (pooled_std_dev / np.sqrt(len(unique_datasets)))\n",
    "\n",
    "    # Compute the confidence interval\n",
    "    ci_lower = mean - margin_of_error\n",
    "    ci_upper = mean + margin_of_error\n",
    "\n",
    "    results.append({\n",
    "        'dataset': dataset,\n",
    "        'mean': mean,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.6876</td>\n",
       "      <td>0.7346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>med_qa</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>0.1956</td>\n",
       "      <td>0.2459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medmc_qa</td>\n",
       "      <td>0.3022</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>0.3306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open_book_qa</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>0.6248</td>\n",
       "      <td>0.6777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strategy_qa</td>\n",
       "      <td>0.3085</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0.3565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>0.8329</td>\n",
       "      <td>0.8139</td>\n",
       "      <td>0.8519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset   mean  ci_lower  ci_upper\n",
       "0  commonsense_qa 0.7111    0.6876    0.7346\n",
       "1          med_qa 0.2207    0.1956    0.2459\n",
       "2        medmc_qa 0.3022    0.2737    0.3306\n",
       "3    open_book_qa 0.6512    0.6248    0.6777\n",
       "4     strategy_qa 0.3085    0.2605    0.3565\n",
       "5       worldtree 0.8329    0.8139    0.8519"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if the pooling is correct for the dataset option\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.6819</td>\n",
       "      <td>0.7314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>med_qa</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medmc_qa</td>\n",
       "      <td>0.3051</td>\n",
       "      <td>0.2749</td>\n",
       "      <td>0.3358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open_book_qa</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.6258</td>\n",
       "      <td>0.6780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strategy_qa</td>\n",
       "      <td>0.3436</td>\n",
       "      <td>0.2961</td>\n",
       "      <td>0.3935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset   mean  ci_lower  ci_upper\n",
       "0  commonsense_qa 0.7073    0.6819    0.7314\n",
       "1          med_qa 0.2184    0.1920    0.2456\n",
       "2        medmc_qa 0.3051    0.2749    0.3358\n",
       "3    open_book_qa 0.6516    0.6258    0.6780\n",
       "4     strategy_qa 0.3436    0.2961    0.3935\n",
       "5       worldtree 0.8325    0.8125    0.8525"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be very similar to\n",
    "kripp_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these two should roughly be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "command-xlarge-nightly   0.3103\n",
       "flan-T5-xxl              0.4359\n",
       "gpt-3.5-turbo            0.6212\n",
       "gpt-4                    0.7827\n",
       "text-davinci-002         0.4138\n",
       "text-davinci-003         0.4648\n",
       "dtype: float64"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kripp_dataset_model.pivot_table(values='mean', index='dataset', columns='model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>command-xlarge-nightly</td>\n",
       "      <td>0.3135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flan-T5-xxl</td>\n",
       "      <td>0.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.6334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.7835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>0.4185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>0.4698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model   mean\n",
       "0  command-xlarge-nightly 0.3135\n",
       "1             flan-T5-xxl 0.4325\n",
       "2           gpt-3.5-turbo 0.6334\n",
       "3                   gpt-4 0.7835\n",
       "4        text-davinci-002 0.4185\n",
       "5        text-davinci-003 0.4698"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kripp_model[['model','mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # INCORRECT SINCE SUMMING OVER DATASETS\n",
    "# # RESULTS WILL BE TOO HIGH\n",
    "\n",
    "# # KRIPPENDORFF ALPHA all datasets together\n",
    "# # Define bootstrapping parameters\n",
    "# n_bootstraps = 1000\n",
    "# confidence_level = 0.95\n",
    "# np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# # Perform bootstrapping and calculate means and confidence intervals\n",
    "# results = []\n",
    "\n",
    "# for (model, prompt), group in df.groupby(['model', 'prompt']):\n",
    "#     bootstrapped_means = []\n",
    "#     for _ in range(n_bootstraps):\n",
    "#         answer_label = group['answer_label'].sample(n=len(group), replace=True)\n",
    "#         indices = answer_label.index\n",
    "#         answer_from_choices = group.loc[indices, 'answer_from_choices']\n",
    "\n",
    "#         metric = krippendorff.alpha(reliability_data=[list(answer_label), list(answer_from_choices)],level_of_measurement='nominal')\n",
    "\n",
    "#         bootstrapped_means.append(metric)\n",
    "    \n",
    "#     mean = np.mean(bootstrapped_means)\n",
    "#     lower = np.percentile(bootstrapped_means, (1 - confidence_level) / 2 * 100)\n",
    "#     upper = np.percentile(bootstrapped_means, (1 + confidence_level) / 2 * 100)\n",
    "    \n",
    "#     results.append({\n",
    "#         # 'dataset': dataset,\n",
    "#         'model': model,\n",
    "#         'prompt': prompt,\n",
    "#         'mean': mean,\n",
    "#         'ci_lower': lower,\n",
    "#         'ci_upper': upper\n",
    "#     })\n",
    "\n",
    "# # Convert the results to a DataFrame and pivot\n",
    "# results_df = pd.DataFrame(results)\n",
    "\n",
    "# results_df.pivot_table(values='mean', index='model', columns='prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define bootstrapping parameters\n",
    "# n_bootstraps = 1000\n",
    "# confidence_level = 0.95\n",
    "# np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# # Perform bootstrapping and calculate means and confidence intervals\n",
    "# results = []\n",
    "\n",
    "# for (model, prompt, dataset), group in df.groupby(['model', 'prompt', 'dataset']):\n",
    "#     bootstrapped_means = []\n",
    "#     for _ in range(n_bootstraps):\n",
    "#         resampled = group['correct_answer'].sample(n=len(group), replace=True)\n",
    "#         bootstrapped_means.append(resampled.mean())\n",
    "    \n",
    "#     mean = np.mean(bootstrapped_means)\n",
    "#     lower = np.percentile(bootstrapped_means, (1 - confidence_level) / 2 * 100)\n",
    "#     upper = np.percentile(bootstrapped_means, (1 + confidence_level) / 2 * 100)\n",
    "    \n",
    "#     results.append({\n",
    "#         'dataset': dataset,\n",
    "#         'model': model,\n",
    "#         'prompt': prompt,\n",
    "#         'mean': mean,\n",
    "#         'ci_lower': lower,\n",
    "#         'ci_upper': upper\n",
    "#     })\n",
    "\n",
    "# # Convert the results to a DataFrame and pivot\n",
    "# results_df = pd.DataFrame(results)\n",
    "# mean_pivot = results_df.pivot_table(values='mean', index='model', columns='prompt')\n",
    "# ci_pivot_lower = results_df.pivot_table(values='ci_lower', index='model', columns='prompt')\n",
    "# ci_pivot_upper = results_df.pivot_table(values='ci_upper', index='model', columns='prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ACCURACY BOOTSRTAPPING\n",
    "# # Define bootstrapping parameters\n",
    "# n_bootstraps = 1000\n",
    "# confidence_level = 0.95\n",
    "# np.random.seed(42)  # Set the seed for reproducibility\n",
    "\n",
    "# # Perform bootstrapping and calculate means and confidence intervals\n",
    "# results = []\n",
    "\n",
    "# for (model, prompt), group in df.groupby(['model', 'prompt']):\n",
    "#     bootstrapped_means = []\n",
    "#     for _ in range(n_bootstraps):\n",
    "#         resampled = group['correct_answer'].sample(n=len(group), replace=True)\n",
    "#         bootstrapped_means.append(resampled.mean())\n",
    "    \n",
    "#     mean = np.mean(bootstrapped_means)\n",
    "#     lower = np.percentile(bootstrapped_means, (1 - confidence_level) / 2 * 100)\n",
    "#     upper = np.percentile(bootstrapped_means, (1 + confidence_level) / 2 * 100)\n",
    "    \n",
    "#     results.append({\n",
    "#         'model': model,\n",
    "#         'prompt': prompt,\n",
    "#         'mean': mean,\n",
    "#         'ci_lower': lower,\n",
    "#         'ci_upper': upper\n",
    "#     })\n",
    "\n",
    "# # Convert the results to a DataFrame and pivot\n",
    "# results_df = pd.DataFrame(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspection of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df.dataset == \"strategy_qa\")& (df.model == \"command-xlarge-nightly\") & (df.prompt == \"None_zhou-01\")]\n",
    "# filtered_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df[['answer', 'answer_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df[\"correct_answer\"].unique(), filtered_df[\"answer_from_choices\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df[\"correct_answer\"].value_counts(), filtered_df[\"answer_from_choices\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df[\"correct_answer\"].count(), filtered_df[\"answer_from_choices\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0493"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "krippendorff.alpha(reliability_data=[list(filtered_df[\"answer_label\"]), list(filtered_df[\"answer_from_choices\"].replace(\"\", np.nan))],level_of_measurement='nominal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df[[\"answer\",\"answer_from_choices\"]][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['dataset'])['number_choices'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions extra, non pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_function_new(eval:dict):\n",
    "    import pandas as pd\n",
    "    eval_dict = pd.json_normalize(eval).to_dict('records')[0]\n",
    "    eval_list = list(eval_dict.keys())\n",
    "    datasets = sorted(list(eval.keys()))\n",
    "\n",
    "    models = []\n",
    "    prompts = []\n",
    "    for i in eval_list:\n",
    "        # fast fix for chat gpt model:\n",
    "        i = i.replace(\"gpt-3.5-turbo\",\"gpt-3-5-turbo\")\n",
    "        dataset,split,metric,model,prompt = i.split(\".\")\n",
    "        model = model.replace(\"gpt-3-5-turbo\",\"gpt-3.5-turbo\")\n",
    "        if model not in models:\n",
    "            models.append(model)\n",
    "        if prompt not in prompts:\n",
    "            prompts.append(prompt)\n",
    "            \n",
    "    models = sorted(models)\n",
    "\n",
    "    if \"None_None_None\" in prompts: prompts.remove(\"None_None_None\")\n",
    "\n",
    "    # no instructions implemented yet\n",
    "    # instructions = []\n",
    "    cot_triggers = []\n",
    "    for i in prompts:\n",
    "        instruction, cot_trigger, _ = i.split(\"_\")\n",
    "        # if instruction not in instructions:\n",
    "        #     instructions.append(instruction)\n",
    "\n",
    "        # old: only cot_trigger\n",
    "        # if cot_trigger not in cot_triggers:\n",
    "        #     cot_triggers.append(cot_trigger)\n",
    "\n",
    "        # new: instruction + cot_trigger\n",
    "        if cot_trigger not in cot_triggers:\n",
    "            cot_triggers.append(instruction + \"_\" + cot_trigger)\n",
    "\n",
    "    cot_triggers = sorted(cot_triggers)\n",
    "\n",
    "    cot_trigger_header = sorted(cot_triggers*len(models))\n",
    "    model_header = models*len(cot_triggers)\n",
    "\n",
    "    # Create a dictionary to store the data\n",
    "    data_dict = {}\n",
    "    for k,v in eval_dict.items():\n",
    "        # fast fix for chat gpt model:\n",
    "        k = k.replace(\"gpt-3.5-turbo\",\"gpt-3-5-turbo\")\n",
    "        dataset,split,metric,model,prompt = k.split(\".\")\n",
    "        model = model.replace(\"gpt-3-5-turbo\",\"gpt-3.5-turbo\")\n",
    "        instruction, cot_trigger, _ = prompt.split(\"_\")\n",
    "        # old: only cot_trigger\n",
    "        # df.loc[dataset, (cot_trigger, model)] = v\n",
    "\n",
    "        # new: instruction + cot_trigger\n",
    "        col_name = instruction + \"_\" + cot_trigger + \"_\" + model\n",
    "        if dataset not in data_dict:\n",
    "            data_dict[dataset] = {}\n",
    "        data_dict[dataset][col_name] = v\n",
    "\n",
    "    # Create a dataframe from the dictionary\n",
    "    df = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "\n",
    "    # Calculate the average row and add it to the dataframe\n",
    "    df.loc['Average'] = df.mean()\n",
    "\n",
    "    # Round the dataframe to 2 decimal places\n",
    "    df = df.round(2)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None_None_command-xlarge-nightly</th>\n",
       "      <th>None_kojima-01_command-xlarge-nightly</th>\n",
       "      <th>None_zhou-01_command-xlarge-nightly</th>\n",
       "      <th>qa-10_None_command-xlarge-nightly</th>\n",
       "      <th>qa-12_None_command-xlarge-nightly</th>\n",
       "      <th>qa-13_None_command-xlarge-nightly</th>\n",
       "      <th>qa-16_None_command-xlarge-nightly</th>\n",
       "      <th>qa-17_None_command-xlarge-nightly</th>\n",
       "      <th>refl-01_None_command-xlarge-nightly</th>\n",
       "      <th>zhou-01-ins_None_command-xlarge-nightly</th>\n",
       "      <th>...</th>\n",
       "      <th>None_None_text-davinci-003</th>\n",
       "      <th>None_kojima-01_text-davinci-003</th>\n",
       "      <th>None_zhou-01_text-davinci-003</th>\n",
       "      <th>qa-10_None_text-davinci-003</th>\n",
       "      <th>qa-12_None_text-davinci-003</th>\n",
       "      <th>qa-13_None_text-davinci-003</th>\n",
       "      <th>qa-16_None_text-davinci-003</th>\n",
       "      <th>qa-17_None_text-davinci-003</th>\n",
       "      <th>refl-01_None_text-davinci-003</th>\n",
       "      <th>zhou-01-ins_None_text-davinci-003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>commonsense_qa</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_qa</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medmc_qa</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_book_qa</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategy_qa</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldtree</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                None_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                              0.52   \n",
       "med_qa                                      0.18   \n",
       "medmc_qa                                    0.27   \n",
       "open_book_qa                                0.58   \n",
       "strategy_qa                                 0.55   \n",
       "worldtree                                   0.61   \n",
       "Average                                     0.45   \n",
       "\n",
       "                None_kojima-01_command-xlarge-nightly  \\\n",
       "commonsense_qa                                   0.48   \n",
       "med_qa                                           0.30   \n",
       "medmc_qa                                         0.15   \n",
       "open_book_qa                                     0.42   \n",
       "strategy_qa                                      0.58   \n",
       "worldtree                                        0.61   \n",
       "Average                                          0.42   \n",
       "\n",
       "                None_zhou-01_command-xlarge-nightly  \\\n",
       "commonsense_qa                                 0.73   \n",
       "med_qa                                         0.27   \n",
       "medmc_qa                                       0.42   \n",
       "open_book_qa                                   0.61   \n",
       "strategy_qa                                    0.24   \n",
       "worldtree                                      0.76   \n",
       "Average                                        0.51   \n",
       "\n",
       "                qa-10_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                               0.70   \n",
       "med_qa                                       0.27   \n",
       "medmc_qa                                     0.27   \n",
       "open_book_qa                                 0.58   \n",
       "strategy_qa                                  0.12   \n",
       "worldtree                                    0.73   \n",
       "Average                                      0.44   \n",
       "\n",
       "                qa-12_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                               0.70   \n",
       "med_qa                                       0.27   \n",
       "medmc_qa                                     0.30   \n",
       "open_book_qa                                 0.58   \n",
       "strategy_qa                                  0.09   \n",
       "worldtree                                    0.82   \n",
       "Average                                      0.46   \n",
       "\n",
       "                qa-13_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                               0.76   \n",
       "med_qa                                       0.24   \n",
       "medmc_qa                                     0.36   \n",
       "open_book_qa                                 0.58   \n",
       "strategy_qa                                  0.12   \n",
       "worldtree                                    0.85   \n",
       "Average                                      0.48   \n",
       "\n",
       "                qa-16_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                               0.67   \n",
       "med_qa                                       0.33   \n",
       "medmc_qa                                     0.36   \n",
       "open_book_qa                                 0.55   \n",
       "strategy_qa                                  0.33   \n",
       "worldtree                                    0.85   \n",
       "Average                                      0.52   \n",
       "\n",
       "                qa-17_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                               0.61   \n",
       "med_qa                                       0.30   \n",
       "medmc_qa                                     0.36   \n",
       "open_book_qa                                 0.61   \n",
       "strategy_qa                                  0.30   \n",
       "worldtree                                    0.64   \n",
       "Average                                      0.47   \n",
       "\n",
       "                refl-01_None_command-xlarge-nightly  \\\n",
       "commonsense_qa                                 0.70   \n",
       "med_qa                                         0.21   \n",
       "medmc_qa                                       0.24   \n",
       "open_book_qa                                   0.61   \n",
       "strategy_qa                                    0.06   \n",
       "worldtree                                      0.79   \n",
       "Average                                        0.43   \n",
       "\n",
       "                zhou-01-ins_None_command-xlarge-nightly  ...  \\\n",
       "commonsense_qa                                     0.73  ...   \n",
       "med_qa                                             0.24  ...   \n",
       "medmc_qa                                           0.33  ...   \n",
       "open_book_qa                                       0.64  ...   \n",
       "strategy_qa                                        0.09  ...   \n",
       "worldtree                                          0.82  ...   \n",
       "Average                                            0.47  ...   \n",
       "\n",
       "                None_None_text-davinci-003  None_kojima-01_text-davinci-003  \\\n",
       "commonsense_qa                        0.73                             0.67   \n",
       "med_qa                                0.30                             0.33   \n",
       "medmc_qa                              0.36                             0.36   \n",
       "open_book_qa                          0.64                             0.58   \n",
       "strategy_qa                           0.61                             0.64   \n",
       "worldtree                             0.94                             0.91   \n",
       "Average                               0.60                             0.58   \n",
       "\n",
       "                None_zhou-01_text-davinci-003  qa-10_None_text-davinci-003  \\\n",
       "commonsense_qa                           0.67                         0.70   \n",
       "med_qa                                   0.39                         0.36   \n",
       "medmc_qa                                 0.48                         0.45   \n",
       "open_book_qa                             0.79                         0.73   \n",
       "strategy_qa                              0.64                         0.58   \n",
       "worldtree                                0.82                         0.82   \n",
       "Average                                  0.63                         0.61   \n",
       "\n",
       "                qa-12_None_text-davinci-003  qa-13_None_text-davinci-003  \\\n",
       "commonsense_qa                         0.79                         0.67   \n",
       "med_qa                                 0.30                         0.39   \n",
       "medmc_qa                               0.36                         0.36   \n",
       "open_book_qa                           0.79                         0.61   \n",
       "strategy_qa                            0.67                         0.70   \n",
       "worldtree                              0.91                         0.85   \n",
       "Average                                0.64                         0.60   \n",
       "\n",
       "                qa-16_None_text-davinci-003  qa-17_None_text-davinci-003  \\\n",
       "commonsense_qa                         0.58                         0.64   \n",
       "med_qa                                 0.36                         0.24   \n",
       "medmc_qa                               0.39                         0.42   \n",
       "open_book_qa                           0.64                         0.73   \n",
       "strategy_qa                            0.55                         0.58   \n",
       "worldtree                              0.82                         0.91   \n",
       "Average                                0.56                         0.59   \n",
       "\n",
       "                refl-01_None_text-davinci-003  \\\n",
       "commonsense_qa                           0.76   \n",
       "med_qa                                   0.33   \n",
       "medmc_qa                                 0.39   \n",
       "open_book_qa                             0.64   \n",
       "strategy_qa                              0.64   \n",
       "worldtree                                0.91   \n",
       "Average                                  0.61   \n",
       "\n",
       "                zhou-01-ins_None_text-davinci-003  \n",
       "commonsense_qa                               0.73  \n",
       "med_qa                                       0.36  \n",
       "medmc_qa                                     0.33  \n",
       "open_book_qa                                 0.82  \n",
       "strategy_qa                                  0.64  \n",
       "worldtree                                    0.88  \n",
       "Average                                      0.63  \n",
       "\n",
       "[7 rows x 60 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = table_function_new(eval)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None_None_command-xlarge-nightly</th>\n",
       "      <th>None_kojima-01_command-xlarge-nightly</th>\n",
       "      <th>None_zhou-01_command-xlarge-nightly</th>\n",
       "      <th>qa-10_None_command-xlarge-nightly</th>\n",
       "      <th>qa-12_None_command-xlarge-nightly</th>\n",
       "      <th>qa-13_None_command-xlarge-nightly</th>\n",
       "      <th>qa-16_None_command-xlarge-nightly</th>\n",
       "      <th>qa-17_None_command-xlarge-nightly</th>\n",
       "      <th>refl-01_None_command-xlarge-nightly</th>\n",
       "      <th>zhou-01-ins_None_command-xlarge-nightly</th>\n",
       "      <th>...</th>\n",
       "      <th>None_None_text-davinci-003</th>\n",
       "      <th>None_kojima-01_text-davinci-003</th>\n",
       "      <th>None_zhou-01_text-davinci-003</th>\n",
       "      <th>qa-10_None_text-davinci-003</th>\n",
       "      <th>qa-12_None_text-davinci-003</th>\n",
       "      <th>qa-13_None_text-davinci-003</th>\n",
       "      <th>qa-16_None_text-davinci-003</th>\n",
       "      <th>qa-17_None_text-davinci-003</th>\n",
       "      <th>refl-01_None_text-davinci-003</th>\n",
       "      <th>zhou-01-ins_None_text-davinci-003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         None_None_command-xlarge-nightly  \\\n",
       "Average                              0.45   \n",
       "\n",
       "         None_kojima-01_command-xlarge-nightly  \\\n",
       "Average                                   0.42   \n",
       "\n",
       "         None_zhou-01_command-xlarge-nightly  \\\n",
       "Average                                 0.51   \n",
       "\n",
       "         qa-10_None_command-xlarge-nightly  qa-12_None_command-xlarge-nightly  \\\n",
       "Average                               0.44                               0.46   \n",
       "\n",
       "         qa-13_None_command-xlarge-nightly  qa-16_None_command-xlarge-nightly  \\\n",
       "Average                               0.48                               0.52   \n",
       "\n",
       "         qa-17_None_command-xlarge-nightly  \\\n",
       "Average                               0.47   \n",
       "\n",
       "         refl-01_None_command-xlarge-nightly  \\\n",
       "Average                                 0.43   \n",
       "\n",
       "         zhou-01-ins_None_command-xlarge-nightly  ...  \\\n",
       "Average                                     0.47  ...   \n",
       "\n",
       "         None_None_text-davinci-003  None_kojima-01_text-davinci-003  \\\n",
       "Average                         0.6                             0.58   \n",
       "\n",
       "         None_zhou-01_text-davinci-003  qa-10_None_text-davinci-003  \\\n",
       "Average                           0.63                         0.61   \n",
       "\n",
       "         qa-12_None_text-davinci-003  qa-13_None_text-davinci-003  \\\n",
       "Average                         0.64                          0.6   \n",
       "\n",
       "         qa-16_None_text-davinci-003  qa-17_None_text-davinci-003  \\\n",
       "Average                         0.56                         0.59   \n",
       "\n",
       "         refl-01_None_text-davinci-003  zhou-01-ins_None_text-davinci-003  \n",
       "Average                           0.61                               0.63  \n",
       "\n",
       "[1 rows x 60 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (df[df.index==\"Average\"])\n",
    "#df.to_csv(\"Average_values_df.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "import pandas as pd\n",
    "def clean_column(df, col_name):\n",
    "    pattern = r\"^.?'(.?)'.?'(.?)'.?'(.?)'.?'(.?)'.*$\"\n",
    "    return(df[col_name].apply(lambda x: re.sub(pattern, r\"'\\3\", x)[1:]))\n",
    "\n",
    "def json_to_dataframe_3(json_data):\n",
    "    df_data = []\n",
    "    for category, data in json_data.items():\n",
    "        for subset, questions in data.items():\n",
    "            for question in questions:\n",
    "                for generated_cot in question['generated_cot']:\n",
    "                    row = {\n",
    "                        'dataset': category,\n",
    "                        'split': subset,\n",
    "                        'id': question['id'],\n",
    "                        'model': generated_cot['model'],\n",
    "                        'instruction': generated_cot['instruction'],\n",
    "                        'cot_trigger': generated_cot[\"cot_trigger\"],\n",
    "                        'generated_cot': generated_cot['cot'],\n",
    "                        'correct_answer': generated_cot['answers'][0]['correct_answer'],\n",
    "                    }\n",
    "                    df_data.append(row)\n",
    "    df = pd.DataFrame(df_data)\n",
    "    # df[\"model\"] = clean_column(df, \"model\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'name': 'command-xlarge-nightly', 'temperature': 0, 'max_tokens': 512}\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"model\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>instruction</th>\n",
       "      <th>cot_trigger</th>\n",
       "      <th>generated_cot</th>\n",
       "      <th>correct_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>'name': 'command-xlarge-nightly', 'temperature...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The main purpose of farmers is to supply food.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>'name': 'text-davinci-003', 'temperature': 0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>E) supply food</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>'name': 'flan-T5-xxl', 'temperature': 0, 'max_...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>'name': 'gpt-3.5-turbo', 'temperature': 0, 'ma...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>E) supply food</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>commonsense_qa</td>\n",
       "      <td>validation</td>\n",
       "      <td>9aff72f0c480c2b4edde45bd2e7e4870</td>\n",
       "      <td>'name': 'text-davinci-002', 'temperature': 0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\\nE) supply food</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11875</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>test</td>\n",
       "      <td>worldtree_test_1659</td>\n",
       "      <td>'name': 'flan-T5-xxl', 'temperature': 0, 'max_...</td>\n",
       "      <td>None</td>\n",
       "      <td>zhou-01</td>\n",
       "      <td>C is the dependent variable. The dependent var...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11876</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>test</td>\n",
       "      <td>worldtree_test_1659</td>\n",
       "      <td>'name': 'text-davinci-003', 'temperature': 0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>zhou-01</td>\n",
       "      <td>\\n\\nStep 1: The vertical axis on a graph is t...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11877</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>test</td>\n",
       "      <td>worldtree_test_1659</td>\n",
       "      <td>'name': 'text-davinci-002', 'temperature': 0, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>zhou-01</td>\n",
       "      <td>\\n\\nThe first thing we need to do is identify...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11878</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>test</td>\n",
       "      <td>worldtree_test_1659</td>\n",
       "      <td>'name': 'command-xlarge-nightly', 'temperature...</td>\n",
       "      <td>None</td>\n",
       "      <td>zhou-01</td>\n",
       "      <td>\\nThe y-axis is the vertical axis on a graph. ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11879</th>\n",
       "      <td>worldtree</td>\n",
       "      <td>test</td>\n",
       "      <td>worldtree_test_1659</td>\n",
       "      <td>'name': 'gpt-4', 'temperature': 0, 'max_tokens...</td>\n",
       "      <td>None</td>\n",
       "      <td>kojima-01</td>\n",
       "      <td>The vertical axis on a graph is the y-axis, wh...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11880 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset       split                                id  \\\n",
       "0      commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "1      commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "2      commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "3      commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "4      commonsense_qa  validation  9aff72f0c480c2b4edde45bd2e7e4870   \n",
       "...               ...         ...                               ...   \n",
       "11875       worldtree        test               worldtree_test_1659   \n",
       "11876       worldtree        test               worldtree_test_1659   \n",
       "11877       worldtree        test               worldtree_test_1659   \n",
       "11878       worldtree        test               worldtree_test_1659   \n",
       "11879       worldtree        test               worldtree_test_1659   \n",
       "\n",
       "                                                   model instruction  \\\n",
       "0      'name': 'command-xlarge-nightly', 'temperature...        None   \n",
       "1      'name': 'text-davinci-003', 'temperature': 0, ...        None   \n",
       "2      'name': 'flan-T5-xxl', 'temperature': 0, 'max_...        None   \n",
       "3      'name': 'gpt-3.5-turbo', 'temperature': 0, 'ma...        None   \n",
       "4      'name': 'text-davinci-002', 'temperature': 0, ...        None   \n",
       "...                                                  ...         ...   \n",
       "11875  'name': 'flan-T5-xxl', 'temperature': 0, 'max_...        None   \n",
       "11876  'name': 'text-davinci-003', 'temperature': 0, ...        None   \n",
       "11877  'name': 'text-davinci-002', 'temperature': 0, ...        None   \n",
       "11878  'name': 'command-xlarge-nightly', 'temperature...        None   \n",
       "11879  'name': 'gpt-4', 'temperature': 0, 'max_tokens...        None   \n",
       "\n",
       "      cot_trigger                                      generated_cot  \\\n",
       "0            None     The main purpose of farmers is to supply food.   \n",
       "1            None                                     E) supply food   \n",
       "2            None                                                  E   \n",
       "3            None                                     E) supply food   \n",
       "4            None                                   \\nE) supply food   \n",
       "...           ...                                                ...   \n",
       "11875     zhou-01  C is the dependent variable. The dependent var...   \n",
       "11876     zhou-01   \\n\\nStep 1: The vertical axis on a graph is t...   \n",
       "11877     zhou-01   \\n\\nThe first thing we need to do is identify...   \n",
       "11878     zhou-01  \\nThe y-axis is the vertical axis on a graph. ...   \n",
       "11879   kojima-01  The vertical axis on a graph is the y-axis, wh...   \n",
       "\n",
       "       correct_answer  \n",
       "0                True  \n",
       "1                True  \n",
       "2                True  \n",
       "3                True  \n",
       "4                True  \n",
       "...               ...  \n",
       "11875            True  \n",
       "11876           False  \n",
       "11877            True  \n",
       "11878            True  \n",
       "11879            True  \n",
       "\n",
       "[11880 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/home/kon/work/ThoughtSource/libs/cot/cot/datasets/thoughtsource/thoughtsource_33_paper.json\"\n",
    "\n",
    "\n",
    "with open(path, \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "df = json_to_dataframe_3(data)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
