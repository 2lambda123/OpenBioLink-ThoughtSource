{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading med_qa...\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kon/CoT/ThoughtSource/libs/cot/cot/evaluate.py:84: UserWarning: Your answer could not be extracted, please add your sequence to the list of personalized answers sequences.\n",
      "                sequence: {pred}\n",
      "                In the file: libs/cot/cot/evaluate.py under the function clean()\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': {'None_lievin-02_kojima-A-D': 0.19324430479183033, 'None_lievin-10_kojima-A-D': 0.19402985074626866, 'None_lievin-03_kojima-A-D': 0.19638648860958366, 'None_lievin-01_kojima-A-D': 0.19088766692851533, 'None_kojima-01_kojima-A-D': 0.192458758837392}}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "from cot import Collection\n",
    "\n",
    "# 1) Dataset loading and selecting a random sample\n",
    "collection = Collection([\"med_qa\"], verbose=False)\n",
    "# collection = collection.select(split=\"validation\")\n",
    "\n",
    "# 2) Language Model generates chains of thought and then extracts answers\n",
    "config={\n",
    "    \"instruction_keys\": ['qa-01'], # \"Answer the following question through step-by-step reasoning.\"\n",
    "    \"cot_trigger_keys\": ['kojima-01'], # \"Answer: Let's think step by step.\"\n",
    "    \"answer_extraction_keys\": ['kojima-A-D'], # \"Therefore, among A through D, the answer is\"\n",
    "    \"api_service\": \"huggingface_hub\",\n",
    "    \"engine\": \"google/flan-t5-xl\",\n",
    "    \"warn\": False,\n",
    "    \"verbose\": False,\n",
    "}\n",
    "collection.generate(config=config)\n",
    "\n",
    "# 3) Performance evaluation\n",
    "collection.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(34, 48), match='answer is (d).'>\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "txt = \"Therefore, among A through E, the answer is (d).\"\n",
    "expected_answer_location = r\"\\s?[\\(\\{\\[]?(.)[\\)\\}\\]]?\\.?\"\n",
    "starting_sequence = r\"[Aa]nswer:?\\s?(?:is)?\\s?\" + expected_answer_location\n",
    "in_one = r\"[Aa]nswer:?\\s?(?:is)?\\s?\\s?[\\(\\{\\[]?(.)[\\)\\}\\]]?\\.?\"\n",
    "x = re.search(starting_sequence, txt)\n",
    "print(x)\n",
    "print(x.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(34, 48), match='answer is (d).'>\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "txt = \"Therefore, among A through E, the answer is (d).\"\n",
    "\n",
    "starting_sequence = r'answer:?\\s(?:is)?\\s?\\s?[\\(\\{\\[]?(A|B|C|D|E|F|G)[\\)\\}\\]]?\\.?'\n",
    "\n",
    "x = re.search(starting_sequence, txt, re.MULTILINE | re.IGNORECASE)\n",
    "print(x)\n",
    "print(x.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'answer:?\\\\s(?:is)?\\\\s?\\\\s?[\\\\(\\\\{\\\\[]?(A|B|C|D|E|F|G)[\\\\)\\\\}\\\\]]?\\\\.?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'answer:?\\\\\\\\s(?:is)?\\\\\\\\s?\\\\\\\\s?[\\\\\\\\(\\\\\\\\{\\\\\\\\[]?(A|B|C|D|E|F|G)[\\\\\\\\)\\\\\\\\}\\\\\\\\]]?\\\\\\\\.?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r'answer:?\\\\s(?:is)?\\\\s?\\\\s?[\\\\(\\\\{\\\\[]?(A|B|C|D|E|F|G)[\\\\)\\\\}\\\\]]?\\\\.?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Aa]nswer:?\\\\s?(?:is)?\\\\s?\\\\s?[\\\\(\\\\{\\\\[]?(.)[\\\\)\\\\}\\\\]]?\\\\.?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Aa]nswer:?\\\\s?(?:is)?\\\\s?\\\\s?[\\\\(\\\\{\\\\[]?(.)[\\\\)\\\\}\\\\]]?\\\\.?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"[Aa]nswer:?\\s?(?:is)?\\s?\\s?[\\(\\{\\[]?(.)[\\)\\}\\]]?\\.?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\a'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"\\a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\a'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\\a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match was found at 34-46: answer is D.\n",
      "Group 1 found at 44-45: D\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "regex = r\"[Aa]nswer:?\\s?(?:is)?\\s?\" + r\"\\s?[\\(\\{\\[]?(.)[\\)\\}\\]]?\\.?\"\n",
    "\n",
    "test_str = \"Therefore, among A through E, the answer is D.\"\n",
    "\n",
    "matches = re.search(regex, test_str, re.MULTILINE)\n",
    "\n",
    "if matches:\n",
    "    print (\"Match was found at {start}-{end}: {match}\".format(start = matches.start(), end = matches.end(), match = matches.group()))\n",
    "    \n",
    "    for groupNum in range(0, len(matches.groups())):\n",
    "        groupNum = groupNum + 1\n",
    "        \n",
    "        print (\"Group {groupNum} found at {start}-{end}: {group}\".format(groupNum = groupNum, start = matches.start(groupNum), end = matches.end(groupNum), group = matches.group(groupNum)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.dump(\"commonsense_qa_validation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '7b95825a19d6930d6aed35c7c57a2d82',\n",
       " 'ref_id': '',\n",
       " 'question': \"James couldn't get comfortable.  There was too much dirt.  He needed to clean out what?\",\n",
       " 'type': 'multiplechoice',\n",
       " 'choices': ['ground', 'subway', 'bank', 'bed', 'street'],\n",
       " 'context': '',\n",
       " 'cot': ['Bed is a piece of furniture for sleep or rest, typically a framework with a mattress.',\n",
       "  \"James couldn't get comfortable.\",\n",
       "  'There was too much dirt.',\n",
       "  'He needed to clean out bed.',\n",
       "  'James could have found the ground with too much dirt but itâ€™s not possible to clean the whole ground.',\n",
       "  'Subways were under several feet of dirt, james always found it claustrophobic and he hated using it so, it was not what he needed to clean out.',\n",
       "  'Bank is not a private property that could be needed for james to clean up.',\n",
       "  'Cleaning of streets is a responsibility of the administrative body of a city or a town and not for james to worry about.'],\n",
       " 'answer': ['bed'],\n",
       " 'generated_cot': [{'id': '887',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': 'kojima-01',\n",
       "   'prompt_text': '',\n",
       "   'answers': [{'id': '0',\n",
       "     'answer_extraction': 'kojima-A-E',\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'Therefore, among A through E, the answer is D.',\n",
       "     'correct_answer': False}],\n",
       "   'cot': \" James couldn't get comfortable.  This means he was not able to relax.  There was too much dirt.  This means there was a lot of dirt, and it was making James uncomfortable.  He needed to clean out what?  This means he needed to remove the dirt.  The answer must be something that James can clean out.  The answer cannot be (A) ground, (B) subway, (C) bank, or (E) street.  These are all places where there might be dirt, but James cannot remove the dirt from these places.  The answer must be (D) bed.\",\n",
       "   'author': 'kojima',\n",
       "   'date': None,\n",
       "   'api_service': '',\n",
       "   'model': 'gpt-3',\n",
       "   'comment': '',\n",
       "   'annotation': []},\n",
       "  {'id': '788',\n",
       "   'fragments_version': '0.01',\n",
       "   'instruction': None,\n",
       "   'cot_trigger': None,\n",
       "   'prompt_text': '',\n",
       "   'answers': [{'id': '0',\n",
       "     'answer_extraction': None,\n",
       "     'answer_extraction_text': '',\n",
       "     'answer': 'So the answer is (d).',\n",
       "     'correct_answer': False}],\n",
       "   'cot': 'The answer should be something that James could clean out that would make him more comfortable. Of the above choices, the only thing that James could realistically clean out is his bed.',\n",
       "   'author': 'wei',\n",
       "   'date': None,\n",
       "   'api_service': '',\n",
       "   'model': 'gpt-3',\n",
       "   'comment': '',\n",
       "   'annotation': []}],\n",
       " 'feedback': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection[\"commonsense_qa\"][\"validation\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for  item in collection[\"commonsense_qa\"][\"validation\"]:\n",
    "    print(\n",
    "        item['generated_cot'][0]['answers'][0]['correct_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a19cb823e24c98ee05a9cfa4a3a579b5d56d4c1a735f2a12456750b95a1e155e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
